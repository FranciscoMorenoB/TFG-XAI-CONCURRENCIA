{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generate_data import Data\n",
    "from src.evaluate import *\n",
    "from src.models import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 30.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = Data(layer_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 132 train | 79 val | 318 test\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 15.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, val, test = data.get_splits(['random_subsample'], [[0.25, 0.75]])\n",
    "\n",
    "train_unshuffled = train.copy()\n",
    "np.random.shuffle(train)\n",
    "\n",
    "x_train, y_train = data.get_x_y(train)\n",
    "x_val, y_val = data.get_x_y(val)\n",
    "x_test, y_test = data.get_x_y(test)\n",
    "\n",
    "train_original = data.reverse_encoding(data.get_x_y(train_unshuffled)[0])\n",
    "val_original = data.reverse_encoding(x_val)\n",
    "test_original = data.reverse_encoding(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek at unshuffled train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_,.,,_', '_uw,,_', ',dr.__', 'A'],\n",
       " ['.___,_', '._,,w.', '__cr,,', 'V'],\n",
       " [',.__._', 'uw,,_.', '_.._cr', 'V'],\n",
       " ['_,,._,', '.wu_.,', '_cr._.', 'V'],\n",
       " [',,.,,_', '___wu.', ',.,.,_', 'V'],\n",
       " ['_,_.,,', '_._,__', '_._r._', 'C'],\n",
       " ['_,__._', '.___,,', '.r._,,', 'C'],\n",
       " ['.__._.', 'wu,,,.', ',__,,,', 'V'],\n",
       " ['_,,__,', '__uw,,', ',.,__r', 'C'],\n",
       " [',,,__.', '.__.w_', '_cr__,', 'V'],\n",
       " [',__._,', '.,,_w,', '_,dr_,', 'D'],\n",
       " ['_,.,_,', ',,____', ',,r.,_', 'C'],\n",
       " ['..___.', ',_,...', '_._dr,', 'D'],\n",
       " ['..,._,', '.__.w,', '__,,cr', 'V'],\n",
       " ['._..,.', ',.,,.w', '_,_,,,', 'V'],\n",
       " ['_,.___', ',,__..', ',,,r,,', 'C'],\n",
       " ['._,.,,', '.,_.,,', 'dr,,._', 'D'],\n",
       " ['_._.._', '.....,', '_.,_,_', 'V'],\n",
       " ['._..,_', ',,,_wu', '..,,,,', 'V'],\n",
       " ['.___,,', ',wu_.,', '_,,,cr', 'V']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_original[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 4 | F2-uw 7 | F2-w 8 | F2-noop 12 | \n",
      "F3 cr:    F2-wu 6 | F2-uw 6 | F2-w 9 | F2-noop 6 | \n",
      "F3 r:    F2-wu 4 | F2-uw 4 | F2-w 11 | F2-noop 10 | \n",
      "F3 noop:    F2-wu 10 | F2-uw 9 | F2-w 12 | F2-noop 14 | \n",
      "\n",
      "Positive samples count: 56\n",
      "Total samples count: 132\n",
      "Positive class ratio: 0.42424242424242425\n"
     ]
    }
   ],
   "source": [
    "pos_train_ratio = get_stats_and_ratio(train_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek at test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['___._.', '__..,_', ',__.cr', 'V'],\n",
       " [',,__,,', '_._.,w', ',,,r_.', 'C'],\n",
       " [',,,._.', '__.,uw', '.cr_._', 'V'],\n",
       " ['_.._,,', '__,,uw', ',,.._r', 'C'],\n",
       " ['_,._..', '.._w.,', ',_,_dr', 'D'],\n",
       " ['__._.,', '_.,_uw', '_,.,_.', 'V'],\n",
       " ['.__,..', ',_wu._', 'r___..', 'C'],\n",
       " [',_..,,', ',_w._.', '.,_dr.', 'D'],\n",
       " ['_.,_,_', '__,,,,', '_cr._.', 'V'],\n",
       " ['.__.__', '.,w.__', '_._.r.', 'C'],\n",
       " [',._,__', ',,wu__', ',.,_cr', 'V'],\n",
       " ['.,,.,,', '_.,uw.', '.___._', 'V'],\n",
       " ['.,._,_', '_,.wu.', ',_,.dr', 'V'],\n",
       " [',_.,._', '.,,uw_', '__._cr', 'V'],\n",
       " [',_,,__', '.__uw.', ',r,,._', 'C']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_original[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 19 | F2-uw 15 | F2-w 19 | F2-noop 20 | \n",
      "F3 cr:    F2-wu 16 | F2-uw 14 | F2-w 17 | F2-noop 25 | \n",
      "F3 r:    F2-wu 21 | F2-uw 22 | F2-w 20 | F2-noop 25 | \n",
      "F3 noop:    F2-wu 20 | F2-uw 20 | F2-w 22 | F2-noop 23 | \n",
      "\n",
      "Positive samples count: 142\n",
      "Total samples count: 318\n",
      "Positive class ratio: 0.44654088050314467\n"
     ]
    }
   ],
   "source": [
    "pos_test_ratio = get_stats_and_ratio(test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek at val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.,,._,', '.._,__', '.,,_cr', 'V'],\n",
       " ['__,._,', '__,...', ',._cr,', 'V'],\n",
       " [',.,,,_', '....,,', '_,_,,,', 'V'],\n",
       " ['.,._,,', ',._uw_', '.,.,,r', 'C'],\n",
       " [',.._,_', ',.wu..', '._._dr', 'V'],\n",
       " ['__..__', '_._w.,', '_,.,r.', 'C'],\n",
       " ['.,.,..', '__uw,_', '_.___.', 'V'],\n",
       " ['.,.,..', '.,_.._', ',._dr,', 'D'],\n",
       " ['__.,,,', '_._w__', ',._,,_', 'V'],\n",
       " ['_,_,._', '_....,', 'r.._.,', 'C'],\n",
       " ['..,,.,', ',,__,,', 'dr,,.,', 'D'],\n",
       " [',,_.__', '__..uw', '_,,cr,', 'V'],\n",
       " [',_,,,.', '._w__,', '__.,__', 'V'],\n",
       " ['_,,,..', '_wu_,_', '.,_.._', 'V'],\n",
       " ['.._,,_', '.,_.uw', '.,__cr', 'V']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_original[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 2 | F2-uw 3 | F2-w 3 | F2-noop 3 | \n",
      "F3 cr:    F2-wu 3 | F2-uw 5 | F2-w 4 | F2-noop 4 | \n",
      "F3 r:    F2-wu 5 | F2-uw 4 | F2-w 5 | F2-noop 7 | \n",
      "F3 noop:    F2-wu 5 | F2-uw 6 | F2-w 8 | F2-noop 12 | \n",
      "\n",
      "Positive samples count: 30\n",
      "Total samples count: 79\n",
      "Positive class ratio: 0.379746835443038\n"
     ]
    }
   ],
   "source": [
    "pos_val_ratio = get_stats_and_ratio(val_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send label arrays to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases codificadas: ['A' 'C' 'D' 'V']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificar etiquetas categóricas a índices numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# Verificar clases codificadas\n",
    "print(\"Clases codificadas:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data in normal format (same as CNN format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normal = data.to_conv_format(x_train)\n",
    "x_val_normal = data.to_conv_format(x_val)\n",
    "x_test_normal = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_normal)):\n",
    "    x_train_normal[i] = x_train_normal[i].to(device)\n",
    "    x_val_normal[i] = x_val_normal[i].to(device)\n",
    "    x_test_normal[i] = x_test_normal[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 48])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_normal[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data in convolutional format, send to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = data.to_conv_format(x_train)\n",
    "x_val_cnn = data.to_conv_format(x_val)\n",
    "x_test_cnn = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_cnn)):\n",
    "    x_train_cnn[i] = x_train_cnn[i].to(device)\n",
    "    x_val_cnn[i] = x_val_cnn[i].to(device)\n",
    "    x_test_cnn[i] = x_test_cnn[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 48])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cnn[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data in LSTM format, send to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = data.to_lstm_format(x_train)\n",
    "x_val_lstm = data.to_lstm_format(x_val)\n",
    "x_test_lstm = data.to_lstm_format(x_test)\n",
    "for i in range(len(x_train_lstm)):\n",
    "    x_train_lstm[i] = x_train_lstm[i].to(device)\n",
    "    x_val_lstm[i] = x_val_lstm[i].to(device)\n",
    "    x_test_lstm[i] = x_test_lstm[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 6, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lstm[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 20\n",
    "epochs = 200\n",
    "early_stopping_limit = 100\n",
    "\n",
    "experiment_name = \"25per\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training procedure for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(constructor, x_train, x_val, x_test, weight_decay, *argv):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    wrong_preds = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        model = constructor(*argv)\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "        train_losses.append([])\n",
    "        val_losses.append([])\n",
    "        train_accs.append([])\n",
    "        val_accs.append([])\n",
    "        \n",
    "        best_acc = 0\n",
    "\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = train_epoch(model, x_train, y_train, criterion, optimizer, epoch, 10, verbose=False)\n",
    "            val_loss, val_acc = eval_epoch(model, x_val, y_val, criterion, 'Validation', verbose=False)\n",
    "\n",
    "            \n",
    "            train_losses[-1].append(train_loss)\n",
    "            val_losses[-1].append(val_loss)\n",
    "            train_accs[-1].append(train_acc)\n",
    "            val_accs[-1].append(val_acc)\n",
    "            \n",
    "            model_name = constructor.__name__[:constructor.__name__.find('_')]\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'./{model_name}_model_TEMP_' + experiment_name)    \n",
    "                early_stopping_cnt = 0\n",
    "            else:\n",
    "                early_stopping_cnt += 1\n",
    "\n",
    "            if early_stopping_cnt >= early_stopping_limit:\n",
    "                break\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n",
    "    \n",
    "        accuracies.append(get_accuracy_by_cases(model, x_test, y_test, test_original))\n",
    "        precisions.append(get_precision_by_cases(model, x_test, y_test, test_original))\n",
    "        recalls.append(get_recall_by_cases(model, x_test, y_test, test_original))\n",
    "        f1_scores.append(get_f1_by_cases(model, x_test, y_test, test_original))\n",
    "        \n",
    "        wrong_preds.append(get_wrong_predictions(model, x_test, y_test, test_original))\n",
    "\n",
    "        if accuracies[-1]['Overall'] > best_accuracy:\n",
    "            torch.save(model.state_dict(), f'./best_{model_name}_model_' + experiment_name)    \n",
    "            best_accuracy = accuracies[-1]['Overall']\n",
    "\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test accuracy:\", accuracies[-1]['Overall'])\n",
    "    \n",
    "    return accuracies, precisions, recalls, f1_scores, wrong_preds, [train_losses, val_losses, train_accs, val_accs]\n",
    "    #return accuracies, precisions, wrong_preds, [train_losses, val_losses, train_accs, val_accs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_7728\\2598404065.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.9213836477987422\n",
      "2 / 20 models trained | Current model test accuracy: 0.8647798742138365\n",
      "3 / 20 models trained | Current model test accuracy: 0.8144654088050315\n",
      "4 / 20 models trained | Current model test accuracy: 0.9559748427672956\n",
      "5 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "6 / 20 models trained | Current model test accuracy: 0.949685534591195\n",
      "7 / 20 models trained | Current model test accuracy: 0.9622641509433962\n",
      "8 / 20 models trained | Current model test accuracy: 0.9559748427672956\n",
      "9 / 20 models trained | Current model test accuracy: 0.9811320754716981\n",
      "10 / 20 models trained | Current model test accuracy: 0.9905660377358491\n",
      "11 / 20 models trained | Current model test accuracy: 0.9591194968553459\n",
      "12 / 20 models trained | Current model test accuracy: 0.9433962264150944\n",
      "13 / 20 models trained | Current model test accuracy: 0.8962264150943396\n",
      "14 / 20 models trained | Current model test accuracy: 0.9245283018867925\n",
      "15 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "16 / 20 models trained | Current model test accuracy: 0.940251572327044\n",
      "17 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "18 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "19 / 20 models trained | Current model test accuracy: 0.9276729559748428\n",
      "20 / 20 models trained | Current model test accuracy: 0.9182389937106918\n",
      "CPU times: total: 24min 32s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnn_accuracies, cnn_precisions, cnn_recalls, cnn_f1_scores, cnn_wrong_preds, cnn_epoch_stats = train_models(\n",
    "    CNN_Model, x_train_cnn, x_val_cnn, x_test_cnn, 0.0001, data, 64, 128, 4, -1, 'keras')\n",
    "    \n",
    "#cnn_accuracies, cnn_precisions, cnn_wrong_preds, cnn_epoch_stats = train_models(CNN_Model, x_train_cnn, x_val_cnn, x_test_cnn, 0.0001, data, 64, 128, 4, -1, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for CNN:\n",
      "Experiment 1:\n",
      "  Accuracy: 0.9213836477987422\n",
      "  Precision: 0.9627118644067797\n",
      "  Recall: 0.9213836477987422\n",
      "  F1-score: 0.9415944825088969\n",
      "Experiment 2:\n",
      "  Accuracy: 0.8647798742138365\n",
      "  Precision: 0.8802588996763754\n",
      "  Recall: 0.8647798742138365\n",
      "  F1-score: 0.8724507351097269\n",
      "Experiment 3:\n",
      "  Accuracy: 0.8144654088050315\n",
      "  Precision: 0.8269230769230769\n",
      "  Recall: 0.8144654088050315\n",
      "  F1-score: 0.820646967798983\n",
      "Experiment 4:\n",
      "  Accuracy: 0.9559748427672956\n",
      "  Precision: 0.9700996677740864\n",
      "  Recall: 0.9559748427672956\n",
      "  F1-score: 0.9629854632241268\n",
      "Experiment 5:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9792387543252595\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9544144287846508\n",
      "Experiment 6:\n",
      "  Accuracy: 0.949685534591195\n",
      "  Precision: 0.9540983606557377\n",
      "  Recall: 0.949685534591195\n",
      "  F1-score: 0.9518868333261123\n",
      "Experiment 7:\n",
      "  Accuracy: 0.9622641509433962\n",
      "  Precision: 0.9832775919732442\n",
      "  Recall: 0.9622641509433962\n",
      "  F1-score: 0.9726573902889949\n",
      "Experiment 8:\n",
      "  Accuracy: 0.9559748427672956\n",
      "  Precision: 0.9638157894736842\n",
      "  Recall: 0.9559748427672956\n",
      "  F1-score: 0.9598793038418018\n",
      "Experiment 9:\n",
      "  Accuracy: 0.9811320754716981\n",
      "  Precision: 0.99\n",
      "  Recall: 0.9811320754716981\n",
      "  F1-score: 0.9855460897865416\n",
      "Experiment 10:\n",
      "  Accuracy: 0.9905660377358491\n",
      "  Precision: 0.9900990099009901\n",
      "  Recall: 0.9905660377358491\n",
      "  F1-score: 0.9903324687573686\n",
      "Experiment 11:\n",
      "  Accuracy: 0.9591194968553459\n",
      "  Precision: 0.9634551495016611\n",
      "  Recall: 0.9591194968553459\n",
      "  F1-score: 0.9612824344518407\n",
      "Experiment 12:\n",
      "  Accuracy: 0.9433962264150944\n",
      "  Precision: 0.9730639730639731\n",
      "  Recall: 0.9433962264150944\n",
      "  F1-score: 0.9580004640832699\n",
      "Experiment 13:\n",
      "  Accuracy: 0.8962264150943396\n",
      "  Precision: 0.9269102990033222\n",
      "  Recall: 0.8962264150943396\n",
      "  F1-score: 0.9113101480169851\n",
      "Experiment 14:\n",
      "  Accuracy: 0.9245283018867925\n",
      "  Precision: 0.956081081081081\n",
      "  Recall: 0.9245283018867925\n",
      "  F1-score: 0.940039995932617\n",
      "Experiment 15:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9366666666666666\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9337329785920363\n",
      "Experiment 16:\n",
      "  Accuracy: 0.940251572327044\n",
      "  Precision: 0.9435215946843853\n",
      "  Recall: 0.940251572327044\n",
      "  F1-score: 0.94188374530672\n",
      "Experiment 17:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9466666666666667\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9386752423064899\n",
      "Experiment 18:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9501661129568106\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9403923485370242\n",
      "Experiment 19:\n",
      "  Accuracy: 0.9276729559748428\n",
      "  Precision: 0.9471947194719472\n",
      "  Recall: 0.9276729559748428\n",
      "  F1-score: 0.9373322040841179\n",
      "Experiment 20:\n",
      "  Accuracy: 0.9182389937106918\n",
      "  Precision: 0.944078947368421\n",
      "  Recall: 0.9182389937106918\n",
      "  F1-score: 0.9309797038337202\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for CNN:\")\n",
    "for i in range(len(cnn_accuracies)):\n",
    "    print(f\"Experiment {i + 1}:\")\n",
    "    print(f\"  Accuracy: {cnn_accuracies[i]['Overall']}\")\n",
    "    print(f\"  Precision: {cnn_precisions[i]['Overall']}\")\n",
    "    print(f\"  Recall: {cnn_recalls[i]['Overall']}\")\n",
    "    print(f\"  F1-score: {cnn_f1_scores[i]['Overall']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_7728\\2598404065.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.9245283018867925\n",
      "2 / 20 models trained | Current model test accuracy: 0.9591194968553459\n",
      "3 / 20 models trained | Current model test accuracy: 0.9056603773584906\n",
      "4 / 20 models trained | Current model test accuracy: 0.9213836477987422\n",
      "5 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "6 / 20 models trained | Current model test accuracy: 0.9088050314465409\n",
      "7 / 20 models trained | Current model test accuracy: 0.89937106918239\n",
      "8 / 20 models trained | Current model test accuracy: 0.940251572327044\n",
      "9 / 20 models trained | Current model test accuracy: 0.9716981132075472\n",
      "10 / 20 models trained | Current model test accuracy: 0.949685534591195\n",
      "11 / 20 models trained | Current model test accuracy: 0.9150943396226415\n",
      "12 / 20 models trained | Current model test accuracy: 0.9119496855345912\n",
      "13 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "14 / 20 models trained | Current model test accuracy: 0.9213836477987422\n",
      "15 / 20 models trained | Current model test accuracy: 0.9591194968553459\n",
      "16 / 20 models trained | Current model test accuracy: 0.9276729559748428\n",
      "17 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "18 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "19 / 20 models trained | Current model test accuracy: 0.9339622641509434\n",
      "20 / 20 models trained | Current model test accuracy: 0.9308176100628931\n",
      "CPU times: total: 9min 45s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lstm_accuracies, lstm_precisions, lstm_recalls, lstm_f1Scores, lstm_wrong_preds, lstm_epoch_stats = train_models(LSTM_Model, x_train_lstm, x_val_lstm, x_test_lstm, 0.0001, data, 16, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LSTM:\n",
      "Experiment 1:\n",
      "  Accuracy: 0.9245283018867925\n",
      "  Precision: 0.9628378378378378\n",
      "  Recall: 0.9245283018867925\n",
      "  F1-score: 0.9432942686345369\n",
      "Experiment 2:\n",
      "  Accuracy: 0.9591194968553459\n",
      "  Precision: 0.9865771812080537\n",
      "  Recall: 0.9591194968553459\n",
      "  F1-score: 0.9726545975203653\n",
      "Experiment 3:\n",
      "  Accuracy: 0.9056603773584906\n",
      "  Precision: 0.9362416107382551\n",
      "  Recall: 0.9056603773584906\n",
      "  F1-score: 0.9206971228214911\n",
      "Experiment 4:\n",
      "  Accuracy: 0.9213836477987422\n",
      "  Precision: 0.9658703071672355\n",
      "  Recall: 0.9213836477987422\n",
      "  F1-score: 0.9431026540720984\n",
      "Experiment 5:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9759450171821306\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9528472977874501\n",
      "Experiment 6:\n",
      "  Accuracy: 0.9088050314465409\n",
      "  Precision: 0.9131832797427653\n",
      "  Recall: 0.9088050314465409\n",
      "  F1-score: 0.9109888951168483\n",
      "Experiment 7:\n",
      "  Accuracy: 0.89937106918239\n",
      "  Precision: 0.921311475409836\n",
      "  Recall: 0.89937106918239\n",
      "  F1-score: 0.9102090742292793\n",
      "Experiment 8:\n",
      "  Accuracy: 0.940251572327044\n",
      "  Precision: 0.9693877551020408\n",
      "  Recall: 0.940251572327044\n",
      "  F1-score: 0.9545973921225971\n",
      "Experiment 9:\n",
      "  Accuracy: 0.9716981132075472\n",
      "  Precision: 0.9771986970684039\n",
      "  Recall: 0.9716981132075472\n",
      "  F1-score: 0.9744406426893301\n",
      "Experiment 10:\n",
      "  Accuracy: 0.949685534591195\n",
      "  Precision: 0.9965397923875432\n",
      "  Recall: 0.949685534591195\n",
      "  F1-score: 0.9725486688061187\n",
      "Experiment 11:\n",
      "  Accuracy: 0.9150943396226415\n",
      "  Precision: 0.9822695035460993\n",
      "  Recall: 0.9150943396226415\n",
      "  F1-score: 0.9474927709993652\n",
      "Experiment 12:\n",
      "  Accuracy: 0.9119496855345912\n",
      "  Precision: 0.9489795918367347\n",
      "  Recall: 0.9119496855345912\n",
      "  F1-score: 0.930096216850019\n",
      "Experiment 13:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9696969696969697\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9498596068993181\n",
      "Experiment 14:\n",
      "  Accuracy: 0.9213836477987422\n",
      "  Precision: 0.9593220338983051\n",
      "  Recall: 0.9213836477987422\n",
      "  F1-score: 0.9399701863072398\n",
      "Experiment 15:\n",
      "  Accuracy: 0.9591194968553459\n",
      "  Precision: 0.9706840390879479\n",
      "  Recall: 0.9591194968553459\n",
      "  F1-score: 0.9648671171290718\n",
      "Experiment 16:\n",
      "  Accuracy: 0.9276729559748428\n",
      "  Precision: 0.9594594594594594\n",
      "  Recall: 0.9276729559748428\n",
      "  F1-score: 0.9432985047739145\n",
      "Experiment 17:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9792387543252595\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9544144287846508\n",
      "Experiment 18:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9794520547945206\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9545157289435111\n",
      "Experiment 19:\n",
      "  Accuracy: 0.9339622641509434\n",
      "  Precision: 0.9634551495016611\n",
      "  Recall: 0.9339622641509434\n",
      "  F1-score: 0.9484794925585159\n",
      "Experiment 20:\n",
      "  Accuracy: 0.9308176100628931\n",
      "  Precision: 0.9894366197183099\n",
      "  Recall: 0.9308176100628931\n",
      "  F1-score: 0.9592323926606775\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for LSTM:\")\n",
    "for i in range(len(lstm_accuracies)):\n",
    "    print(f\"Experiment {i + 1}:\")\n",
    "    print(f\"  Accuracy: {lstm_accuracies[i]['Overall']}\")\n",
    "    print(f\"  Precision: {lstm_precisions[i]['Overall']}\")\n",
    "    print(f\"  Recall: {lstm_recalls[i]['Overall']}\")\n",
    "    print(f\"  F1-score: {lstm_f1Scores[i]['Overall']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_7728\\2598404065.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.8207547169811321\n",
      "2 / 20 models trained | Current model test accuracy: 0.8584905660377359\n",
      "3 / 20 models trained | Current model test accuracy: 0.8301886792452831\n",
      "4 / 20 models trained | Current model test accuracy: 0.8773584905660378\n",
      "5 / 20 models trained | Current model test accuracy: 0.8238993710691824\n",
      "6 / 20 models trained | Current model test accuracy: 0.8647798742138365\n",
      "7 / 20 models trained | Current model test accuracy: 0.8364779874213837\n",
      "8 / 20 models trained | Current model test accuracy: 0.8930817610062893\n",
      "9 / 20 models trained | Current model test accuracy: 0.8805031446540881\n",
      "10 / 20 models trained | Current model test accuracy: 0.8742138364779874\n",
      "11 / 20 models trained | Current model test accuracy: 0.8930817610062893\n",
      "12 / 20 models trained | Current model test accuracy: 0.8710691823899371\n",
      "13 / 20 models trained | Current model test accuracy: 0.8742138364779874\n",
      "14 / 20 models trained | Current model test accuracy: 0.8742138364779874\n",
      "15 / 20 models trained | Current model test accuracy: 0.7295597484276729\n",
      "16 / 20 models trained | Current model test accuracy: 0.8522012578616353\n",
      "17 / 20 models trained | Current model test accuracy: 0.8773584905660378\n",
      "18 / 20 models trained | Current model test accuracy: 0.8773584905660378\n",
      "19 / 20 models trained | Current model test accuracy: 0.8301886792452831\n",
      "20 / 20 models trained | Current model test accuracy: 0.8050314465408805\n",
      "CPU times: total: 8min 2s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepset_accuracies, deepset_precisions, deepset_recalls, deepset_f1Scores, deepset_wrong_preds, deepset_epoch_stats = train_models(DEEPSET_Model, x_train_normal, x_val_normal, x_test_normal, 0.005, data, 128, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for DeepSet:\n",
      "Experiment 1:\n",
      "  Accuracy: 0.8207547169811321\n",
      "  Precision: 0.8403908794788274\n",
      "  Recall: 0.8207547169811321\n",
      "  F1-score: 0.8304567401076642\n",
      "Experiment 2:\n",
      "  Accuracy: 0.8584905660377359\n",
      "  Precision: 0.8673139158576052\n",
      "  Recall: 0.8584905660377359\n",
      "  F1-score: 0.862879685813859\n",
      "Experiment 3:\n",
      "  Accuracy: 0.8301886792452831\n",
      "  Precision: 0.8571428571428571\n",
      "  Recall: 0.8301886792452831\n",
      "  F1-score: 0.8434504792332269\n",
      "Experiment 4:\n",
      "  Accuracy: 0.8773584905660378\n",
      "  Precision: 0.8896103896103896\n",
      "  Recall: 0.8773584905660378\n",
      "  F1-score: 0.8834419636666204\n",
      "Experiment 5:\n",
      "  Accuracy: 0.8238993710691824\n",
      "  Precision: 0.8453947368421053\n",
      "  Recall: 0.8238993710691824\n",
      "  F1-score: 0.8345086569087957\n",
      "Experiment 6:\n",
      "  Accuracy: 0.8647798742138365\n",
      "  Precision: 0.8852459016393442\n",
      "  Recall: 0.8647798742138365\n",
      "  F1-score: 0.8748932158953663\n",
      "Experiment 7:\n",
      "  Accuracy: 0.8364779874213837\n",
      "  Precision: 0.8501628664495114\n",
      "  Recall: 0.8364779874213837\n",
      "  F1-score: 0.8432649095105066\n",
      "Experiment 8:\n",
      "  Accuracy: 0.8930817610062893\n",
      "  Precision: 0.9144736842105263\n",
      "  Recall: 0.8930817610062893\n",
      "  F1-score: 0.9036511388348404\n",
      "Experiment 9:\n",
      "  Accuracy: 0.8805031446540881\n",
      "  Precision: 0.898360655737705\n",
      "  Recall: 0.8805031446540881\n",
      "  F1-score: 0.8893422669417846\n",
      "Experiment 10:\n",
      "  Accuracy: 0.8742138364779874\n",
      "  Precision: 0.8896103896103896\n",
      "  Recall: 0.8742138364779874\n",
      "  F1-score: 0.8818449142142676\n",
      "Experiment 11:\n",
      "  Accuracy: 0.8930817610062893\n",
      "  Precision: 0.9084967320261438\n",
      "  Recall: 0.8930817610062893\n",
      "  F1-score: 0.9007232984233463\n",
      "Experiment 12:\n",
      "  Accuracy: 0.8710691823899371\n",
      "  Precision: 0.8892508143322475\n",
      "  Recall: 0.8710691823899371\n",
      "  F1-score: 0.8800661030066393\n",
      "Experiment 13:\n",
      "  Accuracy: 0.8742138364779874\n",
      "  Precision: 0.8921568627450981\n",
      "  Recall: 0.8742138364779874\n",
      "  F1-score: 0.8830942157992112\n",
      "Experiment 14:\n",
      "  Accuracy: 0.8742138364779874\n",
      "  Precision: 0.8892508143322475\n",
      "  Recall: 0.8742138364779874\n",
      "  F1-score: 0.8816682156133829\n",
      "Experiment 15:\n",
      "  Accuracy: 0.7295597484276729\n",
      "  Precision: 0.7641196013289037\n",
      "  Recall: 0.7295597484276729\n",
      "  F1-score: 0.7464398623506701\n",
      "Experiment 16:\n",
      "  Accuracy: 0.8522012578616353\n",
      "  Precision: 0.869281045751634\n",
      "  Recall: 0.8522012578616353\n",
      "  F1-score: 0.8606564227467556\n",
      "Experiment 17:\n",
      "  Accuracy: 0.8773584905660378\n",
      "  Precision: 0.9013157894736842\n",
      "  Recall: 0.8773584905660378\n",
      "  F1-score: 0.8891757973340777\n",
      "Experiment 18:\n",
      "  Accuracy: 0.8773584905660378\n",
      "  Precision: 0.8954248366013072\n",
      "  Recall: 0.8773584905660378\n",
      "  F1-score: 0.8862996069701924\n",
      "Experiment 19:\n",
      "  Accuracy: 0.8301886792452831\n",
      "  Precision: 0.8464052287581699\n",
      "  Recall: 0.8301886792452831\n",
      "  F1-score: 0.8382185281894745\n",
      "Experiment 20:\n",
      "  Accuracy: 0.8050314465408805\n",
      "  Precision: 0.8283828382838284\n",
      "  Recall: 0.8050314465408805\n",
      "  F1-score: 0.8165402259413163\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for DeepSet:\")\n",
    "for i in range(len(deepset_accuracies)):\n",
    "    print(f\"Experiment {i + 1}:\")\n",
    "    print(f\"  Accuracy: {deepset_accuracies[i]['Overall']}\")\n",
    "    print(f\"  Precision: {deepset_precisions[i]['Overall']}\")\n",
    "    print(f\"  Recall: {deepset_recalls[i]['Overall']}\")\n",
    "    print(f\"  F1-score: {deepset_f1Scores[i]['Overall']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_7728\\2598404065.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.6729559748427673\n",
      "2 / 20 models trained | Current model test accuracy: 0.7767295597484277\n",
      "3 / 20 models trained | Current model test accuracy: 0.550314465408805\n",
      "4 / 20 models trained | Current model test accuracy: 0.6855345911949685\n",
      "5 / 20 models trained | Current model test accuracy: 0.19811320754716982\n",
      "6 / 20 models trained | Current model test accuracy: 0.5974842767295597\n",
      "7 / 20 models trained | Current model test accuracy: 0.5534591194968553\n",
      "8 / 20 models trained | Current model test accuracy: 0.6132075471698113\n",
      "9 / 20 models trained | Current model test accuracy: 0.7421383647798742\n",
      "10 / 20 models trained | Current model test accuracy: 0.8805031446540881\n",
      "11 / 20 models trained | Current model test accuracy: 0.5534591194968553\n",
      "12 / 20 models trained | Current model test accuracy: 0.7484276729559748\n",
      "13 / 20 models trained | Current model test accuracy: 0.8176100628930818\n",
      "14 / 20 models trained | Current model test accuracy: 0.5534591194968553\n",
      "15 / 20 models trained | Current model test accuracy: 0.6918238993710691\n",
      "16 / 20 models trained | Current model test accuracy: 0.8710691823899371\n",
      "17 / 20 models trained | Current model test accuracy: 0.7861635220125787\n",
      "18 / 20 models trained | Current model test accuracy: 0.5408805031446541\n",
      "19 / 20 models trained | Current model test accuracy: 0.5534591194968553\n",
      "20 / 20 models trained | Current model test accuracy: 0.720125786163522\n",
      "CPU times: total: 6min 18s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepsetv2_accuracies, deepsetv2_precisions, deepsetv2_recalls, deepsetv2_f1Scores, deepsetv2_wrong_preds, deepsetv2_epoch_stats = train_models(DEEPSETV2_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 16, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for DeepSetV2:\n",
      "Experiment 1:\n",
      "  Accuracy: 0.6729559748427673\n",
      "  Precision: 0.6893203883495146\n",
      "  Recall: 0.6729559748427673\n",
      "  F1-score: 0.6810398924249216\n",
      "Experiment 2:\n",
      "  Accuracy: 0.7767295597484277\n",
      "  Precision: 0.7767295597484277\n",
      "  Recall: 0.7767295597484277\n",
      "  F1-score: 0.7767295597484277\n",
      "Experiment 3:\n",
      "  Accuracy: 0.550314465408805\n",
      "  Precision: 0.570957095709571\n",
      "  Recall: 0.550314465408805\n",
      "  F1-score: 0.5604457649552478\n",
      "Experiment 4:\n",
      "  Accuracy: 0.6855345911949685\n",
      "  Precision: 0.7697841726618705\n",
      "  Recall: 0.6855345911949685\n",
      "  F1-score: 0.7252207436885959\n",
      "Experiment 5:\n",
      "  Accuracy: 0.19811320754716982\n",
      "  Precision: 0.4396551724137931\n",
      "  Recall: 0.19811320754716982\n",
      "  F1-score: 0.27314460596786533\n",
      "Experiment 6:\n",
      "  Accuracy: 0.5974842767295597\n",
      "  Precision: 0.5974842767295597\n",
      "  Recall: 0.5974842767295597\n",
      "  F1-score: 0.5974842767295597\n",
      "Experiment 7:\n",
      "  Accuracy: 0.5534591194968553\n",
      "  Precision: 0.5534591194968553\n",
      "  Recall: 0.5534591194968553\n",
      "  F1-score: 0.5534591194968553\n",
      "Experiment 8:\n",
      "  Accuracy: 0.6132075471698113\n",
      "  Precision: 0.6132075471698113\n",
      "  Recall: 0.6132075471698113\n",
      "  F1-score: 0.6132075471698113\n",
      "Experiment 9:\n",
      "  Accuracy: 0.7421383647798742\n",
      "  Precision: 0.7436708860759493\n",
      "  Recall: 0.7421383647798742\n",
      "  F1-score: 0.7429038350769561\n",
      "Experiment 10:\n",
      "  Accuracy: 0.8805031446540881\n",
      "  Precision: 0.8805031446540881\n",
      "  Recall: 0.8805031446540881\n",
      "  F1-score: 0.8805031446540881\n",
      "Experiment 11:\n",
      "  Accuracy: 0.5534591194968553\n",
      "  Precision: 0.5534591194968553\n",
      "  Recall: 0.5534591194968553\n",
      "  F1-score: 0.5534591194968553\n",
      "Experiment 12:\n",
      "  Accuracy: 0.7484276729559748\n",
      "  Precision: 0.7484276729559748\n",
      "  Recall: 0.7484276729559748\n",
      "  F1-score: 0.7484276729559748\n",
      "Experiment 13:\n",
      "  Accuracy: 0.8176100628930818\n",
      "  Precision: 0.8176100628930818\n",
      "  Recall: 0.8176100628930818\n",
      "  F1-score: 0.8176100628930818\n",
      "Experiment 14:\n",
      "  Accuracy: 0.5534591194968553\n",
      "  Precision: 0.5534591194968553\n",
      "  Recall: 0.5534591194968553\n",
      "  F1-score: 0.5534591194968553\n",
      "Experiment 15:\n",
      "  Accuracy: 0.6918238993710691\n",
      "  Precision: 0.6918238993710691\n",
      "  Recall: 0.6918238993710691\n",
      "  F1-score: 0.6918238993710691\n",
      "Experiment 16:\n",
      "  Accuracy: 0.8710691823899371\n",
      "  Precision: 0.8870967741935484\n",
      "  Recall: 0.8710691823899371\n",
      "  F1-score: 0.8790099238402954\n",
      "Experiment 17:\n",
      "  Accuracy: 0.7861635220125787\n",
      "  Precision: 0.8823529411764706\n",
      "  Recall: 0.7861635220125787\n",
      "  F1-score: 0.8314855875831486\n",
      "Experiment 18:\n",
      "  Accuracy: 0.5408805031446541\n",
      "  Precision: 0.576271186440678\n",
      "  Recall: 0.5408805031446541\n",
      "  F1-score: 0.5580152671755725\n",
      "Experiment 19:\n",
      "  Accuracy: 0.5534591194968553\n",
      "  Precision: 0.5534591194968553\n",
      "  Recall: 0.5534591194968553\n",
      "  F1-score: 0.5534591194968553\n",
      "Experiment 20:\n",
      "  Accuracy: 0.720125786163522\n",
      "  Precision: 0.7890909090909091\n",
      "  Recall: 0.720125786163522\n",
      "  F1-score: 0.7530326334851228\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for DeepSetV2:\")\n",
    "for i in range(len(deepsetv2_accuracies)):\n",
    "    print(f\"Experiment {i + 1}:\")\n",
    "    print(f\"  Accuracy: {deepsetv2_accuracies[i]['Overall']}\")\n",
    "    print(f\"  Precision: {deepsetv2_precisions[i]['Overall']}\")\n",
    "    print(f\"  Recall: {deepsetv2_recalls[i]['Overall']}\")\n",
    "    print(f\"  F1-score: {deepsetv2_f1Scores[i]['Overall']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_7728\\2598404065.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.7295597484276729\n",
      "2 / 20 models trained | Current model test accuracy: 0.7484276729559748\n",
      "3 / 20 models trained | Current model test accuracy: 0.7264150943396226\n",
      "4 / 20 models trained | Current model test accuracy: 0.6572327044025157\n",
      "5 / 20 models trained | Current model test accuracy: 0.660377358490566\n",
      "6 / 20 models trained | Current model test accuracy: 0.6729559748427673\n",
      "7 / 20 models trained | Current model test accuracy: 0.7578616352201258\n",
      "8 / 20 models trained | Current model test accuracy: 0.7389937106918238\n",
      "9 / 20 models trained | Current model test accuracy: 0.6509433962264151\n",
      "10 / 20 models trained | Current model test accuracy: 0.7044025157232704\n",
      "11 / 20 models trained | Current model test accuracy: 0.6855345911949685\n",
      "12 / 20 models trained | Current model test accuracy: 0.7955974842767296\n",
      "13 / 20 models trained | Current model test accuracy: 0.7138364779874213\n",
      "14 / 20 models trained | Current model test accuracy: 0.7389937106918238\n",
      "15 / 20 models trained | Current model test accuracy: 0.6729559748427673\n",
      "16 / 20 models trained | Current model test accuracy: 0.7735849056603774\n",
      "17 / 20 models trained | Current model test accuracy: 0.7138364779874213\n",
      "18 / 20 models trained | Current model test accuracy: 0.7075471698113207\n",
      "19 / 20 models trained | Current model test accuracy: 0.7264150943396226\n",
      "20 / 20 models trained | Current model test accuracy: 0.6194968553459119\n",
      "CPU times: total: 7min 29s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feedforward_accuracies, feedforward_precisions, feedforward_recalls, feedforward_f1Scores, feedforward_wrong_preds, feedforward_epoch_stats = train_models(FEEDFORWARD_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 128, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FeedForward:\n",
      "Experiment 1:\n",
      "  Accuracy: 0.7295597484276729\n",
      "  Precision: 0.7356687898089171\n",
      "  Recall: 0.7295597484276729\n",
      "  F1-score: 0.7326015337716838\n",
      "Experiment 2:\n",
      "  Accuracy: 0.7484276729559748\n",
      "  Precision: 0.7694805194805194\n",
      "  Recall: 0.7484276729559748\n",
      "  F1-score: 0.7588080984731284\n",
      "Experiment 3:\n",
      "  Accuracy: 0.7264150943396226\n",
      "  Precision: 0.7508196721311475\n",
      "  Recall: 0.7264150943396226\n",
      "  F1-score: 0.7384157959756276\n",
      "Experiment 4:\n",
      "  Accuracy: 0.6572327044025157\n",
      "  Precision: 0.6666666666666666\n",
      "  Recall: 0.6572327044025157\n",
      "  F1-score: 0.6619160728424386\n",
      "Experiment 5:\n",
      "  Accuracy: 0.660377358490566\n",
      "  Precision: 0.6698717948717948\n",
      "  Recall: 0.660377358490566\n",
      "  F1-score: 0.6650906941855707\n",
      "Experiment 6:\n",
      "  Accuracy: 0.6729559748427673\n",
      "  Precision: 0.6815286624203821\n",
      "  Recall: 0.6729559748427673\n",
      "  F1-score: 0.6772151898734177\n",
      "Experiment 7:\n",
      "  Accuracy: 0.7578616352201258\n",
      "  Precision: 0.7717041800643086\n",
      "  Recall: 0.7578616352201258\n",
      "  F1-score: 0.7647202702434703\n",
      "Experiment 8:\n",
      "  Accuracy: 0.7389937106918238\n",
      "  Precision: 0.760655737704918\n",
      "  Recall: 0.7389937106918238\n",
      "  F1-score: 0.7496682731641583\n",
      "Experiment 9:\n",
      "  Accuracy: 0.6509433962264151\n",
      "  Precision: 0.662379421221865\n",
      "  Recall: 0.6509433962264151\n",
      "  F1-score: 0.6566116179697425\n",
      "Experiment 10:\n",
      "  Accuracy: 0.7044025157232704\n",
      "  Precision: 0.7115384615384616\n",
      "  Recall: 0.7044025157232704\n",
      "  F1-score: 0.7079525070470659\n",
      "Experiment 11:\n",
      "  Accuracy: 0.6855345911949685\n",
      "  Precision: 0.6967741935483871\n",
      "  Recall: 0.6855345911949685\n",
      "  F1-score: 0.6911086975665599\n",
      "Experiment 12:\n",
      "  Accuracy: 0.7955974842767296\n",
      "  Precision: 0.8038585209003215\n",
      "  Recall: 0.7955974842767296\n",
      "  F1-score: 0.7997066688582212\n",
      "Experiment 13:\n",
      "  Accuracy: 0.7138364779874213\n",
      "  Precision: 0.7151898734177216\n",
      "  Recall: 0.7138364779874213\n",
      "  F1-score: 0.7145125348189415\n",
      "Experiment 14:\n",
      "  Accuracy: 0.7389937106918238\n",
      "  Precision: 0.7483870967741936\n",
      "  Recall: 0.7389937106918238\n",
      "  F1-score: 0.7436607422967277\n",
      "Experiment 15:\n",
      "  Accuracy: 0.6729559748427673\n",
      "  Precision: 0.6805111821086262\n",
      "  Recall: 0.6729559748427673\n",
      "  F1-score: 0.6767124914635232\n",
      "Experiment 16:\n",
      "  Accuracy: 0.7735849056603774\n",
      "  Precision: 0.7986798679867987\n",
      "  Recall: 0.7735849056603774\n",
      "  F1-score: 0.7859321161234107\n",
      "Experiment 17:\n",
      "  Accuracy: 0.7138364779874213\n",
      "  Precision: 0.7322580645161291\n",
      "  Recall: 0.7138364779874213\n",
      "  F1-score: 0.7229299363057324\n",
      "Experiment 18:\n",
      "  Accuracy: 0.7075471698113207\n",
      "  Precision: 0.717948717948718\n",
      "  Recall: 0.7075471698113207\n",
      "  F1-score: 0.7127099949092143\n",
      "Experiment 19:\n",
      "  Accuracy: 0.7264150943396226\n",
      "  Precision: 0.7475083056478405\n",
      "  Recall: 0.7264150943396226\n",
      "  F1-score: 0.7368107682820507\n",
      "Experiment 20:\n",
      "  Accuracy: 0.6194968553459119\n",
      "  Precision: 0.6194968553459119\n",
      "  Recall: 0.6194968553459119\n",
      "  F1-score: 0.6194968553459119\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for FeedForward:\")\n",
    "for i in range(len(feedforward_accuracies)):\n",
    "    print(f\"Experiment {i + 1}:\")\n",
    "    print(f\"  Accuracy: {feedforward_accuracies[i]['Overall']}\")\n",
    "    print(f\"  Precision: {feedforward_precisions[i]['Overall']}\")\n",
    "    print(f\"  Recall: {feedforward_recalls[i]['Overall']}\")\n",
    "    print(f\"  F1-score: {feedforward_f1Scores[i]['Overall']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best 50% performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_half = int(num_experiments / 2)\n",
    "best_cnn_accs = filter_top_k_accuracies(cnn_accuracies, top_half)\n",
    "best_lstm_accs = filter_top_k_accuracies(lstm_accuracies, top_half)\n",
    "best_deepset_accs = filter_top_k_accuracies(deepset_accuracies, top_half)\n",
    "best_deepsetv2_accs = filter_top_k_accuracies(deepsetv2_accuracies, top_half)\n",
    "best_feedforward_accs = filter_top_k_accuracies(feedforward_accuracies, top_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy breakdown by cases for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracies = [cnn_accuracies, lstm_accuracies, deepset_accuracies, deepsetv2_accuracies, feedforward_accuracies]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_df(all_accuracies, model_names, test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy breakdown by cases for top 50% of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracies = [best_cnn_accs, best_lstm_accs, best_deepset_accs, best_deepsetv2_accs, best_feedforward_accs]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']\n",
    "collapsed_cases = ['dr', 'r', 'cr', 'noop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_df(best_accuracies, model_names, test_original, collapsed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracies = [best_cnn_accs, best_lstm_accs, best_deepset_accs, best_deepsetv2_accs, best_feedforward_accs]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']\n",
    "collapsed_cases = ['r', 'cr', 'noop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_df(best_accuracies, model_names, test_original, collapsed_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(cnn_accuracies, ['CNN #' + str(i) for i in range(len(cnn_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(lstm_accuracies, ['LSTM #' + str(i) for i in range(len(lstm_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per DeepSets V1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(deepset_accuracies, ['DeepSet(like in paper) #' + str(i) for i in range(len(deepset_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per DeepSets V2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(deepsetv2_accuracies, ['DeepSet(sum at start) #' + str(i) for i in range(len(deepsetv2_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per FeedForward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(feedforward_accuracies, ['Feedforward #' + str(i) for i in range(len(feedforward_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(cnn_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(lstm_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSets V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(deepset_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSets V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(deepsetv2_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(feedforward_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_model = LSTM_Model(data, 16, 32, 8).to(device)\n",
    "best_lstm_model.load_state_dict(torch.load('best_LSTM_model_' + experiment_name))\n",
    "best_cnn_model = CNN_Model(data, 64, 128, 4, -1,).to(device)\n",
    "best_cnn_model.load_state_dict(torch.load('best_CNN_model_' + experiment_name))\n",
    "best_deepset_model = DEEPSET_Model(data).to(device)\n",
    "best_deepset_model.load_state_dict(torch.load('best_DEEPSET_model_' + experiment_name))\n",
    "best_deepsetv2_model = DEEPSETV2_Model(data, 16, 8).to(device)\n",
    "best_deepsetv2_model.load_state_dict(torch.load('best_DEEPSETV2_model_' + experiment_name))\n",
    "best_feedforward_model = FEEDFORWARD_Model(data).to(device)\n",
    "best_feedforward_model.load_state_dict(torch.load('best_FEEDFORWARD_model_' + experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_cnn_model, x_test_cnn, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_lstm_model, x_test_lstm, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing DeepSets V1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_deepset_model, x_test_normal, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing DeepSets V2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_deepsetv2_model, x_test_normal, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing Feedforward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_feedforward_model, x_test_normal, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Notebook State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('notebook_env_' + experiment_name + '.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Notebook State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "experiment_name = \"25per\"\n",
    "# dill.load_session('notebook_env_' + experiment_name + '.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
