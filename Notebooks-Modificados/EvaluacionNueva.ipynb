{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c36cf9a",
   "metadata": {},
   "source": [
    "#### Generamos una modificacion de one_hot_encoding para que no salte error de que no hay clase R, D, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2964a8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Atomicity violation cases wrong predicted:\n",
      "Sample [',.,_,,_,_,._.,_', '..........w..u.', '_r___d_________'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '.........wu....', '_________r___d_'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '...w.u.........', '_r_d___________'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '....w...u......', '____r__d_______'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '.......w...u...', 'rd_____________'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '......w...u....', '__________r___d'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '..wu...........', '______r__d_____'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '..........w...u', '______rd_______'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '.w...u.........', '__r__d_________'] | Prediction V\n",
      "Sample [',.,_,,_,_,._.,_', '......wu.......', '________r___d__'] | Prediction V\n",
      "\n",
      "\n",
      "0 DeadLock cases wrong predicted:\n",
      "\n",
      "\n",
      "0 Data race cases wrong predicted:\n",
      "\n",
      "\n",
      "0 Valid cases wrong predicted:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_2560\\3134426830.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load('./bestmodels/best_LSTM_model_' + experiment_name, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'if wrong_preds:\\n    df = pd.DataFrame(wrong_preds, columns=[\\'f1\\', \\'f2\\', \\'f3\\', \\'expected\\', \\'predicted\\'])\\n    df.to_csv(\\'errores_violaciones_atomicidad.csv\\', index=False)\\n    print(\"üîÅ Errores exportados a errores_violaciones_atomicidad.csv\")\\nelse:\\n    print(\"‚úÖ El modelo clasific√≥ correctamente todas las muestras.\")\\n    '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from generate_data import Data\n",
    "from evaluate import get_wrong_predictions_bycases, print_wrong_preds_bycases\n",
    "from models import LSTM_Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paso 1: Inicializar generador de datos\n",
    "data = Data(layer_size=15, interop_distances=[0], permutation_intervals=1)\n",
    "\n",
    "# Paso 2: Generar muestras con f2='wu' y f3='rd'\n",
    "def generate_atomicity_samples_rd(n=10):\n",
    "    layer_size = 15\n",
    "    base_f1 = ',.,_,,_,_,._.,__'\n",
    "    base_f1 = base_f1[:layer_size].ljust(layer_size, '.')  # asegurar longitud\n",
    "    samples = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        f2 = ['.'] * layer_size\n",
    "        pos_w = random.randint(0, layer_size - 5)\n",
    "        pos_u = min(pos_w + 1 + random.randint(0, 3), layer_size - 1)\n",
    "        f2[pos_w] = 'w'\n",
    "        f2[pos_u] = 'u'\n",
    "        f2 = ''.join(f2)\n",
    "\n",
    "        f3 = ['_'] * layer_size\n",
    "        pos_r = random.randint(0, layer_size - 5)\n",
    "        pos_d = min(pos_r + 1 + random.randint(0, 3), layer_size - 1)\n",
    "        f3[pos_r] = 'r'\n",
    "        f3[pos_d] = 'd'\n",
    "        f3 = ''.join(f3)\n",
    "\n",
    "        samples.append([base_f1, f2, f3, 'A'])\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Paso 3: Generar muestras artificiales\n",
    "custom_samples = generate_atomicity_samples_rd(10)\n",
    "separated = data.separate_string_chars(custom_samples)\n",
    "\n",
    "# Paso 4: Forzar inclusi√≥n de todos los caracteres usados en el entrenamiento\n",
    "caracteres_entrenamiento = list(\".,_wurdc\")  # Aseg√∫rate de incluir todos los que se usaron\n",
    "layer_size = data.layer_size\n",
    "extra_samples = []\n",
    "\n",
    "for c in caracteres_entrenamiento:\n",
    "    f1 = c * layer_size\n",
    "    f2 = c * layer_size\n",
    "    f3 = c * layer_size\n",
    "    extra_samples.append([f1, f2, f3, 'A'])\n",
    "\n",
    "separated_extra = data.separate_string_chars(extra_samples)\n",
    "separated += separated_extra  # Inyectamos muestras de relleno\n",
    "\n",
    "# Paso 5: One-hot encoding\n",
    "one_hotted = data.one_hot_encode(separated)\n",
    "\n",
    "# Paso 6: Eliminar muestras de relleno\n",
    "one_hotted = one_hotted[:-len(extra_samples)]\n",
    "\n",
    "# Paso 7: Cargar modelo LSTM entrenado\n",
    "experiment_name = \"05per\"\n",
    "best_lstm_model = LSTM_Model(data, 16, 32, 8).to(device)\n",
    "best_lstm_model.load_state_dict(\n",
    "    torch.load('./bestmodels/best_LSTM_model_' + experiment_name, map_location=device)\n",
    ")\n",
    "best_lstm_model.eval()\n",
    "\n",
    "# Paso 8: Preparar datos para evaluaci√≥n\n",
    "x_test = data.to_lstm_format(one_hotted[:, :-1])\n",
    "y_test = torch.tensor([0] * len(custom_samples))  # 'A' = √≠ndice 0\n",
    "original_inputs = [s[:3] for s in custom_samples]\n",
    "\n",
    "# Paso 9: Evaluaci√≥n\n",
    "wrong_preds = get_wrong_predictions_bycases(best_lstm_model, x_test, y_test, original_inputs)\n",
    "print_wrong_preds_bycases(wrong_preds, k=10)\n",
    "\n",
    "# Paso 10: Guardar en CSV si hay errores\n",
    "\"\"\"if wrong_preds:\n",
    "    df = pd.DataFrame(wrong_preds, columns=['f1', 'f2', 'f3', 'expected', 'predicted'])\n",
    "    df.to_csv('errores_violaciones_atomicidad.csv', index=False)\n",
    "    print(\"üîÅ Errores exportados a errores_violaciones_atomicidad.csv\")\n",
    "else:\n",
    "    print(\"‚úÖ El modelo clasific√≥ correctamente todas las muestras.\")\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
