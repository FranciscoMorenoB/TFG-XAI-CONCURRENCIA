{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicaci칩n de Llava de los gr치ficos generados por las t칠cnicas XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting accelerate\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\franm\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.29.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: networkx in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\franm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2022.12.7)\n",
      "Downloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 345.1/345.1 kB 10.8 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.5.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llava para una explicaci칩n de SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 游녤 Ruta de la imagen (SHAP, LIME, ALE, etc.)\n",
    "image_path = \"./imagenes/SHAP_LSTM_CLASE_A.png\"  # Cambia la ruta si hace falta\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 游녤 Token de Hugging Face\n",
    "hf_token = \"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\"  # Sustituye esto por tu token real\n",
    "\n",
    "# 游녤 Cargar modelo LLaVA desde Hugging Face\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\", use_auth_token=hf_token)\n",
    "processor = AutoProcessor.from_pretrained(model_id, use_auth_token=hf_token)\n",
    "\n",
    "# 游녤 Pregunta con contexto para el gr치fico\n",
    "question = \"Este gr치fico fue generado por SHAP para explicar una predicci칩n sobre la clase 'A', que significa 'violacion de atomicidad'. En la imagen ves a que caracter칤stica se corresponde cada n칰mero. 쯈u칠 caracter칤sticas tienen m치s peso y menos peso para esta predicci칩n?\"\n",
    "\n",
    "# 游녤 Preparar inputs\n",
    "prompt = f\"<image>\\nUSER: {question}\\nASSISTANT:\"\n",
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# 游녤 Generar respuesta\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "# 游녤 Mostrar respuesta\n",
    "response = processor.batch_decode(output, skip_special_tokens=True)\n",
    "print(\"游 Respuesta de LLaVA:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llava para una explicaci칩n de LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 游녤 Ruta de la imagen (SHAP, LIME, ALE, etc.)\n",
    "image_path = \"./imagenes/LIME_CNN_CLASE_V.png\"  # Cambia la ruta si hace falta\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 游녤 Token de Hugging Face\n",
    "hf_token = \"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\"  # Sustituye esto por tu token real\n",
    "\n",
    "# 游녤 Cargar modelo LLaVA desde Hugging Face\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\", use_auth_token=hf_token)\n",
    "processor = AutoProcessor.from_pretrained(model_id, use_auth_token=hf_token)\n",
    "\n",
    "# 游녤 Pregunta con contexto para el gr치fico\n",
    "question = \"Este gr치fico fue generado por LIME para explicar la predicci칩n de una muestra de clase R en el modelo CNN. 쯈u칠 caracter칤sticas ayudan al modelo a predecir esta clase? Ten en cuenta que la muestra a predecir por el modelo sale en la parte superior de la imagen.\"\n",
    "\n",
    "# 游녤 Preparar inputs\n",
    "prompt = f\"<image>\\nUSER: {question}\\nASSISTANT:\"\n",
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# 游녤 Generar respuesta\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "# 游녤 Mostrar respuesta\n",
    "response = processor.batch_decode(output, skip_special_tokens=True)\n",
    "print(\"游 Respuesta de LLaVA:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llava para una explicaci칩n de ALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 游녤 Ruta de la imagen (SHAP, LIME, ALE, etc.)\n",
    "image_path = \"./imagenes/LIME_CNN_CLASE_V.png\"  # Cambia la ruta si hace falta\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 游녤 Token de Hugging Face\n",
    "hf_token = \"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\"  # Sustituye esto por tu token real\n",
    "\n",
    "# 游녤 Cargar modelo LLaVA desde Hugging Face\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\", use_auth_token=hf_token)\n",
    "processor = AutoProcessor.from_pretrained(model_id, use_auth_token=hf_token)\n",
    "\n",
    "# 游녤 Pregunta con contexto para el gr치fico\n",
    "question = \"En esta imagen se pueden ver 3 gr치ficas de ALE que representan el efecto acumulado de la caracter칤stica 'w' en la predicci칩n del modelo. En cada gr치fico se observa el efecto de la caracter칤stica en distintas posiciones de la muestra, teniendo en cuenta que hay 16 posiciones. En un gr치fico aparece en la posicion 1, en otro en la posicion 8, y en otro en la posicion 13, aunque esto se puede observar en la gr치fica. 쮺칩mo influye la posici칩n de 'w' en las predicciones?\"\n",
    "\n",
    "# 游녤 Preparar inputs\n",
    "prompt = f\"<image>\\nUSER: {question}\\nASSISTANT:\"\n",
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# 游녤 Generar respuesta\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "# 游녤 Mostrar respuesta\n",
    "response = processor.batch_decode(output, skip_special_tokens=True)\n",
    "print(\"游 Respuesta de LLaVA:\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
