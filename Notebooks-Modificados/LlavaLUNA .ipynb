{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicación de Llava de los gráficos generados por las técnicas XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Luna Santos\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoProcessor, LlavaNextForConditionalGeneration\n",
    "from PIL import Image\n",
    "from accelerate import dispatch_model\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.6\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llava para una explicación de SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a689c357ee4b79a491dc01c25bc33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "# Nombre del modelo en Hugging Face\n",
    "model_name = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "\n",
    "# Cargar el modelo y el procesador de imágenes\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\", device_map=\"auto\", torch_dtype=torch.float16, low_cpu_mem_usage=True) \n",
    "\n",
    "# Imagen a analizar (gráfico)\n",
    "image = Image.open(\"./imagenes/SHAP-V-lstm_cnn.png\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contexto personalizado para mejorar la respuesta\n",
    "context_and_question= (\n",
    "    \"Tenemos una imagen en la que aparecen un conjunto de 10 muestras y dos graficos para los modelos LSTM y CNN\"  \n",
    "    \"Los graficos han sido generados por Shap, una tecnica de explicabilidad aplicada a los modelos de clasificacion\"\n",
    "    \"Cada muestra está compuesta por secuencias de caracteres, donde cada carácter representa una operación específica.\" \n",
    "    \"Las características extraídas representan la presencia o posición de estos caracteres en la muestra\"\n",
    "    \"El objetivo de los modelos es clasificar correctamente cada muestra en una de varias clases (A, V, D, R) dependiendo de los patrones que contenga la muestra. \"\n",
    "    \"El modelo predice el tipo de error: Condición de carrera (D) cuando ocurre las secuencias: no-opsr, wr, uwr, wur. DeadLock (D) cuando ocurre wdr, no-opsdr. \"\n",
    "    \"Violación de atomicidad (A) cuando ocurre: uwdr. EL resto de combinaciones que admite la gramatica son V\"\n",
    "    \"Shap genera un grafico que muestra que muestra cómo cada característica influye en las predicciones del modelo\"\n",
    "    \"Eje Y: Lista de características. Las más influyentes están arriba.\"\n",
    "    \"Cada caracteristica es representada con una tupla de tres posiciones (Funcion, posicion, operacion) \"\n",
    "    \"Donde por ejemplo \"\"f3-4-c\"\" es la caracteristica que representa la operacion \"\"c\"\", en la posicion cuarta(4), de la funcion 3 (f3)\"\n",
    "    \"Eje X: Valores SHAP, que indican el impacto de cada característica en la predicción del modelo.\"\n",
    "    \"Valores SHAP positivos: La característica aumenta la probabilidad de que la muestra sea clasificada en esa clase.\"\n",
    "    \"Valores SHAP negativos: La característica reduce la probabilidad de que la muestra sea clasificada en esa clase.\"\n",
    "    \"Colores: Rojo: Valores altos de la característica. Azul: Valores bajos de la característica.\"\n",
    "    \"Los graficos de la imagen corresponden a la clase V\"\n",
    "\n",
    "    \"Según las gráficas SHAP de la imagen, ¿qué operaciones tienen mayor impacto en la predicción de la clase V en cada modelo (LSTM y CNN)? ¿Hay diferencias en cómo cada modelo interpreta estas operaciones?\"\n",
    "\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"<image>\\nUSER: {context_and_question}\\nASSISTANT:\"\n",
    "# Procesar la imagen y el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juand\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\juand\\anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32000, 32000,  ..., 28739,  3118,   521]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(image, prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Generar respuesta con opciones personalizadas\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=150,  # Máximo de tokens en la respuesta\n",
    "    temperature=0.3,  # Control de aleatoriedad (más bajo = más preciso)\n",
    "    top_p=0.9,  # Método de muestreo para respuestas variadas\n",
    "    repetition_penalty=1.2,  # Evita respuestas repetitivas\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nUSER: Tenemos una imagen en la que aparecen un conjunto de 10 muestras y dos graficos para los modelos LSTM y CNNLos graficos han sido generados por Shap, una tecnica de explicabilidad aplicada a los modelos de clasificacionCada muestra está compuesta por secuencias de caracteres, donde cada carácter representa una operación específica.Las características extraídas representan la presencia o posición de estos caracteres en la muestraEl objetivo de los modelos es clasificar correctamente cada muestra en una de varias clases (A, V, D, R) dependiendo de los patrones que contenga la muestra. El modelo predice el tipo de error: Condición de carrera (D) cuando ocurre las secuencias: no-opsr, wr, uwr, wur. DeadLock (D) cuando ocurre wdr, no-opsdr. Violación de atomicidad (A) cuando ocurre: uwdr. EL resto de combinaciones que admite la gramatica son VShap genera un grafico que muestra que muestra cómo cada característica influye en las predicciones del modeloEje Y: Lista de características. Las más influyentes están arriba.Cada caracteristica es representada con una tupla de tres posiciones (Funcion, posicion, operacion) Donde por ejemplo f3-4-c es la caracteristica que representa la operacion c, en la posicion cuarta(4), de la funcion 3 (f3)Eje X: Valores SHAP, que indican el impacto de cada característica en la predicción del modelo.Valores SHAP positivos: La característica aumenta la probabilidad de que la muestra sea clasificada en esa clase.Valores SHAP negativos: La característica reduce la probabilidad de que la muestra sea clasificada en esa clase.Colores: Rojo: Valores altos de la característica. Azul: Valores bajos de la característica.Los graficos de la imagen corresponden a la clase VSegún las gráficas SHAP de la imagen, ¿qué operaciones tienen mayor impacto en la predicción de la clase V en cada modelo (LSTM y CNN)? ¿Hay diferencias en cómo cada modelo interpreta estas operaciones?\\nASSISTANT: En la imagen proporcionada, se pueden observar algunas operaciones que tienen un gran impacto en la predicción de la clase \"V\" según los graficos SHAP correspondientes a los modelos LSTM y CNN. A continuación, te presento algunas de estas operaciones:\\n\\nEn el modelo LSTM:\\n- La operación \"wdr\" tiene un alto valor SHAP en ambos graficos, lo que significa que esta operación es muy importante para la predicción de la clase \"V\". Esto sugiere que este modelo considera la ubicación de la operación \"wdr\" como un']\n"
     ]
    }
   ],
   "source": [
    "# Decodificar y mostrar la respuesta\n",
    "answer = processor.batch_decode(output, skip_special_tokens=True)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
