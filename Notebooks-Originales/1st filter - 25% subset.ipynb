{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generate_data import Data\n",
    "from src.evaluate import *\n",
    "from src.models import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 703 ms\n",
      "Wall time: 757 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = Data(layer_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 992 train | 595 val | 2382 test\n",
      "CPU times: total: 359 ms\n",
      "Wall time: 355 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, val, test = data.get_splits(['random_subsample'], [[0.25, 0.75]])\n",
    "\n",
    "train_unshuffled = train.copy()\n",
    "np.random.shuffle(train)\n",
    "\n",
    "x_train, y_train = data.get_x_y(train)\n",
    "x_val, y_val = data.get_x_y(val)\n",
    "x_test, y_test = data.get_x_y(test)\n",
    "\n",
    "train_original = data.reverse_encoding(data.get_x_y(train_unshuffled)[0])\n",
    "val_original = data.reverse_encoding(x_val)\n",
    "test_original = data.reverse_encoding(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek at unshuffled train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[',,..,__._,.,._.,', '______.,_.uw._.,', '___..,__.__dr_._', True],\n",
       " [',___,,._,,.__.,.', '__._,__w__._,,,,', '_,.,,,.,_.dr_...', True],\n",
       " [',...__..,.,,,_..', '.,___.__.wu___.,', '._cr._..__,,,.,.', False],\n",
       " ['.,,._.._.,_,,,..', '_..__,,,.,.__.,,', ',_,._._,_,.r,,__', True],\n",
       " ['.__.,,.,,_.,___,', '_._,,,._..._,_,,', '._.,_dr.,,.._,__', True],\n",
       " [',,__,,_.___...,_', '_,__,_,_,,_._..,', '_,.,,cr.._,.._,.', False],\n",
       " ['.._...,.,._,,.,,', ',._,,.,,,.w_._.,', ',,.,,__.,.__,__,', False],\n",
       " ['._.,..._.._...._', '_,_...__.,,.wu,_', '_.._.,.._._,_,._', False],\n",
       " ['.._._,,_._,....,', '_....__,.,uw,_._', ',.,_,,.._,__r,,,', True],\n",
       " ['.,_..,,._,__.,,.', ',___,_.._,_,w.,_', ',,._,,..__,cr__.', False],\n",
       " [',..._.____.__,_,', '.,,,_wu_...,_,_,', '_..__,.__,.r....', True],\n",
       " [',,.,_,__.,.__.,_', '...,__.,.__._..,', '_,_....,,.cr,__,', False],\n",
       " ['._._..,,_,...._.', '_._._,wu_.,___..', '__,.._,_.,.,....', False],\n",
       " [',__,,_._.,.,.,,.', 'w._.,,_.._,_..._', '_...__.__..._._.', False],\n",
       " ['.,._.,._.,,__,..', '__._wu.,..,,__.,', '__,__._cr,.._,_.', False],\n",
       " ['__,,.,,,__.._,..', ',_.,.._,._.,uw._', '_.,__,,.,..,..__', False],\n",
       " [',_,,_.,__,,.__..', '_.,,.,_,uw,__...', '._...,_,.____..,', False],\n",
       " [',._...,,._,._,_.', ',.__,w_,_,__.,,,', ',,,.___,,_,__,__', False],\n",
       " ['._,,.._..,_.,..,', '_.,..,.__.,...wu', '.dr,_...__.,,_,,', False],\n",
       " ['...__.,..__._.._', '.....,_.,_,w_._,', ',..._.,_,,.cr,_,', False]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_original[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 56 | F2-uw 59 | F2-w 64 | F2-noop 65 | \n",
      "F3 cr:    F2-wu 56 | F2-uw 52 | F2-w 63 | F2-noop 51 | \n",
      "F3 r:    F2-wu 69 | F2-uw 49 | F2-w 67 | F2-noop 71 | \n",
      "F3 noop:    F2-wu 69 | F2-uw 54 | F2-w 75 | F2-noop 72 | \n",
      "\n",
      "Positive samples count: 444\n",
      "Total samples count: 992\n",
      "Positive class ratio: 0.4475806451612903\n"
     ]
    }
   ],
   "source": [
    "pos_train_ratio = get_stats_and_ratio(train_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek at test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.,_,__,,._..,.,.', ',_uw__.,,___,...', ',,_,,_.__,._____', False],\n",
       " ['_..,.____.,,.,,_', ',.,......,.,_.,.', ',,,..._,_dr,_,,,', True],\n",
       " ['.,_,,__.,..___._', '__.,_,..,_,.._,,', ',.,..._,..,,,,,.', False],\n",
       " ['__,._.,..,,__...', '_._.w..,..__,...', '_____,..,.,...dr', True],\n",
       " ['.___,,,_,_.._,..', ',____,.,._w____.', '_.cr,....,,.__,.', False],\n",
       " ['.,,..,__._..,_._', '__wu.,._,.,__.._', '_cr...,__.,,,,..', False],\n",
       " [',.__,.,_..._,.,,', ',_,.,,_,_.,_,wu_', ',,._,._,_r,,,,._', True],\n",
       " [',.,.._..,,,.,.__', '_,._uw____,_,__.', '_._...,_,_,r._._', True],\n",
       " [',_,,,,,.__...___', ',_._.,,uw_,_,,,_', '.r,_..__,..,,._.', True],\n",
       " ['.,_.,__..___._..', ',._._,uw___..,__', '__...,.__.r_._..', True],\n",
       " ['_,,,,,_._,,,,..,', ',_,_,_..,..wu__,', '_,..__cr..,,._.,', False],\n",
       " ['._,_,_,._,__,_..', '__...,_._..__,wu', '..,_,__...,__,_.', False],\n",
       " ['_._,,,.....,.,._', ',_.,uw.,__,,...,', ',..,.,_..__..,.r', True],\n",
       " [',.,,..,,__,._._.', '.,wu._,_____..._', '.,r.___,..._,,..', True],\n",
       " ['__.,_._,,.,_.._.', ',_.__,__.,,wu,_.', '.,_.,.dr.._.,,._', False]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_original[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 140 | F2-uw 133 | F2-w 138 | F2-noop 160 | \n",
      "F3 cr:    F2-wu 139 | F2-uw 142 | F2-w 145 | F2-noop 151 | \n",
      "F3 r:    F2-wu 132 | F2-uw 149 | F2-w 151 | F2-noop 154 | \n",
      "F3 noop:    F2-wu 148 | F2-uw 173 | F2-w 162 | F2-noop 165 | \n",
      "\n",
      "Positive samples count: 1017\n",
      "Total samples count: 2382\n",
      "Positive class ratio: 0.4269521410579345\n"
     ]
    }
   ],
   "source": [
    "pos_test_ratio = get_stats_and_ratio(test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peek at val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[',,,__..__.____,.', 'w___,_._,,.__,,.', '...__,.cr.,,__,.', False],\n",
       " [',_..._,_._._,,,.', '_.._._.uw..,,_,_', '_.,,_._.,,.,_cr_', False],\n",
       " ['.___.,_.__,.,_.,', '_,,.._.,._..w_.,', '..,_..__.,__.r,.', True],\n",
       " ['._,.,,.._,_,.,_,', '.,,uw_.._.....,.', ',.,,,,.r.,,_..._', True],\n",
       " ['_..,_.,_,_._,,,,', '__.,,_.uw,,,,..,', '.__.,cr,.,.__..,', False],\n",
       " ['_,,._._....,,,_,', ',,_._w._._.__,_,', '_._.r,_..,,.,__,', True],\n",
       " ['..__.,_,____,._,', '.,_.w,,,_._,_,__', ',.,.,.,..__._cr,', False],\n",
       " ['.,._.,_..,_,,,_,', ',_.._._.____wu__', '.,_,r_.,,_,_.__.', True],\n",
       " ['._,._,_,,,___,.,', '..___,___uw.,__.', ',.,....,,_dr,_,_', True],\n",
       " ['..,.__.__,,_,___', '____,__._.,uw__.', ',__.,_cr___._,_.', False],\n",
       " ['___...,____,,__.', '_,,..._,___,__,.', '.,_,,._._,.,..cr', False],\n",
       " [',,._,.,.,_...,_,', 'wu__,._.,____,,,', ',.__,.._.,__,,,r', True],\n",
       " ['__.,._,,.______,', '.w..._.._.,_..__', ',.,_dr,._,_,.,._', True],\n",
       " [',..,,,__...,,,,,', ',,__._,,,._,,.,_', '_.___..__....,__', False],\n",
       " ['_,.._,_,_,.,,,,,', '..,_.._,..,._,,,', 'r._,.__._,..,,,.', True]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_original[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 29 | F2-uw 33 | F2-w 38 | F2-noop 30 | \n",
      "F3 cr:    F2-wu 30 | F2-uw 31 | F2-w 32 | F2-noop 53 | \n",
      "F3 r:    F2-wu 39 | F2-uw 42 | F2-w 38 | F2-noop 47 | \n",
      "F3 noop:    F2-wu 38 | F2-uw 28 | F2-w 35 | F2-noop 52 | \n",
      "\n",
      "Positive samples count: 267\n",
      "Total samples count: 595\n",
      "Positive class ratio: 0.44873949579831934\n"
     ]
    }
   ],
   "source": [
    "pos_val_ratio = get_stats_and_ratio(val_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send label arrays to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.from_numpy(y_train.astype(float)).float().to(device)\n",
    "y_val = torch.from_numpy(y_val.astype(float)).float().to(device)\n",
    "y_test = torch.from_numpy(y_test.astype(float)).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data in normal format (same as CNN format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normal = data.to_conv_format(x_train)\n",
    "x_val_normal = data.to_conv_format(x_val)\n",
    "x_test_normal = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_normal)):\n",
    "    x_train_normal[i] = x_train_normal[i].to(device)\n",
    "    x_val_normal[i] = x_val_normal[i].to(device)\n",
    "    x_test_normal[i] = x_test_normal[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_normal[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data in convolutional format, send to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = data.to_conv_format(x_train)\n",
    "x_val_cnn = data.to_conv_format(x_val)\n",
    "x_test_cnn = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_cnn)):\n",
    "    x_train_cnn[i] = x_train_cnn[i].to(device)\n",
    "    x_val_cnn[i] = x_val_cnn[i].to(device)\n",
    "    x_test_cnn[i] = x_test_cnn[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cnn[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data in LSTM format, send to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = data.to_lstm_format(x_train)\n",
    "x_val_lstm = data.to_lstm_format(x_val)\n",
    "x_test_lstm = data.to_lstm_format(x_test)\n",
    "for i in range(len(x_train_lstm)):\n",
    "    x_train_lstm[i] = x_train_lstm[i].to(device)\n",
    "    x_val_lstm[i] = x_val_lstm[i].to(device)\n",
    "    x_test_lstm[i] = x_test_lstm[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992, 16, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lstm[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 20\n",
    "epochs = 200\n",
    "early_stopping_limit = 100\n",
    "\n",
    "experiment_name = \"25per\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training procedure for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(constructor, x_train, x_val, x_test, weight_decay, *argv):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    wrong_preds = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        model = constructor(*argv)\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "        train_losses.append([])\n",
    "        val_losses.append([])\n",
    "        train_accs.append([])\n",
    "        val_accs.append([])\n",
    "        \n",
    "        best_acc = 0\n",
    "\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = train_epoch(model, x_train, y_train, criterion, optimizer, epoch, 10, verbose=False)\n",
    "            val_loss, val_acc = eval_epoch(model, x_val, y_val, criterion, 'Validation', verbose=False)\n",
    "\n",
    "            \n",
    "            train_losses[-1].append(train_loss)\n",
    "            val_losses[-1].append(val_loss)\n",
    "            train_accs[-1].append(train_acc)\n",
    "            val_accs[-1].append(val_acc)\n",
    "            \n",
    "            model_name = constructor.__name__[:constructor.__name__.find('_')]\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'./{model_name}_model_TEMP_' + experiment_name)    \n",
    "                early_stopping_cnt = 0\n",
    "            else:\n",
    "                early_stopping_cnt += 1\n",
    "\n",
    "            if early_stopping_cnt >= early_stopping_limit:\n",
    "                break\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n",
    "    \n",
    "        accuracies.append(get_accuracy_by_cases(model, x_test, y_test, test_original))\n",
    "        precisions.append(get_precision_by_cases(model, x_test, y_test, test_original))\n",
    "        recalls.append(get_recall_by_cases(model, x_test, y_test, test_original))\n",
    "        f1_scores.append(get_f1_by_cases(precisions[-1], recalls[-1]))\n",
    "        \n",
    "        wrong_preds.append((f\"Experimento {i}\", get_wrong_predictions(model, x_test, y_test, test_original)))\n",
    "\n",
    "        if accuracies[-1]['Overall'] > best_accuracy:\n",
    "            torch.save(model.state_dict(), f'./best_{model_name}_model_' + experiment_name)    \n",
    "            best_accuracy = accuracies[-1]['Overall']\n",
    "\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test accuracy:\", accuracies[-1]['Overall'])\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test precision:\", precisions[-1]['Overall'])\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test recall:\", recalls[-1]['Overall'])\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test f1:\", f1_scores[-1]['Overall'])\n",
    "\n",
    "\n",
    "    \n",
    "    return accuracies, precisions, recalls, f1_scores, wrong_preds, [train_losses, val_losses, train_accs, val_accs], model\n",
    "    #return accuracies, precisions, wrong_preds, [train_losses, val_losses, train_accs, val_accs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_21016\\1162859194.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.9395465994962217\n",
      "1 / 20 models trained | Current model test precision: 0.9008264462809917\n",
      "1 / 20 models trained | Current model test recall: 0.9646017699115044\n",
      "1 / 20 models trained | Current model test f1: 0.9316239316239316\n",
      "2 / 20 models trained | Current model test accuracy: 0.9403862300587741\n",
      "2 / 20 models trained | Current model test precision: 0.8847845206684257\n",
      "2 / 20 models trained | Current model test recall: 0.9891838741396264\n",
      "2 / 20 models trained | Current model test f1: 0.9340761374187558\n",
      "3 / 20 models trained | Current model test accuracy: 0.9416456759026028\n",
      "3 / 20 models trained | Current model test precision: 0.8810763888888888\n",
      "3 / 20 models trained | Current model test recall: 0.9980334316617503\n",
      "3 / 20 models trained | Current model test f1: 0.9359151682803135\n",
      "4 / 20 models trained | Current model test accuracy: 0.9408060453400504\n",
      "4 / 20 models trained | Current model test precision: 0.8808695652173913\n",
      "4 / 20 models trained | Current model test recall: 0.9960668633235005\n",
      "4 / 20 models trained | Current model test f1: 0.9349330872173511\n",
      "5 / 20 models trained | Current model test accuracy: 0.9403862300587741\n",
      "5 / 20 models trained | Current model test precision: 0.884108867427568\n",
      "5 / 20 models trained | Current model test recall: 0.9901671583087512\n",
      "5 / 20 models trained | Current model test f1: 0.9341372912801483\n",
      "6 / 20 models trained | Current model test accuracy: 0.9408060453400504\n",
      "6 / 20 models trained | Current model test precision: 0.8815331010452961\n",
      "6 / 20 models trained | Current model test recall: 0.9950835791543756\n",
      "6 / 20 models trained | Current model test f1: 0.9348729792147806\n",
      "7 / 20 models trained | Current model test accuracy: 0.9412258606213266\n",
      "7 / 20 models trained | Current model test precision: 0.904147465437788\n",
      "7 / 20 models trained | Current model test recall: 0.9646017699115044\n",
      "7 / 20 models trained | Current model test f1: 0.9333967649857279\n",
      "8 / 20 models trained | Current model test accuracy: 0.9387069689336692\n",
      "8 / 20 models trained | Current model test precision: 0.8871111111111111\n",
      "8 / 20 models trained | Current model test recall: 0.9813176007866273\n",
      "8 / 20 models trained | Current model test f1: 0.9318394024276377\n",
      "9 / 20 models trained | Current model test accuracy: 0.9391267842149454\n",
      "9 / 20 models trained | Current model test precision: 0.8927927927927928\n",
      "9 / 20 models trained | Current model test recall: 0.9744346116027532\n",
      "9 / 20 models trained | Current model test f1: 0.9318288669487541\n",
      "10 / 20 models trained | Current model test accuracy: 0.9412258606213266\n",
      "10 / 20 models trained | Current model test precision: 0.8856640281442393\n",
      "10 / 20 models trained | Current model test recall: 0.9901671583087512\n",
      "10 / 20 models trained | Current model test f1: 0.935004642525534\n",
      "11 / 20 models trained | Current model test accuracy: 0.9408060453400504\n",
      "11 / 20 models trained | Current model test precision: 0.88898756660746\n",
      "11 / 20 models trained | Current model test recall: 0.984267453294002\n",
      "11 / 20 models trained | Current model test f1: 0.9342043863742416\n",
      "12 / 20 models trained | Current model test accuracy: 0.9395465994962217\n",
      "12 / 20 models trained | Current model test precision: 0.8979033728350045\n",
      "12 / 20 models trained | Current model test recall: 0.9685349065880039\n",
      "12 / 20 models trained | Current model test f1: 0.9318826868495743\n",
      "13 / 20 models trained | Current model test accuracy: 0.9391267842149454\n",
      "13 / 20 models trained | Current model test precision: 0.8892857142857142\n",
      "13 / 20 models trained | Current model test recall: 0.9793510324483776\n",
      "13 / 20 models trained | Current model test f1: 0.9321478708469817\n",
      "14 / 20 models trained | Current model test accuracy: 0.9382871536523929\n",
      "14 / 20 models trained | Current model test precision: 0.904275092936803\n",
      "14 / 20 models trained | Current model test recall: 0.9567354965585054\n",
      "14 / 20 models trained | Current model test f1: 0.9297658862876254\n",
      "15 / 20 models trained | Current model test accuracy: 0.9382871536523929\n",
      "15 / 20 models trained | Current model test precision: 0.8870106761565836\n",
      "15 / 20 models trained | Current model test recall: 0.9803343166175025\n",
      "15 / 20 models trained | Current model test f1: 0.9313404950957496\n",
      "16 / 20 models trained | Current model test accuracy: 0.9416456759026028\n",
      "16 / 20 models trained | Current model test precision: 0.9042357274401474\n",
      "16 / 20 models trained | Current model test recall: 0.9655850540806293\n",
      "16 / 20 models trained | Current model test f1: 0.9339039467427483\n",
      "17 / 20 models trained | Current model test accuracy: 0.9374475230898405\n",
      "17 / 20 models trained | Current model test precision: 0.895264116575592\n",
      "17 / 20 models trained | Current model test recall: 0.9665683382497542\n",
      "17 / 20 models trained | Current model test f1: 0.9295508274231679\n",
      "18 / 20 models trained | Current model test accuracy: 0.9416456759026028\n",
      "18 / 20 models trained | Current model test precision: 0.8810763888888888\n",
      "18 / 20 models trained | Current model test recall: 0.9980334316617503\n",
      "18 / 20 models trained | Current model test f1: 0.9359151682803135\n",
      "19 / 20 models trained | Current model test accuracy: 0.9399664147774979\n",
      "19 / 20 models trained | Current model test precision: 0.9016544117647058\n",
      "19 / 20 models trained | Current model test recall: 0.9646017699115044\n",
      "19 / 20 models trained | Current model test f1: 0.9320665083135391\n",
      "20 / 20 models trained | Current model test accuracy: 0.9378673383711167\n",
      "20 / 20 models trained | Current model test precision: 0.8917944093778178\n",
      "20 / 20 models trained | Current model test recall: 0.9724680432645034\n",
      "20 / 20 models trained | Current model test f1: 0.9303857008466604\n",
      "CPU times: total: 5h 8min 20s\n",
      "Wall time: 1d 5h 10min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnn_accuracies, cnn_precisions, cnn_recall, cnn_f1, cnn_wrong_preds, cnn_epoch_stats, model = train_models(\n",
    "    CNN_Model, x_train_cnn, x_val_cnn, x_test_cnn, 0.0001, data, 64, 128, 4, -1, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_21016\\1162859194.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.998320738874895\n",
      "1 / 20 models trained | Current model test precision: 0.9970559371933267\n",
      "1 / 20 models trained | Current model test recall: 0.9990167158308751\n",
      "1 / 20 models trained | Current model test f1: 0.9980353634577603\n",
      "2 / 20 models trained | Current model test accuracy: 0.9412258606213266\n",
      "2 / 20 models trained | Current model test precision: 0.8789974070872947\n",
      "2 / 20 models trained | Current model test recall: 1.0\n",
      "2 / 20 models trained | Current model test f1: 0.9356025758969642\n",
      "3 / 20 models trained | Current model test accuracy: 1.0\n",
      "3 / 20 models trained | Current model test precision: 1.0\n",
      "3 / 20 models trained | Current model test recall: 1.0\n",
      "3 / 20 models trained | Current model test f1: 1.0\n",
      "4 / 20 models trained | Current model test accuracy: 0.9403862300587741\n",
      "4 / 20 models trained | Current model test precision: 0.8787878787878788\n",
      "4 / 20 models trained | Current model test recall: 0.9980334316617503\n",
      "4 / 20 models trained | Current model test f1: 0.9346224677716389\n",
      "5 / 20 models trained | Current model test accuracy: 1.0\n",
      "5 / 20 models trained | Current model test precision: 1.0\n",
      "5 / 20 models trained | Current model test recall: 1.0\n",
      "5 / 20 models trained | Current model test f1: 1.0\n",
      "6 / 20 models trained | Current model test accuracy: 0.9412258606213266\n",
      "6 / 20 models trained | Current model test precision: 0.8789974070872947\n",
      "6 / 20 models trained | Current model test recall: 1.0\n",
      "6 / 20 models trained | Current model test f1: 0.9356025758969642\n",
      "7 / 20 models trained | Current model test accuracy: 0.9412258606213266\n",
      "7 / 20 models trained | Current model test precision: 0.8789974070872947\n",
      "7 / 20 models trained | Current model test recall: 1.0\n",
      "7 / 20 models trained | Current model test f1: 0.9356025758969642\n",
      "8 / 20 models trained | Current model test accuracy: 0.9412258606213266\n",
      "8 / 20 models trained | Current model test precision: 0.8789974070872947\n",
      "8 / 20 models trained | Current model test recall: 1.0\n",
      "8 / 20 models trained | Current model test f1: 0.9356025758969642\n",
      "9 / 20 models trained | Current model test accuracy: 1.0\n",
      "9 / 20 models trained | Current model test precision: 1.0\n",
      "9 / 20 models trained | Current model test recall: 1.0\n",
      "9 / 20 models trained | Current model test f1: 1.0\n",
      "10 / 20 models trained | Current model test accuracy: 0.9328295549958019\n",
      "10 / 20 models trained | Current model test precision: 0.9255213505461768\n",
      "10 / 20 models trained | Current model test recall: 0.9164208456243854\n",
      "10 / 20 models trained | Current model test f1: 0.9209486166007905\n",
      "11 / 20 models trained | Current model test accuracy: 0.9374475230898405\n",
      "11 / 20 models trained | Current model test precision: 0.8847517730496454\n",
      "11 / 20 models trained | Current model test recall: 0.9813176007866273\n",
      "11 / 20 models trained | Current model test f1: 0.9305361305361306\n",
      "12 / 20 models trained | Current model test accuracy: 0.9991603694374476\n",
      "12 / 20 models trained | Current model test precision: 0.9980372914622179\n",
      "12 / 20 models trained | Current model test recall: 1.0\n",
      "12 / 20 models trained | Current model test f1: 0.9990176817288801\n",
      "13 / 20 models trained | Current model test accuracy: 1.0\n",
      "13 / 20 models trained | Current model test precision: 1.0\n",
      "13 / 20 models trained | Current model test recall: 1.0\n",
      "13 / 20 models trained | Current model test f1: 1.0\n",
      "14 / 20 models trained | Current model test accuracy: 1.0\n",
      "14 / 20 models trained | Current model test precision: 1.0\n",
      "14 / 20 models trained | Current model test recall: 1.0\n",
      "14 / 20 models trained | Current model test f1: 1.0\n",
      "15 / 20 models trained | Current model test accuracy: 1.0\n",
      "15 / 20 models trained | Current model test precision: 1.0\n",
      "15 / 20 models trained | Current model test recall: 1.0\n",
      "15 / 20 models trained | Current model test f1: 1.0\n",
      "16 / 20 models trained | Current model test accuracy: 0.9995801847187238\n",
      "16 / 20 models trained | Current model test precision: 1.0\n",
      "16 / 20 models trained | Current model test recall: 0.9990167158308751\n",
      "16 / 20 models trained | Current model test f1: 0.999508116084604\n",
      "17 / 20 models trained | Current model test accuracy: 0.9412258606213266\n",
      "17 / 20 models trained | Current model test precision: 0.8789974070872947\n",
      "17 / 20 models trained | Current model test recall: 1.0\n",
      "17 / 20 models trained | Current model test f1: 0.9356025758969642\n",
      "18 / 20 models trained | Current model test accuracy: 0.9995801847187238\n",
      "18 / 20 models trained | Current model test precision: 1.0\n",
      "18 / 20 models trained | Current model test recall: 0.9990167158308751\n",
      "18 / 20 models trained | Current model test f1: 0.999508116084604\n",
      "19 / 20 models trained | Current model test accuracy: 1.0\n",
      "19 / 20 models trained | Current model test precision: 1.0\n",
      "19 / 20 models trained | Current model test recall: 1.0\n",
      "19 / 20 models trained | Current model test f1: 1.0\n",
      "20 / 20 models trained | Current model test accuracy: 0.9995801847187238\n",
      "20 / 20 models trained | Current model test precision: 1.0\n",
      "20 / 20 models trained | Current model test recall: 0.9990167158308751\n",
      "20 / 20 models trained | Current model test f1: 0.999508116084604\n",
      "CPU times: total: 2h 14min 58s\n",
      "Wall time: 3d 1h 47min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lstm_accuracies, lstm_precision, lstm_recall, lstm_f1, lstm_wrong_preds, lstm_epoch_stats, model = train_models(LSTM_Model, x_train_lstm, x_val_lstm, x_test_lstm, 0.0001, data, 16, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_21016\\1162859194.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.9126784214945424\n",
      "1 / 20 models trained | Current model test precision: 0.8538932633420823\n",
      "1 / 20 models trained | Current model test recall: 0.95968534906588\n",
      "1 / 20 models trained | Current model test f1: 0.9037037037037037\n",
      "2 / 20 models trained | Current model test accuracy: 0.9311502938706969\n",
      "2 / 20 models trained | Current model test precision: 0.8731408573928259\n",
      "2 / 20 models trained | Current model test recall: 0.9813176007866273\n",
      "2 / 20 models trained | Current model test f1: 0.924074074074074\n",
      "3 / 20 models trained | Current model test accuracy: 0.8988245172124265\n",
      "3 / 20 models trained | Current model test precision: 0.8887775551102205\n",
      "3 / 20 models trained | Current model test recall: 0.872173058013766\n",
      "3 / 20 models trained | Current model test f1: 0.8803970223325063\n",
      "4 / 20 models trained | Current model test accuracy: 0.9282115869017632\n",
      "4 / 20 models trained | Current model test precision: 0.8763345195729537\n",
      "4 / 20 models trained | Current model test recall: 0.9685349065880039\n",
      "4 / 20 models trained | Current model test f1: 0.9201307800093413\n",
      "5 / 20 models trained | Current model test accuracy: 0.927791771620487\n",
      "5 / 20 models trained | Current model test precision: 0.8823529411764706\n",
      "5 / 20 models trained | Current model test recall: 0.9587020648967551\n",
      "5 / 20 models trained | Current model test f1: 0.9189443920829405\n",
      "6 / 20 models trained | Current model test accuracy: 0.9303106633081444\n",
      "6 / 20 models trained | Current model test precision: 0.8742304309586632\n",
      "6 / 20 models trained | Current model test recall: 0.9773844641101278\n",
      "6 / 20 models trained | Current model test f1: 0.9229340761374187\n",
      "7 / 20 models trained | Current model test accuracy: 0.9193954659949622\n",
      "7 / 20 models trained | Current model test precision: 0.8787878787878788\n",
      "7 / 20 models trained | Current model test recall: 0.9410029498525073\n",
      "7 / 20 models trained | Current model test f1: 0.9088319088319088\n",
      "8 / 20 models trained | Current model test accuracy: 0.8946263643996641\n",
      "8 / 20 models trained | Current model test precision: 0.8689788053949904\n",
      "8 / 20 models trained | Current model test recall: 0.8869223205506391\n",
      "8 / 20 models trained | Current model test f1: 0.8778588807785888\n",
      "9 / 20 models trained | Current model test accuracy: 0.9105793450881612\n",
      "9 / 20 models trained | Current model test precision: 0.8821292775665399\n",
      "9 / 20 models trained | Current model test recall: 0.9124877089478859\n",
      "9 / 20 models trained | Current model test f1: 0.8970517158047366\n",
      "10 / 20 models trained | Current model test accuracy: 0.9227539882451721\n",
      "10 / 20 models trained | Current model test precision: 0.8702222222222222\n",
      "10 / 20 models trained | Current model test recall: 0.9626352015732547\n",
      "10 / 20 models trained | Current model test f1: 0.9140989729225024\n",
      "11 / 20 models trained | Current model test accuracy: 0.9340890008396305\n",
      "11 / 20 models trained | Current model test precision: 0.8798586572438163\n",
      "11 / 20 models trained | Current model test recall: 0.9793510324483776\n",
      "11 / 20 models trained | Current model test f1: 0.9269427640763146\n",
      "12 / 20 models trained | Current model test accuracy: 0.9143576826196473\n",
      "12 / 20 models trained | Current model test precision: 0.8867745004757374\n",
      "12 / 20 models trained | Current model test recall: 0.9164208456243854\n",
      "12 / 20 models trained | Current model test f1: 0.9013539651837523\n",
      "13 / 20 models trained | Current model test accuracy: 0.9034424853064652\n",
      "13 / 20 models trained | Current model test precision: 0.8869223205506391\n",
      "13 / 20 models trained | Current model test recall: 0.8869223205506391\n",
      "13 / 20 models trained | Current model test f1: 0.8869223205506391\n",
      "14 / 20 models trained | Current model test accuracy: 0.9089000839630562\n",
      "14 / 20 models trained | Current model test precision: 0.8831417624521073\n",
      "14 / 20 models trained | Current model test recall: 0.9065880039331367\n",
      "14 / 20 models trained | Current model test f1: 0.8947113051916544\n",
      "15 / 20 models trained | Current model test accuracy: 0.9172963895885811\n",
      "15 / 20 models trained | Current model test precision: 0.8838951310861424\n",
      "15 / 20 models trained | Current model test recall: 0.928220255653884\n",
      "15 / 20 models trained | Current model test f1: 0.905515587529976\n",
      "16 / 20 models trained | Current model test accuracy: 0.9231738035264484\n",
      "16 / 20 models trained | Current model test precision: 0.8638743455497382\n",
      "16 / 20 models trained | Current model test recall: 0.9734513274336283\n",
      "16 / 20 models trained | Current model test f1: 0.9153952843273231\n",
      "17 / 20 models trained | Current model test accuracy: 0.9252728799328296\n",
      "17 / 20 models trained | Current model test precision: 0.8709106984969054\n",
      "17 / 20 models trained | Current model test recall: 0.9685349065880039\n",
      "17 / 20 models trained | Current model test f1: 0.9171322160148976\n",
      "18 / 20 models trained | Current model test accuracy: 0.9273719563392108\n",
      "18 / 20 models trained | Current model test precision: 0.8734513274336283\n",
      "18 / 20 models trained | Current model test recall: 0.9705014749262537\n",
      "18 / 20 models trained | Current model test f1: 0.9194224499301351\n",
      "19 / 20 models trained | Current model test accuracy: 0.5730478589420654\n",
      "19 / 20 models trained | Current model test precision: 0.0\n",
      "19 / 20 models trained | Current model test recall: 0.0\n",
      "19 / 20 models trained | Current model test f1: 0.0\n",
      "20 / 20 models trained | Current model test accuracy: 0.9034424853064652\n",
      "20 / 20 models trained | Current model test precision: 0.8751191611058151\n",
      "20 / 20 models trained | Current model test recall: 0.9026548672566371\n",
      "20 / 20 models trained | Current model test f1: 0.8886737657308809\n",
      "CPU times: total: 1h 43min 38s\n",
      "Wall time: 26min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepset_accuracies, deepset_procision, deepset_recall, deepset_f1, deepset_wrong_preds, deepset_epoch_stats, model = train_models(DEEPSET_Model, x_train_normal, x_val_normal, x_test_normal, 0.005, data, 128, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franm\\AppData\\Local\\Temp\\ipykernel_21016\\1162859194.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "1 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "1 / 20 models trained | Current model test recall: 1.0\n",
      "1 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "2 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "2 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "2 / 20 models trained | Current model test recall: 1.0\n",
      "2 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "3 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "3 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "3 / 20 models trained | Current model test recall: 1.0\n",
      "3 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "4 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "4 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "4 / 20 models trained | Current model test recall: 1.0\n",
      "4 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "5 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "5 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "5 / 20 models trained | Current model test recall: 1.0\n",
      "5 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "6 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "6 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "6 / 20 models trained | Current model test recall: 1.0\n",
      "6 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "7 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "7 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "7 / 20 models trained | Current model test recall: 1.0\n",
      "7 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "8 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "8 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "8 / 20 models trained | Current model test recall: 1.0\n",
      "8 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "9 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "9 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "9 / 20 models trained | Current model test recall: 1.0\n",
      "9 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "10 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "10 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "10 / 20 models trained | Current model test recall: 1.0\n",
      "10 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "11 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "11 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "11 / 20 models trained | Current model test recall: 1.0\n",
      "11 / 20 models trained | Current model test f1: 0.5984112974404237\n",
      "12 / 20 models trained | Current model test accuracy: 0.4269521410579345\n",
      "12 / 20 models trained | Current model test precision: 0.4269521410579345\n",
      "12 / 20 models trained | Current model test recall: 1.0\n",
      "12 / 20 models trained | Current model test f1: 0.5984112974404237\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepsetv2_accuracies, deepsetv2_procision, deepsetv2_recall, deepsetv2_f1, deepsetv2_wrong_preds, deepsetv2_epoch_stats, model = train_models(DEEPSETV2_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "feedforward_accuracies, feedforward_precision, feedforward_recall, feedforward_f1, feedforward_wrong_preds, feedforward_epoch_stats, model = train_models(FEEDFORWARD_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 128, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Lista de modelos y nombres\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet', 'DeepSetV2', 'Feedforward']\n",
    "all_accuracies = [cnn_accuracies, lstm_accuracies, deepset_accuracies, deepsetv2_accuracies, feedforward_accuracies]\n",
    "all_precisions = [cnn_precisions, lstm_precision, deepset_procision, deepsetv2_procision, feedforward_precision]\n",
    "all_recalls = [cnn_recall, lstm_recall, deepset_recall, deepsetv2_recall, feedforward_recall]\n",
    "all_f1_scores = [cnn_f1, lstm_f1, deepset_f1, deepsetv2_f1, feedforward_f1]\n",
    "\n",
    "imprimirMetricas(model_names, all_accuracies, all_precisions, all_recalls, all_f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best 50% performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_half = int(num_experiments / 2)\n",
    "best_cnn_accs = filter_top_k_accuracies(cnn_accuracies, top_half)\n",
    "best_lstm_accs = filter_top_k_accuracies(lstm_accuracies, top_half)\n",
    "best_deepset_accs = filter_top_k_accuracies(deepset_accuracies, top_half)\n",
    "best_deepsetv2_accs = filter_top_k_accuracies(deepsetv2_accuracies, top_half)\n",
    "best_feedforward_accs = filter_top_k_accuracies(feedforward_accuracies, top_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy breakdown by cases for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracies = [cnn_accuracies, lstm_accuracies, deepset_accuracies, deepsetv2_accuracies, feedforward_accuracies]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_df(all_accuracies, model_names, test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy breakdown by cases for top 50% of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracies = [best_cnn_accs, best_lstm_accs, best_deepset_accs, best_deepsetv2_accs, best_feedforward_accs]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']\n",
    "collapsed_cases = ['dr', 'r', 'cr', 'noop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_df(best_accuracies, model_names, test_original, collapsed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracies = [best_cnn_accs, best_lstm_accs, best_deepset_accs, best_deepsetv2_accs, best_feedforward_accs]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']\n",
    "collapsed_cases = ['r', 'cr', 'noop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_df(best_accuracies, model_names, test_original, collapsed_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(cnn_accuracies, ['CNN #' + str(i) for i in range(len(cnn_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(lstm_accuracies, ['LSTM #' + str(i) for i in range(len(lstm_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per DeepSets V1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(deepset_accuracies, ['DeepSet(like in paper) #' + str(i) for i in range(len(deepset_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per DeepSets V2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(deepsetv2_accuracies, ['DeepSet(sum at start) #' + str(i) for i in range(len(deepsetv2_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies per FeedForward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats_per_model(feedforward_accuracies, ['Feedforward #' + str(i) for i in range(len(feedforward_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(cnn_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(lstm_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSets V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(deepset_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSets V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(deepsetv2_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(feedforward_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_model = LSTM_Model(data, 16, 32, 8).to(device)\n",
    "best_lstm_model.load_state_dict(torch.load('best_LSTM_model_' + experiment_name))\n",
    "best_cnn_model = CNN_Model(data, 64, 128, 4, -1,).to(device)\n",
    "best_cnn_model.load_state_dict(torch.load('best_CNN_model_' + experiment_name))\n",
    "best_deepset_model = DEEPSET_Model(data).to(device)\n",
    "best_deepset_model.load_state_dict(torch.load('best_DEEPSET_model_' + experiment_name))\n",
    "best_deepsetv2_model = DEEPSETV2_Model(data, 16, 8).to(device)\n",
    "best_deepsetv2_model.load_state_dict(torch.load('best_DEEPSETV2_model_' + experiment_name))\n",
    "best_feedforward_model = FEEDFORWARD_Model(data).to(device)\n",
    "best_feedforward_model.load_state_dict(torch.load('best_FEEDFORWARD_model_' + experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_cnn_model, x_test_cnn, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_lstm_model, x_test_lstm, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing DeepSets V1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_deepset_model, x_test_normal, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing DeepSets V2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_deepsetv2_model, x_test_normal, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top wrong predictions for best performing Feedforward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds([get_wrong_predictions(best_feedforward_model, x_test_normal, y_test, test_original)], top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Notebook State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('notebook_env_' + experiment_name + '.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Notebook State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "experiment_name = \"25per\"\n",
    "# dill.load_session('notebook_env_' + experiment_name + '.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
