{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_data as vaina\n",
    "import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from evaluate import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos el conjunto de datos de entramiento y lo dividimos en 5% del subset para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 26 train | 100 val | 403 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luna Santos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Define el dispositivo que PyTorch usará para ejecutar los cálculos.\n",
    "\n",
    "data = vaina.Data(layer_size=6)\n",
    "train, val, test = data.get_splits(['random_subsample'], [[0.05, 0.95]]) #internamente onehot\n",
    "train_unshuffled = train.copy()\n",
    "np.random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function list.__sizeof__()>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos todos los datos en x (variables), y (clasificacion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data.get_x_y(train) #devuelve  self.np_data = self.one_hot_encode(self.samples_char_sep)\n",
    "x_val, y_val = data.get_x_y(val)\n",
    "x_test, y_test = data.get_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "       0.0], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]\n",
    "#print(x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V' 'V' 'V' 'V' 'C' 'V' 'C' 'D' 'C' 'V']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------train_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 1 | F2-uw 2 | F2-w 1 | F2-noop 2 | \n",
      "F3 cr:    F2-wu 2 | F2-uw 1 | F2-w 3 | F2-noop 1 | \n",
      "F3 r:    F2-wu 0 | F2-uw 1 | F2-w 1 | F2-noop 4 | \n",
      "F3 noop:    F2-wu 3 | F2-uw 1 | F2-w 2 | F2-noop 1 | \n",
      "\n",
      "Positive samples count: 11\n",
      "Total samples count: 26\n",
      "Positive class ratio: 0.4230769230769231\n",
      "--------test_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 20 | F2-uw 17 | F2-w 24 | F2-noop 22 | \n",
      "F3 cr:    F2-wu 20 | F2-uw 21 | F2-w 22 | F2-noop 27 | \n",
      "F3 r:    F2-wu 27 | F2-uw 25 | F2-w 30 | F2-noop 29 | \n",
      "F3 noop:    F2-wu 24 | F2-uw 23 | F2-w 32 | F2-noop 40 | \n",
      "\n",
      "Positive samples count: 174\n",
      "Total samples count: 403\n",
      "Positive class ratio: 0.4317617866004963\n",
      "--------val_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 4 | F2-uw 6 | F2-w 5 | F2-noop 11 | \n",
      "F3 cr:    F2-wu 3 | F2-uw 3 | F2-w 5 | F2-noop 7 | \n",
      "F3 r:    F2-wu 3 | F2-uw 4 | F2-w 5 | F2-noop 9 | \n",
      "F3 noop:    F2-wu 8 | F2-uw 11 | F2-w 8 | F2-noop 8 | \n",
      "\n",
      "Positive samples count: 43\n",
      "Total samples count: 100\n",
      "Positive class ratio: 0.43\n"
     ]
    }
   ],
   "source": [
    "train_original = data.reverse_encoding(data.get_x_y(train_unshuffled)[0])\n",
    "val_original = data.reverse_encoding(x_val)\n",
    "test_original = data.reverse_encoding(x_test)\n",
    "\n",
    "print(\"--------train_original--------\", '\\n')\n",
    "pos_train_ratio = get_stats_and_ratio(train_original)\n",
    "print(\"--------test_original--------\", '\\n')\n",
    "pos_test_ratio = get_stats_and_ratio(test_original)\n",
    "print(\"--------val_original--------\", '\\n')\n",
    "pos_val_ratio = get_stats_and_ratio(val_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mandamos las etiquetas codificadas al dispositivo del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un codificador de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar el codificador a las etiquetas y transformarlas a num enteros\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_trainP = y_train\n",
    "\n",
    "#Un tensor es una estructura de datos similar a matrices o arrays, pero con soporte para operaciones avanzadas en GPU.\n",
    "# Convertir las etiquetas a tensores de PyTorch\n",
    "y_train = torch.tensor(y_train, dtype=torch.float).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float).to(device)\n",
    "\n",
    "#se mueven los datos a la CPU o GPU para que puedan ser procesados por PyTorch durante el entrenamiento o la inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor(3.), tensor(1.), tensor(3.), tensor(1.), tensor(3.), tensor(0.), tensor(3.), tensor(3.), tensor(0.), tensor(3.), tensor(3.), tensor(3.), tensor(3.), tensor(3.), tensor(3.), tensor(2.), tensor(1.), tensor(1.), tensor(2.), tensor(3.), tensor(1.), tensor(2.), tensor(3.), tensor(3.), tensor(1.), tensor(3.)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(set(y_train))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = data.to_conv_format(x_train)\n",
    "x_val_cnn = data.to_conv_format(x_val)\n",
    "x_test_cnn = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_cnn)): #itereamos sobre cada tensor\n",
    "    x_train_cnn[i] = x_train_cnn[i].to(device)\n",
    "    x_val_cnn[i] = x_val_cnn[i].to(device)\n",
    "    x_test_cnn[i] = x_test_cnn[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 48])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cnn[0].shape #devuelve un par que indica (num de muestras, numero de funciones en total = 3*numMuestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cnn[0][2] #[x][y] accedes fx de la muestra y    max [2][25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train_cnn está representado como una matriz tridimensional en donde cada fila es la función y cada columna es la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 6 #cuantas veces ejecutaremos el entrenamiento, pero con dif pesos, entrena, parame, semillas\n",
    "epochs = 200 #época es una iteración completa sobre todo el conjunto de entrenamiento\n",
    "early_stopping_limit = 100 #si el cjto de val no ve una mejora durante 100 epocas consecutivas, el entrenam se para. Evitamos sobreajuste\n",
    "\n",
    "experiment_name=\"25per\"\n",
    "\n",
    "#el número de épocas determina cuántas veces el modelo va a ajustarse a los datos y aprender de ellos. Sin embargo, no siempre se necesita un número tan alto; por eso también se utilizan estrategias como el early stopping para evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(constructor, x_train, x_val, x_test, weight_decay, *argv):\n",
    "    accuracies = [] #lista con la precisión de cada modelo en el cjto de prueba\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    wrong_preds = []#lista con las predicciones incorrectas del modelo en el cjto de prueba\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    #listas de listas de cada modelo durante el entrenamiento y prueba\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        model = constructor(*argv)\n",
    "        model.to(device)\n",
    "\n",
    "        #0.  El modelo realiza una predicción con los parámetros actuales (pesos y sesgos).\n",
    "        #1. La función de pérdida calcula el error entre la predicción y las etiquetas reales.\n",
    "        #2. a través de un proceso llamado retropropagación, el modelo calcula el gradiente de la función de pérdida con respecto a cada peso\n",
    "        #3. Finalmente, el modelo actualiza los pesos utilizando un algoritmo de optimización, Adam, que ajusta los pesos en la dirección opuesta a los gradientes, con el objetivo de minimizar la pérdida\n",
    "       \n",
    "\n",
    "        criterion = nn.CrossEntropyLoss() # clasificación multiclase.  función de pérdida, calcula qué tan bien está funcionando el modelo durante el entrenamiento. Combina el calculo de la entropia y la funcion de activación, softmax\n",
    "        #Softmax convierte las salidas del modelo en probabilidades, transformando un vector de valores (posiblemente negativos o cualquier número real) en un conjunto de probabilidades que suman 1\n",
    "        #Entropía cruzada mide la diferencia entre la distribución de probabilidades predicha por el modelo y la distribución real \n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)#actualiza/optimiza los parámetros del modelo durante el entrenamiento para minimizar la función de pérdida\n",
    "        #le pasamos los param dedl modelo para que pueda actualizar los pesos de la red neuronal \n",
    "        #weight para es evitar que los pesos del modelo crezcan demasiado, lo que puede causar sobreajuste (regular el modelo)\n",
    "\n",
    "\n",
    "        train_losses.append([])\n",
    "        val_losses.append([])\n",
    "        train_accs.append([])\n",
    "        val_accs.append([])\n",
    "        \n",
    "        best_acc = 0\n",
    "\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "\n",
    "            train_loss, train_acc = models.train_epoch(model, x_train, y_train, criterion, optimizer, epoch, 10, verbose=False) #ese 10, es que vas a procesar lotes de 10muestras?\n",
    "            val_loss, val_acc = models.eval_epoch(model, x_val, y_val, criterion, 'Validation', verbose=False)\n",
    "\n",
    "            \n",
    "            train_losses[-1].append(train_loss)\n",
    "            val_losses[-1].append(val_loss)\n",
    "            train_accs[-1].append(train_acc)\n",
    "            val_accs[-1].append(val_acc)\n",
    "            \n",
    "            model_name = constructor.__name__[:constructor.__name__.find('')] \n",
    "            if val_acc > best_acc: # si la precisión del cjto de val mejora, se guarda el nombre del modelo act\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'./{model_name}model_TEMP' + experiment_name)    \n",
    "                early_stopping_cnt = 0\n",
    "            else:\n",
    "                early_stopping_cnt += 1\n",
    "\n",
    "            if early_stopping_cnt >= early_stopping_limit: #evitar el sobreajuste\n",
    "                break\n",
    "\n",
    "#Después de finalizar el entrenamiento con las epocas, se carga el mejor modelo \n",
    "        model.load_state_dict(torch.load(f'./{model_name}model_TEMP' + experiment_name))\n",
    "    \n",
    "        #\n",
    "        accuracies.append(get_accuracy_by_cases(model, x_test, y_test, test_original)) #Se evalúa el modelo en el conjunto de prueba \n",
    "     #   precisions.append(get_precision_by_cases(model, x_test, y_test, test_original))\n",
    "      #  recalls.append(get_recall_by_cases(model, x_test, y_test, test_original))\n",
    "       # f1_scores.append(get_f1_by_cases(model, x_test, y_test, test_original))\n",
    "        \n",
    "        wrong_preds.append(get_wrong_predictions(model, x_test, y_test, test_original))\n",
    "\n",
    "#se guarda el modelo con mejor precision en el co¡jto de prueba\n",
    "        if accuracies[-1]['Overall'] > best_accuracy:\n",
    "            torch.save(model.state_dict(), f'./best_{model_name}model' + experiment_name)    \n",
    "            best_accuracy = accuracies[-1]['Overall']\n",
    "\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test accuracy:\", accuracies[-1]['Overall'])\n",
    "\n",
    "    return accuracies, wrong_preds, [train_losses, val_losses, train_accs, val_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luna Santos\\AppData\\Local\\Temp\\ipykernel_15268\\3672781297.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}model_TEMP' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.9528535980148883\n",
      "2 / 6 models trained | Current model test accuracy: 0.9379652605459057\n",
      "3 / 6 models trained | Current model test accuracy: 0.9230769230769231\n",
      "4 / 6 models trained | Current model test accuracy: 0.09925558312655088\n",
      "5 / 6 models trained | Current model test accuracy: 0.9454094292803971\n",
      "6 / 6 models trained | Current model test accuracy: 0.9181141439205955\n"
     ]
    }
   ],
   "source": [
    "cnn_accuracies, cnn_wrong_preds, cnn_epoch_stats = train_models(models.CNN_Model, x_train_cnn, x_val_cnn, x_test_cnn, 0.0001, data, 64, 128, 4, -1, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = data.to_lstm_format(x_train)\n",
    "x_val_lstm = data.to_lstm_format(x_val)\n",
    "x_test_lstm = data.to_lstm_format(x_test)\n",
    "for i in range(len(x_train_lstm)):\n",
    "    x_train_lstm[i] = x_train_lstm[i].to(device)\n",
    "    x_val_lstm[i] = x_val_lstm[i].to(device)\n",
    "    x_test_lstm[i] = x_test_lstm[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luna Santos\\AppData\\Local\\Temp\\ipykernel_15268\\3672781297.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}model_TEMP' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.9404466501240695\n",
      "2 / 6 models trained | Current model test accuracy: 0.9404466501240695\n",
      "3 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "4 / 6 models trained | Current model test accuracy: 0.5210918114143921\n",
      "5 / 6 models trained | Current model test accuracy: 0.9181141439205955\n",
      "6 / 6 models trained | Current model test accuracy: 0.9429280397022333\n"
     ]
    }
   ],
   "source": [
    "lstm_accuracies, lstm_wrong_preds, lstm_epoch_stats = train_models(models.LSTM_Model, x_train_lstm, x_val_lstm, x_test_lstm, 0.0001, data, 16, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normal = data.to_conv_format(x_train)\n",
    "x_val_normal = data.to_conv_format(x_val)\n",
    "x_test_normal = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_normal)):\n",
    "    x_train_normal[i] = x_train_normal[i].to(device)\n",
    "    x_val_normal[i] = x_val_normal[i].to(device)\n",
    "    x_test_normal[i] = x_test_normal[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luna Santos\\AppData\\Local\\Temp\\ipykernel_11576\\3672781297.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}model_TEMP' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.4317617866004963\n",
      "2 / 6 models trained | Current model test accuracy: 0.4317617866004963\n",
      "3 / 6 models trained | Current model test accuracy: 0.4317617866004963\n",
      "4 / 6 models trained | Current model test accuracy: 0.4317617866004963\n",
      "5 / 6 models trained | Current model test accuracy: 0.4317617866004963\n",
      "6 / 6 models trained | Current model test accuracy: 0.4317617866004963\n"
     ]
    }
   ],
   "source": [
    "deepsetv2_accuracies, deepsetv2_wrong_preds, deepsetv2_epoch_stats = train_models(models.DEEPSETV2_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luna Santos\\AppData\\Local\\Temp\\ipykernel_11576\\3672781297.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}model_TEMP' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.5682382133995038\n",
      "2 / 6 models trained | Current model test accuracy: 0.4739454094292804\n",
      "3 / 6 models trained | Current model test accuracy: 0.5781637717121588\n",
      "4 / 6 models trained | Current model test accuracy: 0.5384615384615384\n",
      "5 / 6 models trained | Current model test accuracy: 0.5310173697270472\n",
      "6 / 6 models trained | Current model test accuracy: 0.4838709677419355\n"
     ]
    }
   ],
   "source": [
    "feedforward_accuracies, feedforward_wrong_preds, feedforward_epoch_stats = train_models(models.FEEDFORWARD_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 128, 32, 8, 'keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
