{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_data as vaina\n",
    "import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from evaluate import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos el conjunto de datos de entramiento y lo dividimos en 5% del subset para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 26 train | 100 val | 403 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juand\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = vaina.Data(layer_size=6)\n",
    "train, val, test = data.get_splits(['random_subsample'], [[0.05, 0.95]])\n",
    "train_unshuffled = train.copy()\n",
    "np.random.shuffle(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos todos los datos en x (variables), y (clasificacion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data.get_x_y(train)\n",
    "x_val, y_val = data.get_x_y(val)\n",
    "x_test, y_test = data.get_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------train_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 1 | F2-uw 2 | F2-w 1 | F2-noop 2 | \n",
      "F3 cr:    F2-wu 2 | F2-uw 1 | F2-w 3 | F2-noop 1 | \n",
      "F3 r:    F2-wu 0 | F2-uw 1 | F2-w 1 | F2-noop 4 | \n",
      "F3 noop:    F2-wu 3 | F2-uw 1 | F2-w 2 | F2-noop 1 | \n",
      "\n",
      "Positive samples count: 11\n",
      "Total samples count: 26\n",
      "Positive class ratio: 0.4230769230769231\n",
      "--------test_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 20 | F2-uw 17 | F2-w 24 | F2-noop 22 | \n",
      "F3 cr:    F2-wu 20 | F2-uw 21 | F2-w 22 | F2-noop 27 | \n",
      "F3 r:    F2-wu 27 | F2-uw 25 | F2-w 30 | F2-noop 29 | \n",
      "F3 noop:    F2-wu 24 | F2-uw 23 | F2-w 32 | F2-noop 40 | \n",
      "\n",
      "Positive samples count: 174\n",
      "Total samples count: 403\n",
      "Positive class ratio: 0.4317617866004963\n",
      "--------val_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 4 | F2-uw 6 | F2-w 5 | F2-noop 11 | \n",
      "F3 cr:    F2-wu 3 | F2-uw 3 | F2-w 5 | F2-noop 7 | \n",
      "F3 r:    F2-wu 3 | F2-uw 4 | F2-w 5 | F2-noop 9 | \n",
      "F3 noop:    F2-wu 8 | F2-uw 11 | F2-w 8 | F2-noop 8 | \n",
      "\n",
      "Positive samples count: 43\n",
      "Total samples count: 100\n",
      "Positive class ratio: 0.43\n"
     ]
    }
   ],
   "source": [
    "train_original = data.reverse_encoding(data.get_x_y(train_unshuffled)[0])\n",
    "val_original = data.reverse_encoding(x_val)\n",
    "test_original = data.reverse_encoding(x_test)\n",
    "\n",
    "print(\"--------train_original--------\", '\\n')\n",
    "pos_train_ratio = get_stats_and_ratio(train_original)\n",
    "print(\"--------test_original--------\", '\\n')\n",
    "pos_test_ratio = get_stats_and_ratio(test_original)\n",
    "print(\"--------val_original--------\", '\\n')\n",
    "pos_val_ratio = get_stats_and_ratio(val_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mandamos las etiquetas codificadas al dispositivo del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un codificador de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar el codificador a las etiquetas y transformarlas\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Convertir las etiquetas a tensores de PyTorch\n",
    "y_train = torch.tensor(y_train, dtype=torch.float).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = data.to_conv_format(x_train)\n",
    "x_val_cnn = data.to_conv_format(x_val)\n",
    "x_test_cnn = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_cnn)):\n",
    "    x_train_cnn[i] = x_train_cnn[i].to(device)\n",
    "    x_val_cnn[i] = x_val_cnn[i].to(device)\n",
    "    x_test_cnn[i] = x_test_cnn[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 6\n",
    "epochs = 200\n",
    "early_stopping_limit = 100\n",
    "\n",
    "experiment_name=\"25per\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(constructor, x_train, x_val, x_test, weight_decay, *argv):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    wrong_preds = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        model = constructor(*argv)\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "        train_losses.append([])\n",
    "        val_losses.append([])\n",
    "        train_accs.append([])\n",
    "        val_accs.append([])\n",
    "        \n",
    "        best_acc = 0\n",
    "\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = models.train_epoch(model, x_train, y_train, criterion, optimizer, epoch, 10, verbose=False)\n",
    "            val_loss, val_acc = models.eval_epoch(model, x_val, y_val, criterion, 'Validation', verbose=False)\n",
    "\n",
    "            \n",
    "            train_losses[-1].append(train_loss)\n",
    "            val_losses[-1].append(val_loss)\n",
    "            train_accs[-1].append(train_acc)\n",
    "            val_accs[-1].append(val_acc)\n",
    "            \n",
    "            model_name = constructor.__name__[:constructor.__name__.find('')]\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'./{model_name}model_TEMP' + experiment_name)    \n",
    "                early_stopping_cnt = 0\n",
    "            else:\n",
    "                early_stopping_cnt += 1\n",
    "\n",
    "            if early_stopping_cnt >= early_stopping_limit:\n",
    "                break\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(f'./{model_name}model_TEMP' + experiment_name))\n",
    "    \n",
    "        accuracies.append(get_accuracy_by_cases(model, x_test, y_test, test_original))\n",
    "     #   precisions.append(get_precision_by_cases(model, x_test, y_test, test_original))\n",
    "      #  recalls.append(get_recall_by_cases(model, x_test, y_test, test_original))\n",
    "       # f1_scores.append(get_f1_by_cases(model, x_test, y_test, test_original))\n",
    "        \n",
    "        wrong_preds.append(get_wrong_predictions(model, x_test, y_test, test_original))\n",
    "\n",
    "        if accuracies[-1]['Overall'] > best_accuracy:\n",
    "            torch.save(model.state_dict(), f'./best_{model_name}model' + experiment_name)    \n",
    "            best_accuracy = accuracies[-1]['Overall']\n",
    "\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test accuracy:\", accuracies[-1]['Overall'])\n",
    "    return accuracies, wrong_preds, [train_losses, val_losses, train_accs, val_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_15200\\3672781297.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}model_TEMP' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.5682382133995038\n",
      "2 / 6 models trained | Current model test accuracy: 0.6327543424317618\n",
      "3 / 6 models trained | Current model test accuracy: 0.9503722084367245\n",
      "4 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "5 / 6 models trained | Current model test accuracy: 0.913151364764268\n",
      "6 / 6 models trained | Current model test accuracy: 0.4466501240694789\n"
     ]
    }
   ],
   "source": [
    "cnn_accuracies, cnn_wrong_preds, cnn_epoch_stats = train_models(models.CNN_Model, x_train_cnn, x_val_cnn, x_test_cnn, 0.0001, data, 64, 128, 4, -1, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = data.to_lstm_format(x_train)\n",
    "x_val_lstm = data.to_lstm_format(x_val)\n",
    "x_test_lstm = data.to_lstm_format(x_test)\n",
    "for i in range(len(x_train_lstm)):\n",
    "    x_train_lstm[i] = x_train_lstm[i].to(device)\n",
    "    x_val_lstm[i] = x_val_lstm[i].to(device)\n",
    "    x_test_lstm[i] = x_test_lstm[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_15200\\1066353585.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_5per'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "2 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "3 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "4 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "5 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "6 / 6 models trained | Current model test accuracy: 0.9578163771712159\n"
     ]
    }
   ],
   "source": [
    "lstm_accuracies, lstm_wrong_preds, lstm_epoch_stats = train_models(models.LSTM_Model, x_train_lstm, x_val_lstm, x_test_lstm, 0.0001, data, 16, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normal = data.to_conv_format(x_train)\n",
    "x_val_normal = data.to_conv_format(x_val)\n",
    "x_test_normal = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_normal)):\n",
    "    x_train_normal[i] = x_train_normal[i].to(device)\n",
    "    x_val_normal[i] = x_val_normal[i].to(device)\n",
    "    x_test_normal[i] = x_test_normal[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_15200\\1066353585.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_5per'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "2 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "3 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "4 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "5 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "6 / 6 models trained | Current model test accuracy: 0.9578163771712159\n"
     ]
    }
   ],
   "source": [
    "deepsetv2_accuracies, deepsetv2_wrong_preds, deepsetv2_epoch_stats = train_models(models.DEEPSETV2_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_15200\\1066353585.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_5per'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.9553349875930521\n",
      "2 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "3 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "4 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "5 / 6 models trained | Current model test accuracy: 0.9578163771712159\n",
      "6 / 6 models trained | Current model test accuracy: 0.9578163771712159\n"
     ]
    }
   ],
   "source": [
    "feedforward_accuracies, feedforward_wrong_preds, feedforward_epoch_stats = train_models(models.FEEDFORWARD_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 128, 32, 8, 'keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
