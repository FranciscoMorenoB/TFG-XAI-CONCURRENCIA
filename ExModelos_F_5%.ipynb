{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.core' has no attribute 'numerictypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12784\\4126507688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate_data\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvaina\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juand\\Dropbox\\Mi PC (LAPTOP-N6MQL634)\\Documents\\TFGotros\\generate_data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juand\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdependency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{dependency}: {e}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juand\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# Numpy 1.20.0, 2020-10-19\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     __deprecated_attrs__[\"typeDict\"] = (\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerictypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypeDict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;34m\"`np.typeDict` is a deprecated alias for `np.sctypeDict`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy.core' has no attribute 'numerictypes'"
     ]
    }
   ],
   "source": [
    "import generate_data as vaina\n",
    "import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from evaluate import *\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos el conjunto de datos de entramiento y lo dividimos en 5% del subset para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 132 train | 79 val | 318 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juand\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but OneHotEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Define el dispositivo que PyTorch usará para ejecutar los cálculos.\n",
    "\n",
    "data = vaina.Data(layer_size=6)\n",
    "train, val, test = data.get_splits(['random_subsample'], [[0.25, 0.75]]) #internamente onehot\n",
    "train_unshuffled = train.copy()\n",
    "np.random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[',..._.', 'w._,._', 'cr__._', 'V'],\n",
       " ['.,,_,.', 'w,_,__', '.cr._.', 'V'],\n",
       " [',__,._', 'w,._,.', '_,cr__', 'V'],\n",
       " [',___._', 'w.,_.,', ',..cr,', 'V'],\n",
       " ['__.,.,', 'w._,_.', '_..,cr', 'V'],\n",
       " [',,,__,', ',w._._', 'cr.,,_', 'V'],\n",
       " [',_..,_', '_w....', '.cr.__', 'V'],\n",
       " ['___.__', '_w_,_,', '..cr__', 'V'],\n",
       " ['_.,_._', '_w._.,', '...cr_', 'V'],\n",
       " ['_.,,.,', '.w...,', '__._cr', 'V'],\n",
       " [',,.,.,', '._w__,', 'cr_,_,', 'V'],\n",
       " ['_..__.', '__w_.,', ',cr,.,', 'V'],\n",
       " [',.._..', '_,w_..', '.,cr.,', 'V'],\n",
       " ['_.__,,', '_,w,_,', '__.cr.', 'V'],\n",
       " [',..,__', '.,w.,_', '.___cr', 'V'],\n",
       " [',,.._.', '...w.,', 'cr,,,,', 'V'],\n",
       " ['__,.._', '.,.w..', ',cr_.,', 'V'],\n",
       " ['_...__', '..,w__', ',_cr..', 'V'],\n",
       " ['__....', ',,,w._', '..,cr,', 'V'],\n",
       " ['..._.,', '.,_w_.', ',.__cr', 'V'],\n",
       " ['.._..,', '_.,_w,', 'cr__.,', 'V'],\n",
       " [',,,__.', '.__.w_', '_cr__,', 'V'],\n",
       " ['.___,_', '._,,w.', '__cr,,', 'V'],\n",
       " ['....__', ',..,w,', '__,cr.', 'V'],\n",
       " ['..,._,', '.__.w,', '__,,cr', 'V'],\n",
       " ['_,,_,.', '.__,_w', 'cr,_,.', 'V'],\n",
       " ['._,._,', '__.._w', ',cr___', 'V'],\n",
       " [',.,.,,', '__,,.w', '_.cr,_', 'V'],\n",
       " ['_,,,_,', '.__..w', '__,cr,', 'V'],\n",
       " [',_,_,.', ',.___w', '__.,cr', 'V'],\n",
       " [',__._,', 'w_.___', 'dr._.,', 'D'],\n",
       " ['_...._', 'w,__._', '_dr.__', 'D'],\n",
       " ['_,,,,,', 'w__...', '_,dr,.', 'D'],\n",
       " ['__,,._', 'w,..,,', ',._dr,', 'D'],\n",
       " ['__.___', 'w,.,,,', '.,,.dr', 'D'],\n",
       " ['___.._', '_w.,.,', 'dr,._.', 'D'],\n",
       " ['_,,,,,', '.w_.,.', '.dr,__', 'D'],\n",
       " ['_.,_.,', '_w,__,', '.,dr__', 'D'],\n",
       " [',.,..,', '.w__..', '.,.dr.', 'D'],\n",
       " [',,_._,', '.w_,.,', '....dr', 'D'],\n",
       " [',..,,,', '__w___', 'dr.,..', 'D'],\n",
       " ['_.,_,_', ',_w._,', ',dr,..', 'D'],\n",
       " ['.,....', '__w,__', '_,dr,_', 'D'],\n",
       " [',_..,,', ',_w._.', '.,_dr.', 'D'],\n",
       " ['__,_..', ',.w,..', '.___dr', 'D'],\n",
       " ['.._...', '._,w,_', 'dr,_.,', 'D'],\n",
       " [',._,,.', '...w,.', '_dr,._', 'D'],\n",
       " ['_,_,._', '_..w_,', '_,dr..', 'D'],\n",
       " ['_.,,__', '__.w_.', ',_,dr.', 'D'],\n",
       " ['_,._..', '.._w.,', ',_,_dr', 'D'],\n",
       " ['._____', ',._.w,', 'dr,,_.', 'D'],\n",
       " [',,,__,', ',___w_', '.dr.__', 'D'],\n",
       " [',__._,', '.,,_w,', '_,dr_,', 'D'],\n",
       " ['_,.,,_', '..,_w_', '_,_dr.', 'D'],\n",
       " [',___,.', ',_.,w.', '._,.dr', 'D'],\n",
       " ['.,_...', ',..,.w', 'dr_._.', 'D'],\n",
       " [',,,,_,', '._.,_w', ',dr__.', 'D'],\n",
       " ['__,...', '_,,.,w', ',.dr__', 'D'],\n",
       " [',,_,,,', ',._._w', '__.dr,', 'D'],\n",
       " [',__.,.', '_...,w', '_,.,dr', 'D'],\n",
       " [',__,._', 'w_._,.', 'r__,..', 'C'],\n",
       " ['.,,.,.', 'w,.,._', ',r_,.,', 'C'],\n",
       " ['..._,,', 'w.,..,', '_,r,_.', 'C'],\n",
       " [',,.._.', 'w_,.,_', '_..r_,', 'C'],\n",
       " [',,,._,', 'w_.,_.', '_.__r_', 'C'],\n",
       " ['_,.,__', 'w_,,.,', '_,,._r', 'C'],\n",
       " ['._.___', '_w,,,_', 'r,,,_.', 'C'],\n",
       " ['.,._._', '.w__..', ',r,,_.', 'C'],\n",
       " [',,,___', '_w.._.', '_,r___', 'C'],\n",
       " ['._,.,.', '_w,__.', '.,_r__', 'C'],\n",
       " [',_,_,,', '_w..,,', ',,,,r.', 'C'],\n",
       " [',._,_,', '_w,..,', ',_,__r', 'C'],\n",
       " ['_...._', '..w_.,', 'r,.,,.', 'C'],\n",
       " ['.,__,.', '._w_._', ',r.___', 'C'],\n",
       " [',..,_,', '__w.,_', '_.r.__', 'C'],\n",
       " ['_._.,.', '.,w,.,', '._,r,,', 'C'],\n",
       " ['.__.__', '.,w.__', '_._.r.', 'C'],\n",
       " [',._,..', ',.w_,.', ',,.__r', 'C'],\n",
       " ['...,_.', '___w.,', 'r___..', 'C'],\n",
       " ['..,.,_', ',_,w_.', '.r,.,.', 'C'],\n",
       " [',,,_,.', '_._w,_', '_.r.,_', 'C'],\n",
       " [',__,.,', '._,w._', ',,.r._', 'C'],\n",
       " ['__..__', '_._w.,', '_,.,r.', 'C'],\n",
       " [',._,__', '.__w,,', ',,,_.r', 'C'],\n",
       " [',..,,,', ',.,,w,', 'r,__..', 'C'],\n",
       " [',_,_,.', '__..w.', '_r__,.', 'C'],\n",
       " ['...,,.', '_,.,w.', '.,r,__', 'C'],\n",
       " ['..,.,,', '_._.w,', ',,,r,_', 'C'],\n",
       " [',,.._,', ',,.,w.', '.,,.r_', 'C'],\n",
       " ['.,.,__', ',,..w,', ',,,._r', 'C'],\n",
       " ['_.,._.', '..,,_w', 'r_.,.,', 'C'],\n",
       " ['..._._', '_....w', '.r_,._', 'C'],\n",
       " ['_,.__.', '_,,,.w', '.,r_..', 'C'],\n",
       " [',,__,,', '_._.,w', ',,,r_.', 'C'],\n",
       " ['..___.', ',,,,_w', '...,r,', 'C'],\n",
       " [',,,_..', '_.,_.w', ',_.,_r', 'C'],\n",
       " ['_,._,_', 'w,._.,', ',,_._,', 'V'],\n",
       " ['..,,,.', 'w,._,.', ',_,._,', 'V'],\n",
       " ['_.,.,.', 'w._,..', ',,__,.', 'V'],\n",
       " ['.,,,_,', 'w.,_.,', '__,..,', 'V'],\n",
       " ['_..___', 'w.__,_', '_..,__', 'V'],\n",
       " ['_,,,..', 'w_,,,_', '._.,,,', 'V'],\n",
       " ['.,,,._', 'w,_.,_', '.,__,_', 'V'],\n",
       " ['_,,_,_', '_w,__.', '..,_,_', 'V'],\n",
       " [',,_,._', '_w_._,', '_,_...', 'V'],\n",
       " ['__,,,_', ',w..,.', '_.___.', 'V'],\n",
       " ['_,..,,', '_w_.,.', ',_.,,.', 'V'],\n",
       " ['_.,,,,', '.w_.,,', '_,,.,,', 'V'],\n",
       " [',,,,,_', ',w_..,', '__,__,', 'V'],\n",
       " ['___,.,', ',w._.,', '_,.._,', 'V'],\n",
       " [',,_.__', ',_w.,.', '__....', 'V'],\n",
       " ['.,.,,_', '__w,._', '_,,.__', 'V'],\n",
       " ['_,,..,', '.,w,,,', '.,.,_,', 'V'],\n",
       " ['.._,._', ',.w._.', ',_.,__', 'V'],\n",
       " ['...,__', ',,w_,,', '__.,,_', 'V'],\n",
       " ['.,_.._', '._w,,.', '.,.,.,', 'V'],\n",
       " [',_,,,.', '._w__,', '__.,__', 'V'],\n",
       " ['__.,,,', '_._w__', ',._,,_', 'V'],\n",
       " ['._.,,.', '._,w,_', '_,.._,', 'V'],\n",
       " ['___,__', '.,_w,,', ',,,._,', 'V'],\n",
       " [',,,_,.', ',_.w..', ',_._.,', 'V'],\n",
       " [',.,,_,', '_,.w,.', ',_.,,.', 'V'],\n",
       " ['.__,,,', '__.w.,', '____._', 'V'],\n",
       " ['.,.,.,', '_,,w..', ',._.__', 'V'],\n",
       " ['.,_.._', ',,_,w,', ',,..,_', 'V'],\n",
       " ['.,_,,,', '_..,w,', '__.,__', 'V'],\n",
       " [',_.._,', ',.__w.', '..,.,.', 'V'],\n",
       " ['_,._,,', '_,_,w.', ',,_.,,', 'V'],\n",
       " ['.,_,,,', '_.,_w_', '_.,,__', 'V'],\n",
       " ['_._...', '_._,w_', '.,,._,', 'V'],\n",
       " ['.,_,.,', ',.,.w.', '..___.', 'V'],\n",
       " ['____..', '__._.w', '.__._,', 'V'],\n",
       " [',,_,_,', '...._w', '_.,.,_', 'V'],\n",
       " [',,,.._', '___..w', '.,,,_,', 'V'],\n",
       " [',,_,._', '..__,w', '.__,.,', 'V'],\n",
       " [',.,,,,', '.,,_.w', '__._,,', 'V'],\n",
       " ['._..,.', ',.,,.w', '_,_,,,', 'V'],\n",
       " ['.,___.', '_,.,_w', ',.,...', 'V'],\n",
       " [',.,._.', 'wu.,,.', 'cr._._', 'V'],\n",
       " [',,.,,.', 'wu_,.,', '_cr_,_', 'V'],\n",
       " ['._,_..', 'wu,...', '.,cr..', 'V'],\n",
       " ['.,___.', 'wu_,._', '__.cr,', 'V'],\n",
       " [',_._,,', 'wu__..', ',,,.cr', 'V'],\n",
       " ['.__._,', '.wu,,.', 'cr.__,', 'V'],\n",
       " ['_,,._,', '.wu_.,', '_cr._.', 'V'],\n",
       " ['.,_.,,', ',wu,,_', '._cr.,', 'V'],\n",
       " ['.,._,.', ',wu_,_', '.__cr_', 'V'],\n",
       " ['.___,,', ',wu_.,', '_,,,cr', 'V'],\n",
       " ['.._,,,', ',,wu__', 'cr..,_', 'V'],\n",
       " ['..__,.', ',_wu..', '.cr.,_', 'V'],\n",
       " ['.,,,._', '_,wu._', '_.cr,_', 'V'],\n",
       " [',....,', '.,wu,.', '_..cr.', 'V'],\n",
       " [',._,__', ',,wu__', ',.,_cr', 'V'],\n",
       " ['_,..,_', '_..wu,', 'cr_,._', 'V'],\n",
       " ['.,_,__', '...wu.', ',cr_,,', 'V'],\n",
       " [',,.,_.', '.,,wu,', '__cr,_', 'V'],\n",
       " [',,____', ',..wu,', ',__cr,', 'V'],\n",
       " [',__.,.', ',..wu_', '_,._cr', 'V'],\n",
       " [',,.._,', '_,..wu', 'cr,_,_', 'V'],\n",
       " ['..._.,', ',.,,wu', ',cr,_,', 'V'],\n",
       " ['.__,.,', ',.__wu', '__cr,_', 'V'],\n",
       " ['_,,.__', ',..,wu', '.,.cr.', 'V'],\n",
       " [',._._.', '.__.wu', '__._cr', 'V'],\n",
       " ['___._.', 'wu__,,', 'dr,_,_', 'V'],\n",
       " ['..,,_.', 'wu.,_,', '_dr,,,', 'V'],\n",
       " ['_,___.', 'wu,._,', '__dr__', 'V'],\n",
       " [',_,,,,', 'wu.,,,', '.,_dr_', 'V'],\n",
       " [',_,,__', 'wu__.,', ',._,dr', 'V'],\n",
       " ['_.,,_,', ',wu.,_', 'dr____', 'V'],\n",
       " ['_,__,_', '.wu_.,', '.dr_,,', 'V'],\n",
       " ['__,,,_', '_wu_,,', '..dr._', 'V'],\n",
       " [',.,._.', '.wu.__', '..,dr,', 'V'],\n",
       " ['..,_..', '_wu__.', ',._.dr', 'V'],\n",
       " ['__,.._', '._wu.,', 'dr,,__', 'V'],\n",
       " ['_..__,', '._wu,.', '.dr,,.', 'V'],\n",
       " ['__.._.', '__wu..', ',_dr..', 'V'],\n",
       " ['__._,_', '_.wu,.', ',,_dr.', 'V'],\n",
       " [',.._,_', ',.wu..', '._._dr', 'V'],\n",
       " [',__,_,', '_.,wu,', 'dr,,,.', 'V'],\n",
       " ['__.___', '.._wu_', '_dr.,_', 'V'],\n",
       " ['._,..,', ',_,wu_', '.,dr_,', 'V'],\n",
       " ['_,,,_.', ',,.wu_', '_,_dr_', 'V'],\n",
       " ['.,._,_', '_,.wu.', ',_,.dr', 'V'],\n",
       " [',.,,,,', '_,,,wu', 'dr_...', 'V'],\n",
       " ['._._,.', '.,,.wu', '_dr__.', 'V'],\n",
       " ['.,,.,.', '.,_,wu', '._dr._', 'V'],\n",
       " [',,_.._', ',,..wu', ',__dr.', 'V'],\n",
       " [',.,,.,', ',,,_wu', '._,_dr', 'V'],\n",
       " ['...._,', 'wu_._.', 'r__._,', 'C'],\n",
       " [',__,_,', 'wu.,_.', ',r.,,_', 'C'],\n",
       " ['.,....', 'wu..,.', '.,r,_.', 'C'],\n",
       " [',.._,.', 'wu.,,_', '.,.r,.', 'C'],\n",
       " [',_,_,.', 'wu___,', '_.,_r,', 'C'],\n",
       " ['.,..__', 'wu.__.', '.,,.,r', 'C'],\n",
       " [',.__,,', '.wu,.,', 'r_.,,.', 'C'],\n",
       " [',.,..,', '.wu_,,', '.r,._,', 'C'],\n",
       " ['._,.__', '_wu,._', '_.r,,.', 'C'],\n",
       " ['_,.__.', ',wu.._', ',._r_.', 'C'],\n",
       " [',._.._', '.wu,._', '___.r_', 'C'],\n",
       " [',.,.__', ',wu_,,', '__.,,r', 'C'],\n",
       " ['.__,..', ',_wu._', 'r___..', 'C'],\n",
       " ['_,__,.', '_.wu,,', ',r,,,.', 'C'],\n",
       " ['..,.,.', ',,wu.,', '_,r.__', 'C'],\n",
       " ['._._._', '.,wu._', ',._r,.', 'C'],\n",
       " ['__,__.', ',.wu,.', ',,.,r_', 'C'],\n",
       " [',..._.', '..wu.,', '.,.,,r', 'C'],\n",
       " ['_._.,.', ',,.wu.', 'r_.__.', 'C'],\n",
       " ['.._.._', ',._wu,', ',r__,,', 'C'],\n",
       " [',_,,_,', '_,.wu_', '__r,_,', 'C'],\n",
       " [',.._,.', '_,.wu_', '.,_r__', 'C'],\n",
       " [',___._', '.._wu,', '_...r,', 'C'],\n",
       " ['__.__,', ',_,wu,', '...,,r', 'C'],\n",
       " ['.,.,__', '_,__wu', 'r..,..', 'C'],\n",
       " ['.___,_', ',,.,wu', ',r..__', 'C'],\n",
       " [',____.', '.__.wu', ',_r,__', 'C'],\n",
       " ['__,._,', '.,_.wu', ',,,r_.', 'C'],\n",
       " ['_,_,__', ',.,.wu', ',.,.r.', 'C'],\n",
       " ['__._,.', ',__.wu', '_.,_.r', 'C'],\n",
       " [',...,_', 'wu___.', '.,,.,_', 'V'],\n",
       " ['._,.,.', 'wu__..', '_,,_,,', 'V'],\n",
       " ['.,._._', 'wu_.,_', '_.,,__', 'V'],\n",
       " [',.._,,', 'wu_,.,', '.._,,.', 'V'],\n",
       " ['.,_,_,', 'wu_,..', '__.,._', 'V'],\n",
       " ['..,__,', 'wu,.,.', '....,_', 'V'],\n",
       " ['.__._.', 'wu,,,.', ',__,,,', 'V'],\n",
       " [',.,__,', '_wu___', ',,_.,,', 'V'],\n",
       " ['.....,', ',wu_,_', '._,___', 'V'],\n",
       " ['_,,,..', '_wu_,_', '.,_.._', 'V'],\n",
       " ['____,.', ',wu..,', '_,_,_,', 'V'],\n",
       " ['.,,,_,', '.wu_,,', ',,_,.,', 'V'],\n",
       " ['_,..__', '_wu,,,', ',_,,,,', 'V'],\n",
       " ['.,_,._', '.wu.._', ',_,_.,', 'V'],\n",
       " ['.,,,,,', '__wu..', ',_._..', 'V'],\n",
       " [',,._,.', ',_wu,.', '.,_,_,', 'V'],\n",
       " ['.,.,,.', '.,wu.,', '..____', 'V'],\n",
       " ['.___,.', '.,wu__', ',,_.,,', 'V'],\n",
       " ['.,_,__', '._wu_.', '_._,_.', 'V'],\n",
       " [',._...', '_,wu._', '_,.,.,', 'V'],\n",
       " [',.,,,.', '__wu,_', '___._.', 'V'],\n",
       " [',,.,,_', '___wu.', ',.,.,_', 'V'],\n",
       " ['_,,.,_', '...wu.', '_,.___', 'V'],\n",
       " [',.__..', ',..wu_', '.___,,', 'V'],\n",
       " ['_,__..', '_,_wu,', ',,_.,,', 'V'],\n",
       " ['.,...,', '__,wu,', '_..._.', 'V'],\n",
       " ['_,,.,.', '._.wu.', ',_,.,,', 'V'],\n",
       " ['._.,,.', ',_,wu.', '____._', 'V'],\n",
       " [',.__,_', '__..wu', ',__,,_', 'V'],\n",
       " ['._..,_', ',,,_wu', '..,,,,', 'V'],\n",
       " ['.,_,__', '..,,wu', '..,___', 'V'],\n",
       " [',.,.,.', ',,_,wu', ',.,...', 'V'],\n",
       " ['____._', ',._,wu', ',.,..,', 'V'],\n",
       " ['..,__,', ',,,,wu', '__..,.', 'V'],\n",
       " ['__,...', '_._.wu', '.,._.,', 'V'],\n",
       " [',,._,,', 'uw.,,.', 'cr.,_,', 'V'],\n",
       " [',__.,_', 'uw.,,,', ',cr.,_', 'V'],\n",
       " ['_...,_', 'uw__.,', ',_cr,_', 'V'],\n",
       " ['.,_,.,', 'uw_,..', '_,_cr.', 'V'],\n",
       " [',.__._', 'uw,,_.', '_.._cr', 'V'],\n",
       " ['..,_,.', '.uw_._', 'cr..,,', 'V'],\n",
       " [',,.,,.', ',uw,_,', '_cr.__', 'V'],\n",
       " ['_...,_', ',uw__,', ',_cr_,', 'V'],\n",
       " ['_.__,_', '_uw,,.', '_,_cr,', 'V'],\n",
       " ['......', '_uw,_,', ',__,cr', 'V'],\n",
       " ['_,__._', ',,uw__', 'cr__._', 'V'],\n",
       " ['....,,', '__uw_,', ',cr,..', 'V'],\n",
       " ['..._,.', '.,uw.,', '..cr._', 'V'],\n",
       " ['_._,_.', '._uw__', '.._cr,', 'V'],\n",
       " [',_,,,,', '..uw__', '_,__cr', 'V'],\n",
       " [',,,_,.', ',__uw_', 'cr__.,', 'V'],\n",
       " ['______', ',,.uw,', '_cr,,,', 'V'],\n",
       " ['_.___,', ',_,uw,', '_.cr.,', 'V'],\n",
       " ['..,._,', ',,.uw.', '.._cr_', 'V'],\n",
       " [',_.,._', '.,,uw_', '__._cr', 'V'],\n",
       " ['..___,', '._,.uw', 'cr,__.', 'V'],\n",
       " [',,,._.', '__.,uw', '.cr_._', 'V'],\n",
       " [',._.,_', '.,,_uw', '..cr,.', 'V'],\n",
       " [',,_.__', '__..uw', '_,,cr,', 'V'],\n",
       " ['.._,,_', '.,_.uw', '.,__cr', 'V'],\n",
       " ['_.._,_', 'uw_,__', 'dr..,,', 'A'],\n",
       " [',_.,,_', 'uw,..,', ',dr_,.', 'A'],\n",
       " [',___,,', 'uw...,', '._dr__', 'A'],\n",
       " ['_,..._', 'uw,,_.', '_,_dr,', 'A'],\n",
       " ['.,.,..', 'uw.,,.', '_._,dr', 'A'],\n",
       " [',,,.._', '.uw,,,', 'dr.,,,', 'A'],\n",
       " ['_,.,,_', '_uw,,_', ',dr.__', 'A'],\n",
       " ['_.....', ',uw.,_', '_.dr._', 'A'],\n",
       " ['____,,', '_uw._.', ',_.dr,', 'A'],\n",
       " ['.,,,_.', '_uw._.', ',.,_dr', 'A'],\n",
       " ['_...__', ',.uw,_', 'dr,,__', 'A'],\n",
       " ['_.____', '._uw__', '.dr_._', 'A'],\n",
       " ['__._,,', '.,uw,,', '_.dr_,', 'A'],\n",
       " [',,__..', '.,uw._', '._.dr,', 'A'],\n",
       " [',_,__,', '.,uw._', '_.._dr', 'A'],\n",
       " [',.,,_.', '_..uw.', 'dr__._', 'A'],\n",
       " [',_..,.', '.,_uw,', '_dr__,', 'A'],\n",
       " ['_,,_,_', '..,uw.', '.,dr,_', 'A'],\n",
       " ['_._._,', '.,.uw_', '.,,dr,', 'A'],\n",
       " ['__.,,.', ',..uw,', '.__.dr', 'A'],\n",
       " ['_,_,._', '..,,uw', 'dr__,.', 'A'],\n",
       " [',..,,_', ',_,_uw', '.dr..,', 'A'],\n",
       " ['.,._,.', '.__,uw', ',_dr_,', 'A'],\n",
       " ['_.,.__', '_,_,uw', '_,_dr,', 'A'],\n",
       " [',.,_._', '.__,uw', ',,._dr', 'A'],\n",
       " ['.._.,,', 'uw_._,', 'r_.,..', 'C'],\n",
       " ['._,__,', 'uw,._,', '_r.,.,', 'C'],\n",
       " ['....._', 'uw____', '.,r_..', 'C'],\n",
       " [',,,,_.', 'uw._,_', '...r_.', 'C'],\n",
       " ['..,..,', 'uw_.__', '_.__r_', 'C'],\n",
       " ['_.,,_,', 'uw,.,_', '._...r', 'C'],\n",
       " [',.,,,_', '_uw_,.', 'r____.', 'C'],\n",
       " ['_,,,_.', ',uw,._', ',r.,,_', 'C'],\n",
       " [',.,._.', '_uw,,_', ',.r,,.', 'C'],\n",
       " ['._.,..', ',uw.,.', '_..r.,', 'C'],\n",
       " ['__.__,', '_uw.,,', '_.,,r,', 'C'],\n",
       " ['.,.._,', '_uw.,,', ',_,,,r', 'C'],\n",
       " ['.,._..', '..uw_.', 'r.,.,,', 'C'],\n",
       " [',,_,,.', ',_uw__', '_r_.._', 'C'],\n",
       " ['.,,.__', '._uw__', ',_r,_.', 'C'],\n",
       " ['_,_,..', '__uw_,', ',,,r..', 'C'],\n",
       " [',.,.,.', '_.uw.,', ',__,r,', 'C'],\n",
       " ['_,,__,', '__uw,,', ',.,__r', 'C'],\n",
       " ['_,...,', '.,_uw.', 'r_._..', 'C'],\n",
       " [',_,,__', '.__uw.', ',r,,._', 'C'],\n",
       " ['._,,..', '_,_uw,', '._r,._', 'C'],\n",
       " ['_.,.,.', '._,uw.', ',.,r__', 'C'],\n",
       " [',..,.,', ',,.uw_', '_.._r_', 'C'],\n",
       " ['.,._,,', ',._uw_', '.,.,,r', 'C'],\n",
       " ['_.,_..', ',.__uw', 'r,_,__', 'C'],\n",
       " [',,..__', '_.,_uw', '_r....', 'C'],\n",
       " [',,.,.,', '.,_.uw', '.,r_._', 'C'],\n",
       " [',,_.._', '_.,,uw', ',,,r,_', 'C'],\n",
       " [',_,.,.', ',_,.uw', ',._.r,', 'C'],\n",
       " ['_.._,,', '__,,uw', ',,.._r', 'C'],\n",
       " ['__.,.,', 'uw.__,', ',.,,,_', 'V'],\n",
       " [',,._,.', 'uw,,,_', ',._.__', 'V'],\n",
       " ['.._,,_', 'uw._.,', ',.,.,,', 'V'],\n",
       " ['.,_,,.', 'uw._._', ',,,,._', 'V'],\n",
       " [',_,__,', 'uw___.', '.,,_,.', 'V'],\n",
       " ['.,_,_,', 'uw_,._', ',..,.,', 'V'],\n",
       " ['_,..,_', 'uw,.__', ',.,__.', 'V'],\n",
       " ['__,,_,', ',uw,_,', '.,____', 'V'],\n",
       " ['__,,_.', ',uw_._', '._____', 'V'],\n",
       " [',,.._.', '.uw,.,', '_._,..', 'V'],\n",
       " ['_,__..', '.uw._.', ',,,,._', 'V'],\n",
       " ['.,,..,', ',uw,,_', '.__,,_', 'V'],\n",
       " ['..,,,_', ',uw.._', '._._..', 'V'],\n",
       " ['.,.,._', '.uw_,.', '.,,_,,', 'V'],\n",
       " ['.,..__', '_,uw_.', ',_,.,.', 'V'],\n",
       " ['.__,.,', ',_uw..', '_.,_,,', 'V'],\n",
       " ['.,.,..', '__uw,_', '_.___.', 'V'],\n",
       " [',,,_,.', ',,uw,.', '_.,,,.', 'V'],\n",
       " [',,,...', ',,uw._', ',,.__.', 'V'],\n",
       " [',,...,', '_.uw.,', '.,,._,', 'V'],\n",
       " ['_._.,,', ',.uw,,', ',_,..,', 'V'],\n",
       " ['__._._', '__.uw_', '_,_,,.', 'V'],\n",
       " ['_.,_,_', ',,,uw,', '__.,._', 'V'],\n",
       " ['.,,.,,', '_.,uw.', '.___._', 'V'],\n",
       " [',_._.,', ',__uw.', ',.__,,', 'V'],\n",
       " ['.,__,_', '_..uw,', '._..,_', 'V'],\n",
       " [',,_..,', ',__uw.', '.,._.,', 'V'],\n",
       " ['_,..,.', ',._uw_', ',.,.,,', 'V'],\n",
       " ['__._.,', '_.,_uw', '_,.,_.', 'V'],\n",
       " [',_,,,,', '.,..uw', '.,._..', 'V'],\n",
       " [',.___.', '_,_,uw', ',,_._.', 'V'],\n",
       " [',...__', ',_..uw', '.._,_,', 'V'],\n",
       " ['_,,,,,', '_,,.uw', ',___..', 'V'],\n",
       " ['_._.__', '__._uw', '..,...', 'V'],\n",
       " ['......', '___,uw', '_._,..', 'V'],\n",
       " [',..,,.', ',_,.,_', 'cr,,__', 'V'],\n",
       " [',,.___', '..__,_', '.cr,._', 'V'],\n",
       " [',,,.,,', '...__.', ',,cr._', 'V'],\n",
       " [',._.,_', ',,.,._', ',._cr_', 'V'],\n",
       " [',__.,_', '._,._,', '_,_.cr', 'V'],\n",
       " ['_,,,.,', '._,,,_', 'cr_.,_', 'V'],\n",
       " ['.._.,_', ',.,.__', '_cr,.,', 'V'],\n",
       " ['_.,,._', ',.._..', '._cr__', 'V'],\n",
       " ['__,._,', '__,...', ',._cr,', 'V'],\n",
       " ['.__,..', '.__...', ',___cr', 'V'],\n",
       " [',,_.._', '.,__..', 'cr.._,', 'V'],\n",
       " ['.,,_,.', '.,.__.', '.cr,..', 'V'],\n",
       " ['_..,,.', ',.___.', '._cr_,', 'V'],\n",
       " ['_,.,_.', ',_,_.,', ',.,cr,', 'V'],\n",
       " ['.._.,,', '___,_,', ',,,,cr', 'V'],\n",
       " ['.,_._,', '.,,...', 'cr._.,', 'V'],\n",
       " ['__._..', '.,.,,,', '.cr,_.', 'V'],\n",
       " ['._..,,', '__,_._', ',.cr..', 'V'],\n",
       " ['_,._,.', ',._.._', '._,cr,', 'V'],\n",
       " [',_.._,', ',.._._', '..,_cr', 'V'],\n",
       " ['__.,.,', '____..', 'cr_,__', 'V'],\n",
       " ['_._.,,', ',..,.,', '_cr...', 'V'],\n",
       " [',,,.._', '.,.__,', '.,cr..', 'V'],\n",
       " ['.._,_,', '_,_,..', '.,.cr,', 'V'],\n",
       " ['_,_.._', '._____', ',_._cr', 'V'],\n",
       " ['._.__.', '_.,,,_', 'cr___.', 'V'],\n",
       " ['_.,_,_', '__,,,,', '_cr._.', 'V'],\n",
       " [',...,_', '._,_._', '._cr,,', 'V'],\n",
       " [',,,.__', '.,..,_', ',.,cr.', 'V'],\n",
       " ['___._.', '__..,_', ',__.cr', 'V'],\n",
       " ['_____.', '.,,,.,', 'cr_..,', 'V'],\n",
       " ['_..,_.', ',_,_,_', ',cr,._', 'V'],\n",
       " ['_...,,', '.,.,.,', '_.cr._', 'V'],\n",
       " [',._,__', '_,.,.,', '_._cr.', 'V'],\n",
       " ['.,,._,', '.._,__', '.,,_cr', 'V'],\n",
       " ['._,,.,', ',_,,._', 'dr___.', 'D'],\n",
       " ['_,.___', ',,.,,_', ',dr,,_', 'D'],\n",
       " [',,.._,', '.,.___', '.,dr..', 'D'],\n",
       " ['.,.,..', '.,_.._', ',._dr,', 'D'],\n",
       " ['_,.___', '_,._,.', ',___dr', 'D'],\n",
       " ['..,,.,', ',,__,,', 'dr,,.,', 'D'],\n",
       " ['.,..,,', '..____', '.dr,,,', 'D'],\n",
       " [',,__.,', '.,.,,,', '..dr,,', 'D'],\n",
       " ['._._.,', '.,_,_,', '.,_dr_', 'D'],\n",
       " ['._,___', ',,._,_', '_.._dr', 'D'],\n",
       " ['._,.,,', '.,_.,,', 'dr,,._', 'D'],\n",
       " ['_.,__,', '..__,.', '_dr,._', 'D'],\n",
       " [',,._,.', '_.,.,_', ',.dr.,', 'D'],\n",
       " [',_,.,.', '___.,_', '__,dr.', 'D'],\n",
       " ['_.,.,_', ',._...', '__,.dr', 'D'],\n",
       " ['..__,.', ',.____', 'dr.,__', 'D'],\n",
       " ['__,,__', '.,,,__', '.dr,_,', 'D'],\n",
       " ['_,,_..', '._,,,_', '..dr_.', 'D'],\n",
       " [',.__.,', '.._..,', '._.dr,', 'D'],\n",
       " ['__..,.', '._,_.,', ',__.dr', 'D'],\n",
       " [',_._,.', '_,,.,_', 'dr,._.', 'D'],\n",
       " ['_,_.,_', '._,_.,', ',dr_._', 'D'],\n",
       " ['_,...,', ',,.,..', ',,dr,,', 'D'],\n",
       " ['__,,,,', '_.,,,,', '.__dr,', 'D'],\n",
       " ['_..,_.', ',,__._', ',_,.dr', 'D'],\n",
       " [',_..,_', '__,__.', 'dr,__,', 'D'],\n",
       " ['_,.,_.', ',,.__,', ',dr,_.', 'D'],\n",
       " ['.,__.,', ',.,,._', ',_dr,.', 'D'],\n",
       " ['..___.', ',_,...', '_._dr,', 'D'],\n",
       " ['_,__._', '_.,_._', '..__dr', 'D'],\n",
       " ['___._.', ',.,,.,', 'dr..__', 'D'],\n",
       " ['..,,._', ',,__,.', '.dr,.,', 'D'],\n",
       " ['____,,', ',,,.._', '..dr,_', 'D'],\n",
       " ['._.._,', '.,.,.,', '__.dr_', 'D'],\n",
       " ['..,.__', '_,__,,', '__._dr', 'D'],\n",
       " ['_.,.,_', '_.,,,.', 'r.,,_,', 'C'],\n",
       " ['__.._,', ',.__..', ',r_,._', 'C'],\n",
       " ['_,.,_,', ',,____', ',,r.,_', 'C'],\n",
       " ['_,.___', ',,__..', ',,,r,,', 'C'],\n",
       " [',,.,_,', '___,,.', '___,r,', 'C'],\n",
       " [',..,,_', ',._.__', ',....r', 'C'],\n",
       " ['.__,._', ',..___', 'r,,,_,', 'C'],\n",
       " ['_.._,.', '.,____', ',r.,._', 'C'],\n",
       " ['____._', '.,....', ',,r.__', 'C'],\n",
       " [',.,_..', '..,_.,', '_..r._', 'C'],\n",
       " ['.._,..', '__.._.', '__,_r,', 'C'],\n",
       " [',,___.', '_.,__,', '.__,,r', 'C'],\n",
       " ['.,_,.,', '.._.._', 'r____,', 'C'],\n",
       " [',._...', ',,__,.', '.r,_,,', 'C'],\n",
       " [',..__.', '_.,,_.', '..r..,', 'C'],\n",
       " [',.,.,_', '__.,._', ',._r..', 'C'],\n",
       " ['.__.__', ',.,,._', '...,r.', 'C'],\n",
       " [',.__..', ',_,...', ',,,__r', 'C'],\n",
       " ['_,_,,,', '_,..__', 'r,,.,_', 'C'],\n",
       " [',__.._', ',__.._', ',r__..', 'C'],\n",
       " [',,,.__', '.,,_,,', ',,r_,_', 'C'],\n",
       " ['_,_.,,', '_._,__', '_._r._', 'C'],\n",
       " ['__,._,', ',_.,,.', ',._.r.', 'C'],\n",
       " ['._,_,,', '.__.,_', '_,_,.r', 'C'],\n",
       " ['_,_,._', '_....,', 'r.._.,', 'C'],\n",
       " [',_,_,_', '_,_.,_', '_r,,..', 'C'],\n",
       " ['_,,._,', '...___', '.,r_,_', 'C'],\n",
       " ['_,..,_', ',.,,_.', '_,.r,.', 'C'],\n",
       " [',__,..', '_._.,_', ',__.r.', 'C'],\n",
       " [',__,_.', '..,,_.', '.,.,.r', 'C'],\n",
       " ['.._.,.', '.,_,.,', 'r_..,.', 'C'],\n",
       " ['_,__._', '.___,,', '.r._,,', 'C'],\n",
       " ['__,..,', ',.._,.', '__r.__', 'C'],\n",
       " ['.,.,,.', ',__.__', '___r,.', 'C'],\n",
       " ['.,,.,,', ',._.._', '..,,r_', 'C'],\n",
       " ['_.____', '__.._.', '_.,..r', 'C'],\n",
       " [',,_..,', '.___._', 'r..,,_', 'C'],\n",
       " ['..__..', ',__.__', ',r,._,', 'C'],\n",
       " [',._,._', ',.....', '_.r,_,', 'C'],\n",
       " ['_,.__.', ',_.,__', ',_,r__', 'C'],\n",
       " ['_,_,,_', '.,,._.', ',_..r_', 'C'],\n",
       " ['.,.,._', ',,_._.', '_.,._r', 'C'],\n",
       " ['.._,.,', '__.,.,', ',__...', 'V'],\n",
       " ['..___,', ',,,.._', '.___,_', 'V'],\n",
       " [',__,,,', '.,__,_', '.,_.,.', 'V'],\n",
       " [',_._..', '_,,.,.', ',.._,_', 'V'],\n",
       " [',_._._', ',._.__', '._,.,.', 'V'],\n",
       " ['.,,_,.', '..__..', ',._._,', 'V'],\n",
       " [',__.,.', ',,,,._', ',_.._.', 'V'],\n",
       " ['_,_.,.', '__,,_,', '_._,_.', 'V'],\n",
       " ['_.._,_', ',,___.', '.__.,.', 'V'],\n",
       " ['_.,_..', '_,.__.', ',..,,,', 'V'],\n",
       " ['..,.,_', '.,,._,', '__.,__', 'V'],\n",
       " [',.,.__', ',.._..', '___,,_', 'V'],\n",
       " ['.,.._,', '.,.,._', '_.,...', 'V'],\n",
       " ['.__,..', '..._.,', ',.,.._', 'V'],\n",
       " [',._,,_', '_,.,..', ',_.,..', 'V'],\n",
       " ['.,,,_,', '_,__,_', '._.,_.', 'V'],\n",
       " ['_,,_,,', '_,_.,,', '._,___', 'V'],\n",
       " ['.__.._', '..,__.', ',_.,,.', 'V'],\n",
       " ['._,.._', ',.,__.', '_._,,.', 'V'],\n",
       " [',_._.,', ',_,,_,', '...,.,', 'V'],\n",
       " ['_,_,.,', '.,_.,_', '_,_,.,', 'V'],\n",
       " [',_,,..', ',_,_._', '_,..._', 'V'],\n",
       " ['.__,._', ',,,._.', '_.,__,', 'V'],\n",
       " ['_.,,..', ',,,._,', '..,_.,', 'V'],\n",
       " ['_,.,,,', '_.,___', '_.__._', 'V'],\n",
       " [',..__.', '._,_._', ',..._,', 'V'],\n",
       " [',,,.,_', ',_..._', '_.,.._', 'V'],\n",
       " ['_._.._', '.....,', '_.,_,_', 'V'],\n",
       " ['._,,..', '._.,_,', ',.,_,_', 'V'],\n",
       " ['.__,,.', ',,,_,.', '.__..,', 'V'],\n",
       " ['_.___,', ',_,,__', ',..__.', 'V'],\n",
       " [',.,,,_', '....,,', '_,_,,,', 'V'],\n",
       " [',..._.', ',,,.,.', ',,,..,', 'V'],\n",
       " ['._,___', ',.,,,.', '._,.,.', 'V'],\n",
       " ['.,_.._', ',.,._.', '.__,,.', 'V'],\n",
       " [',__,,.', '__,,,_', ',._...', 'V'],\n",
       " ['..._.,', ',..__,', '__.,_,', 'V'],\n",
       " [',.,,,.', ',_._,.', '_..__,', 'V'],\n",
       " ['.,,._,', '_,___,', ',_,_._', 'V'],\n",
       " ['..,._,', '__..,.', '..,_._', 'V'],\n",
       " ['_.,,__', '.._...', ',,_.._', 'V'],\n",
       " [',.._,_', ',__._.', '_.,,,,', 'V'],\n",
       " ['_,.___', '..,._,', '.__,..', 'V'],\n",
       " [',,._.,', '__._..', '_._...', 'V'],\n",
       " ['_,,,_.', '__.,.,', '_,.,,.', 'V'],\n",
       " ['_,.,,,', '_.,.,_', '.,..__', 'V'],\n",
       " ['.__.,.', '_,___,', '__._..', 'V'],\n",
       " ['.,,_..', '.__,__', '__,.__', 'V'],\n",
       " [',__.,.', ',_,__,', ',.,__,', 'V']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos todos los datos en x (variables), y (clasificacion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data.get_x_y(train) #devuelve  self.np_data = self.one_hot_encode(self.samples_char_sep)\n",
    "x_val, y_val = data.get_x_y(val)\n",
    "x_test, y_test = data.get_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]\n",
    "#print(x_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V' 'C' 'A' 'V' 'V' 'V' 'V' 'V' 'V' 'V']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------train_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 4 | F2-uw 7 | F2-w 8 | F2-noop 12 | \n",
      "F3 cr:    F2-wu 6 | F2-uw 6 | F2-w 9 | F2-noop 6 | \n",
      "F3 r:    F2-wu 4 | F2-uw 4 | F2-w 11 | F2-noop 10 | \n",
      "F3 noop:    F2-wu 10 | F2-uw 9 | F2-w 12 | F2-noop 14 | \n",
      "\n",
      "Positive samples count: 56\n",
      "Total samples count: 132\n",
      "Positive class ratio: 0.42424242424242425\n",
      "--------test_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 19 | F2-uw 15 | F2-w 19 | F2-noop 20 | \n",
      "F3 cr:    F2-wu 16 | F2-uw 14 | F2-w 17 | F2-noop 25 | \n",
      "F3 r:    F2-wu 21 | F2-uw 22 | F2-w 20 | F2-noop 25 | \n",
      "F3 noop:    F2-wu 20 | F2-uw 20 | F2-w 22 | F2-noop 23 | \n",
      "\n",
      "Positive samples count: 142\n",
      "Total samples count: 318\n",
      "Positive class ratio: 0.44654088050314467\n",
      "--------val_original-------- \n",
      "\n",
      "Number of samples by case:\n",
      "F3 dr:    F2-wu 2 | F2-uw 3 | F2-w 3 | F2-noop 3 | \n",
      "F3 cr:    F2-wu 3 | F2-uw 5 | F2-w 4 | F2-noop 4 | \n",
      "F3 r:    F2-wu 5 | F2-uw 4 | F2-w 5 | F2-noop 7 | \n",
      "F3 noop:    F2-wu 5 | F2-uw 6 | F2-w 8 | F2-noop 12 | \n",
      "\n",
      "Positive samples count: 30\n",
      "Total samples count: 79\n",
      "Positive class ratio: 0.379746835443038\n"
     ]
    }
   ],
   "source": [
    "train_original = data.reverse_encoding(data.get_x_y(train_unshuffled)[0])\n",
    "val_original = data.reverse_encoding(x_val)\n",
    "test_original = data.reverse_encoding(x_test)\n",
    "\n",
    "print(\"--------train_original--------\", '\\n')\n",
    "pos_train_ratio = get_stats_and_ratio(train_original)\n",
    "print(\"--------test_original--------\", '\\n')\n",
    "pos_test_ratio = get_stats_and_ratio(test_original)\n",
    "print(\"--------val_original--------\", '\\n')\n",
    "pos_val_ratio = get_stats_and_ratio(val_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['___._.', '__..,_', ',__.cr', 'V'], [',,__,,', '_._.,w', ',,,r_.', 'C'], [',,,._.', '__.,uw', '.cr_._', 'V'], ['_.._,,', '__,,uw', ',,.._r', 'C'], ['_,._..', '.._w.,', ',_,_dr', 'D'], ['__._.,', '_.,_uw', '_,.,_.', 'V'], ['.__,..', ',_wu._', 'r___..', 'C'], [',_..,,', ',_w._.', '.,_dr.', 'D'], ['_.,_,_', '__,,,,', '_cr._.', 'V'], ['.__.__', '.,w.__', '_._.r.', 'C'], [',._,__', ',,wu__', ',.,_cr', 'V'], ['.,,.,,', '_.,uw.', '.___._', 'V'], ['.,._,_', '_,.wu.', ',_,.dr', 'V'], [',_.,._', '.,,uw_', '__._cr', 'V'], [',_,,__', '.__uw.', ',r,,._', 'C'], [',.,,_,', '_,.w,.', ',_.,,.', 'V'], ['.___,_', ',,.,wu', ',r..__', 'C'], ['_,,_,,', '_,_.,,', '._,___', 'V'], ['_.,_,_', ',_w._,', ',dr,..', 'D'], ['._.,,.', '._,w,_', '_,.._,', 'V'], [',..,__', '.,w.,_', '.___cr', 'V'], [',._,._', ',.....', '_.r,_,', 'C'], [',,.._.', '...w.,', 'cr,,,,', 'V'], [',_,,,,', '..uw__', '_,__cr', 'V'], ['.__.._', '..,__.', ',_.,,.', 'V'], [',_._.,', ',__uw.', ',.__,,', 'V'], [',___._', 'w.,_.,', ',..cr,', 'V'], [',.__,_', '__..wu', ',__,,_', 'V'], ['____._', ',._,wu', ',.,..,', 'V'], [',____.', '.__.wu', ',_r,__', 'C'], ['__.._.', '__wu..', ',_dr..', 'V'], [',,_.._', '_.,,uw', ',,,r,_', 'C'], ['.,,._,', '_,___,', ',_,_._', 'V'], ['_,,_,_', '..,uw.', '.,dr,_', 'A'], [',_,_,,', '_w..,,', ',,,,r.', 'C'], ['_,_,._', '..,,uw', 'dr__,.', 'A'], ['__,,_.', ',uw_._', '._____', 'V'], ['_,_,.,', '.,_.,_', '_,_,.,', 'V'], ['_,__,_', '.wu_.,', '.dr_,,', 'V'], ['._,._,', '__.._w', ',cr___', 'V'], ['___.__', '_w_,_,', '..cr__', 'V'], ['.,,,._', '_,wu._', '_.cr,_', 'V'], ['._____', ',._.w,', 'dr,,_.', 'D'], ['___._.', 'wu__,,', 'dr,_,_', 'V'], [',,,_,.', ',,uw,.', '_.,,,.', 'V'], [',__,,,', '.,__,_', '.,_.,.', 'V'], [',.,,,,', '_,,,wu', 'dr_...', 'V'], [',__,_.', '..,,_.', '.,.,.r', 'C'], ['_,.__.', ',_.,__', ',_,r__', 'C'], [',,__..', '.,uw._', '._.dr,', 'A'], ['.,....', 'wu..,.', '.,r,_.', 'C'], ['.._.,.', '.,_,.,', 'r_..,.', 'C'], [',,.___', '..__,_', '.cr,._', 'V'], ['____..', '__._.w', '.__._,', 'V'], [',__.,_', '._,._,', '_,_.cr', 'V'], [',_.,,_', 'uw,..,', ',dr_,.', 'A'], ['.__._,', '.wu,,.', 'cr.__,', 'V'], ['..__,.', ',.____', 'dr.,__', 'D'], ['_,,,_.', '__.,.,', '_,.,,.', 'V'], ['.._.,,', '___,_,', ',,,,cr', 'V'], [',,,.__', '.,,_,,', ',,r_,_', 'C'], ['.__.__', ',.,,._', '...,r.', 'C'], ['_...,_', 'uw__.,', ',_cr,_', 'V'], ['__._,_', '_.wu,.', ',,_dr.', 'V'], [',.,.,.', '_.uw.,', ',__,r,', 'C'], [',,_.._', '.,__..', 'cr.._,', 'V'], [',__,._', 'w,._,.', '_,cr__', 'V'], ['.,_,__', '...wu.', ',cr_,,', 'V'], ['._.__.', '_.,,,_', 'cr___.', 'V'], ['.,___.', '_,.,_w', ',.,...', 'V'], [',_._._', ',._.__', '._,.,.', 'V'], [',_,_,_', '_,_.,_', '_r,,..', 'C'], ['._,_,,', '.__.,_', '_,_,.r', 'C'], ['.___,.', '.,wu__', ',,_.,,', 'V'], ['.._.._', ',._wu,', ',r__,,', 'C'], [',,.,,.', ',uw,_,', '_cr.__', 'V'], ['__..,.', '._,_.,', ',__.dr', 'D'], ['_._.,,', ',.uw,,', ',_,..,', 'V'], ['_,.,,_', '..,_w_', '_,_dr.', 'D'], [',.._,.', 'wu.,,_', '.,.r,.', 'C'], [',,._,.', '_.,.,_', ',.dr.,', 'D'], ['_,.,__', 'w_,,.,', '_,,._r', 'C'], ['_,..,_', '_..wu,', 'cr_,._', 'V'], ['.,__,_', '_..uw,', '._..,_', 'V'], ['_,,.,_', '...wu.', '_,.___', 'V'], ['.,_._,', '.,,...', 'cr._.,', 'V'], ['.,_,,,', '_..,w,', '__.,__', 'V'], ['..,__,', ',,,,wu', '__..,.', 'V'], ['.,.,,.', '.,wu.,', '..____', 'V'], ['..,_,.', '.uw_._', 'cr..,,', 'V'], ['.,,,_.', '_uw._.', ',.,_dr', 'A'], ['..___.', ',,,,_w', '...,r,', 'C'], ['.,.,,.', ',__.__', '___r,.', 'C'], ['_.,_.,', '_w,__,', '.,dr__', 'D'], ['__,,,_', '_wu_,,', '..dr._', 'V'], [',..,,,', ',.,,w,', 'r,__..', 'C'], ['.,,.__', '._uw__', ',_r,_.', 'C'], ['_,,,_.', ',,.wu_', '_,_dr_', 'V'], ['._.___', '_w,,,_', 'r,,,_.', 'C'], ['_,.___', '..,._,', '.__,..', 'V'], ['__,..,', ',.._,.', '__r.__', 'C'], ['._.,..', ',uw.,.', '_..r.,', 'C'], ['.__,.,', ',.__wu', '__cr,_', 'V'], ['_.,_,_', ',,,uw,', '__.,._', 'V'], ['_,.,_.', ',,.__,', ',dr,_.', 'D'], ['.__,.,', ',_uw..', '_.,_,,', 'V'], [',,__.,', '.,.,,,', '..dr,,', 'D'], [',_,_,.', '__..w.', '_r__,.', 'C'], ['__.__,', '_uw.,,', '_.,,r,', 'C'], ['.,..__', 'wu.__.', '.,,.,r', 'C'], [',_..,.', '.,_uw,', '_dr__,', 'A'], ['...,__', ',,w_,,', '__.,,_', 'V'], ['.,_,,,', '_.,_w_', '_.,,__', 'V'], ['__.__,', ',_,wu,', '...,,r', 'C'], ['.,,,._', 'w,_.,_', '.,__,_', 'V'], [',.,._.', '_uw,,_', ',.r,,.', 'C'], ['_,_,,,', '_,..__', 'r,,.,_', 'C'], [',,,__,', ',___w_', '.dr.__', 'D'], [',..,_,', '__w.,_', '_.r.__', 'C'], ['.__,._', ',..___', 'r,,,_,', 'C'], [',.._,_', ',__._.', '_.,,,,', 'V'], [',..,,.', ',_,.,_', 'cr,,__', 'V'], [',._,,_', '_,.,..', ',_.,..', 'V'], ['_.___,', ',_,,__', ',..__.', 'V'], ['_,.___', '_,._,.', ',___dr', 'D'], ['_.,_._', '_w._.,', '...cr_', 'V'], ['..,.__', '_,__,,', '__._dr', 'D'], ['_.._,.', '.,____', ',r.,._', 'C'], [',_,.,.', ',_,.uw', ',._.r,', 'C'], [',.,.,,', '__,,.w', '_.cr,_', 'V'], [',,.._.', '.uw,.,', '_._,..', 'V'], ['__.._,', ',.__..', ',r_,._', 'C'], ['_,,,,,', 'w__...', '_,dr,.', 'D'], [',.,__,', '_wu___', ',,_.,,', 'V'], ['__,._,', '.,_.wu', ',,,r_.', 'C'], [',,.,_,', '___,,.', '___,r,', 'C'], ['._._._', '.,wu._', ',._r,.', 'C'], [',__,.,', '._,w._', ',,.r._', 'C'], ['__._,,', '.,uw,,', '_.dr_,', 'A'], [',,____', ',..wu,', ',__cr,', 'V'], [',,,...', ',,uw._', ',,.__.', 'V'], ['__.,.,', '____..', 'cr_,__', 'V'], ['..,.,.', ',,wu.,', '_,r.__', 'C'], ['.._.,,', 'uw_._,', 'r_.,..', 'C'], ['.,..,,', '..____', '.dr,,,', 'D'], ['.,_,_,', 'wu_,..', '__.,._', 'V'], ['__,,__', '.,,,__', '.dr,_,', 'D'], [',,,,,_', ',w_..,', '__,__,', 'V'], ['._,..,', ',_,wu_', '.,dr_,', 'V'], ['._,___', ',.,,,.', '._,.,.', 'V'], ['.,,,_,', 'w.,_.,', '__,..,', 'V'], ['____,,', '_uw._.', ',_.dr,', 'A'], ['_,.___', ',,.,,_', ',dr,,_', 'D'], ['.,_,_,', 'uw_,._', ',..,.,', 'V'], [',...,_', 'wu___.', '.,,.,_', 'V'], ['__,.._', '._wu.,', 'dr,,__', 'V'], [',._...', '_,wu._', '_,.,.,', 'V'], ['_.__,_', '_uw,,.', '_,_cr,', 'V'], ['____,.', ',wu..,', '_,_,_,', 'V'], ['._..,,', '__,_._', ',.cr..', 'V'], ['__....', ',,,w._', '..,cr,', 'V'], ['__,.._', '.,.w..', ',cr_.,', 'V'], [',..__.', '_.,,_.', '..r..,', 'C'], [',._,__', '.__w,,', ',,,_.r', 'C'], [',_,__,', '.,uw._', '_.._dr', 'A'], ['__,,._', 'w,..,,', ',._dr,', 'D'], [',.,._.', '.wu.__', '..,dr,', 'V'], ['.._,._', ',.w._.', ',_.,__', 'V'], [',,,,_.', 'uw._,_', '...r_.', 'C'], [',._,_,', '_w,..,', ',_,__r', 'C'], ['.__.,.', '_,___,', '__._..', 'V'], ['_,...,', ',,.,..', ',,dr,,', 'D'], ['.,..__', '_,uw_.', ',_,.,.', 'V'], ['.,_.,,', ',wu,,_', '._cr.,', 'V'], ['_.,,_,', 'uw,.,_', '._...r', 'C'], ['_,.__.', '_,,,.w', '.,r_..', 'C'], [',,_.._', ',,..wu', ',__dr.', 'V'], ['...,_.', '___w.,', 'r___..', 'C'], ['_..,,.', ',.___.', '._cr_,', 'V'], ['..._._', '_....w', '.r_,._', 'C'], ['_.,.,.', '._,uw.', ',.,r__', 'C'], ['_.._,_', 'uw_,__', 'dr..,,', 'A'], ['_,_.._', '._____', ',_._cr', 'V'], [',..,,,', '__w___', 'dr.,..', 'D'], ['.,.._,', '.,.,._', '_.,...', 'V'], ['.,,,_,', '.wu_,,', ',,_,.,', 'V'], ['___,.,', ',w._.,', '_,.._,', 'V'], ['..._,.', '.,uw.,', '..cr._', 'V'], [',,.,,.', 'wu_,.,', '_cr_,_', 'V'], ['_,,.,.', '._.wu.', ',_,.,,', 'V'], [',..,,_', ',_,_uw', '.dr..,', 'A'], ['__,...', '_._.wu', '.,._.,', 'V'], [',..._.', '..wu.,', '.,.,,r', 'C'], ['._,.._', ',.,__.', '_._,,.', 'V'], ['_,_.,.', '__,,_,', '_._,_.', 'V'], [',,,___', '_w.._.', '_,r___', 'C'], ['.,.,._', ',,_._.', '_.,._r', 'C'], [',_..,_', '__,__.', 'dr,__,', 'D'], [',_.._,', ',.__w.', '..,.,.', 'V'], [',_,.,.', '___.,_', '__,dr.', 'D'], ['__,_..', ',.w,..', '.___dr', 'D'], ['_...._', 'w,__._', '_dr.__', 'D'], ['_.,_..', '_,.__.', ',..,,,', 'V'], [',.__..', ',_,...', ',,,__r', 'C'], [',,_,._', '_w_._,', '_,_...', 'V'], [',.,.,_', '__.,._', ',._r..', 'C'], ['.._...', '._,w,_', 'dr,_.,', 'D'], [',__.,.', ',..wu_', '_,._cr', 'V'], ['_..,_.', ',,__._', ',_,.dr', 'D'], [',...,_', '._,_._', '._cr,,', 'V'], ['__.___', 'w,.,,,', '.,,.dr', 'D'], [',..,.,', ',,.uw_', '_.._r_', 'C'], ['_,._,.', ',._.._', '._,cr,', 'V'], ['.__,._', ',,,._.', '_.,__,', 'V'], ['_..___', 'w.__,_', '_..,__', 'V'], [',.,,.,', ',,,_wu', '._,_dr', 'V'], ['.,.,.,', '_,,w..', ',._.__', 'V'], ['_...,_', ',uw__,', ',_cr_,', 'V'], [',_.._,', ',.._._', '..,_cr', 'V'], [',.___.', '_,_,uw', ',,_._.', 'V'], ['._._,.', '.,,.wu', '_dr__.', 'V'], ['.,_.._', ',,_,w,', ',,..,_', 'V'], ['_,_,__', ',.,.wu', ',.,.r.', 'C'], ['_,__..', '_,_wu,', ',,_.,,', 'V'], ['..,,_.', 'wu.,_,', '_dr,,,', 'V'], ['_,.,_.', ',_,_.,', ',.,cr,', 'V'], [',,_,,.', ',_uw__', '_r_.._', 'C'], [',,._,,', 'uw.,,.', 'cr.,_,', 'V'], ['.,.._,', '_uw.,,', ',_,,,r', 'C'], ['_.,.,_', '_.,,,.', 'r.,,_,', 'C'], ['_.,__,', '..__,.', '_dr,._', 'D'], ['__,__.', ',.wu,.', ',,.,r_', 'C'], [',,._,.', ',_wu,.', '.,_,_,', 'V'], ['.,,_,.', '.,.__.', '.cr,..', 'V'], ['.,_,__', '..,,wu', '..,___', 'V'], ['__.,,.', ',..uw,', '.__.dr', 'A'], ['..._.,', ',.,,wu', ',cr,_,', 'V'], ['_.,.__', '_,_,uw', '_,_dr,', 'A'], ['_...,,', '.,.,.,', '_.cr._', 'V'], ['_,,_,_', '_w,__.', '..,_,_', 'V'], [',.__.,', '.._..,', '._.dr,', 'D'], ['.,__.,', ',.,,._', ',_dr,.', 'D'], [',.,..,', '.wu_,,', '.r,._,', 'C'], [',__,._', 'w_._,.', 'r__,..', 'C'], ['..__,.', ',_wu..', '.cr.,_', 'V'], [',_._..', '_,,.,.', ',.._,_', 'V'], [',__._,', 'w_.___', 'dr._.,', 'D'], ['._,,.,', ',_,,._', 'dr___.', 'D'], [',,,_,.', '_._w,_', '_.r.,_', 'C'], [',.,.__', ',.._..', '___,,_', 'V'], ['._,_..', 'wu,...', '.,cr..', 'V'], ['.._.,_', ',.,.__', '_cr,.,', 'V'], ['.,_,,.', 'uw._._', ',,,,._', 'V'], ['..._.,', '.,_w_.', ',.__cr', 'V'], ['.._..,', '_.,_w,', 'cr__.,', 'V'], ['.,._..', '..uw_.', 'r.,.,,', 'C'], ['..___,', '._,.uw', 'cr,__.', 'V'], [',,,.,_', ',_..._', '_.,.._', 'V'], ['_..__,', '._wu,.', '.dr,,.', 'V'], [',._.._', '.wu,._', '___.r_', 'C'], ['_..,_.', ',_,_,_', ',cr,._', 'V'], [',_._,.', '_,,.,_', 'dr,._.', 'D'], ['___._.', ',.,,.,', 'dr..__', 'D'], [',,.._,', '_,..wu', 'cr,_,_', 'V'], ['..,._,', ',,.uw.', '.._cr_', 'V'], ['_...._', '..w_.,', 'r,.,,.', 'C'], ['.,....', '__w,__', '_,dr,_', 'D'], [',,._.,', '__._..', '_._...', 'V'], [',.,,,_', '_uw_,.', 'r____.', 'C'], ['__.,.,', 'w._,_.', '_..,cr', 'V'], [',.,.__', ',wu_,,', '__.,,r', 'C'], ['_,.__.', ',wu.._', ',._r_.', 'C'], ['__,,,_', ',w..,.', '_.___.', 'V'], ['___.._', '_w.,.,', 'dr,._.', 'D'], ['._,__,', 'uw,._,', '_r.,.,', 'C'], ['_,_,..', '__uw_,', ',,,r..', 'C'], ['_,...,', '.,_uw.', 'r_._..', 'C'], ['.,.,._', '.uw_,.', '.,,_,,', 'V'], [',_,,,,', 'wu.,,,', '.,_dr_', 'V'], [',.._,,', 'wu_,.,', '.._,,.', 'V'], ['_,,,_,', '.__..w', '__,cr,', 'V'], ['_..__.', '__w_.,', ',cr,.,', 'V'], ['_.,,,,', '.w_.,,', '_,,.,,', 'V'], ['._,.,.', 'wu__..', '_,,_,,', 'V'], ['....._', 'uw____', '.,r_..', 'C'], [',__,..', '_._.,_', ',__.r.', 'C'], [',._.,_', ',,.,._', ',._cr_', 'V'], ['_.,,_,', ',wu.,_', 'dr____', 'V'], ['.,_...', ',..,.w', 'dr_._.', 'D'], [',_._,,', 'wu__..', ',,,.cr', 'V'], ['_____.', '.,,,.,', 'cr_..,', 'V'], [',,,,_,', '._.,_w', ',dr__.', 'D'], [',,_.__', ',_w.,.', '__....', 'V'], ['.,._,.', '.__,uw', ',_dr_,', 'A'], ['...._,', 'wu_._.', 'r__._,', 'C'], [',._,__', '_,.,.,', '_._cr.', 'V'], ['_,,._,', '...___', '.,r_,_', 'C'], ['_...__', '..,w__', ',_cr..', 'V'], ['__,,_,', ',uw,_,', '.,____', 'V'], [',_,_,.', 'wu___,', '_.,_r,', 'C'], ['.,_.._', '._w,,.', '.,.,.,', 'V'], ['_.__,,', '_,w,_,', '__.cr.', 'V'], [',,.,_.', '.,,wu,', '__cr,_', 'V'], ['.._,,_', 'uw._.,', ',.,.,,', 'V'], [',..,,_', ',._.__', ',....r', 'C'], ['_,,,,,', '_,,.uw', ',___..', 'V'], ['.,._._', '.w__..', ',r,,_.', 'C'], [',..._.', ',,,.,.', ',,,..,', 'V'], ['_.,,._', ',.._..', '._cr__', 'V'], [',_,,,,', '.,..uw', '.,._..', 'V'], ['.,._._', 'wu_.,_', '_.,,__', 'V'], [',___._', '.._wu,', '_...r,', 'C'], [',__.,_', 'uw.,,,', ',cr.,_', 'V'], ['__,._,', ',_.,,.', ',._.r.', 'C'], [',.,_..', '..,_.,', '_..r._', 'C'], [',.,_._', '.__,uw', ',,._dr', 'A'], ['....,,', '__uw_,', ',cr,..', 'V'], ['__.___', '.._wu_', '_dr.,_', 'V']]\n"
     ]
    }
   ],
   "source": [
    "print(test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mandamos las etiquetas codificadas al dispositivo del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un codificador de etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#input_tensor = input_tensor.requires_grad_()  # Esto habilita el cálculo de gradientes\n",
    "\n",
    "#cambio de torch.float a torch.long\n",
    "\n",
    "# Ajustar el codificador a las etiquetas y transformarlas a num enteros\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_trainP = y_train\n",
    "\n",
    "#Un tensor es una estructura de datos similar a matrices o arrays, pero con soporte para operaciones avanzadas en GPU.\n",
    "# Convertir las etiquetas a tensores de PyTorch\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "#se mueven los datos a la CPU o GPU para que puedan ser procesados por PyTorch durante el entrenamiento o la inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor(3), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(3), tensor(3), tensor(1), tensor(3), tensor(1), tensor(2), tensor(3), tensor(3), tensor(2), tensor(3), tensor(2), tensor(1), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(1), tensor(0), tensor(3), tensor(1), tensor(3), tensor(2), tensor(1), tensor(3), tensor(3), tensor(3), tensor(3), tensor(0), tensor(3), tensor(3), tensor(2), tensor(3), tensor(3), tensor(0), tensor(3), tensor(3), tensor(1), tensor(3), tensor(1), tensor(0), tensor(3), tensor(3), tensor(3), tensor(3), tensor(1), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(1), tensor(3), tensor(3), tensor(3), tensor(3), tensor(1), tensor(1), tensor(3), tensor(3), tensor(3), tensor(3), tensor(1), tensor(3), tensor(3), tensor(1), tensor(2), tensor(3), tensor(1), tensor(1), tensor(3), tensor(3), tensor(2), tensor(3), tensor(2), tensor(1), tensor(3), tensor(1), tensor(3), tensor(3), tensor(3), tensor(2), tensor(3), tensor(2), tensor(0), tensor(2), tensor(3), tensor(2), tensor(0), tensor(3), tensor(3), tensor(3), tensor(3), tensor(1), tensor(1), tensor(3), tensor(3), tensor(3), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(3), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(2), tensor(2), tensor(2), tensor(3), tensor(2), tensor(1), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(0), tensor(3), tensor(3)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(set(y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = data.to_conv_format(x_train)\n",
    "x_val_cnn = data.to_conv_format(x_val)\n",
    "x_test_cnn = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_cnn)): #itereamos sobre cada tensor\n",
    "    x_train_cnn[i] = x_train_cnn[i].to(device)\n",
    "    x_val_cnn[i] = x_val_cnn[i].to(device)\n",
    "    x_test_cnn[i] = x_test_cnn[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 48])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cnn[0].shape #devuelve un par que indica (num de muestras, numero de funciones en total = 3*numMuestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cnn[0][2] #[x][y] accedes fx de la muestra y / max [2][25] ya que hay 3 funciones y este el ejemplo tenemos 26 muestras de train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train_cnn está representado como una matriz tridimensional en donde cada fila es la función y cada columna es la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 6 #cuantas veces ejecutaremos el entrenamiento, pero con dif pesos, entrena, parame, semillas\n",
    "epochs = 200 #época es una iteración completa sobre todo el conjunto de entrenamiento\n",
    "early_stopping_limit = 100 #si el cjto de val no ve una mejora durante 100 epocas consecutivas, el entrenam se para. Evitamos sobreajuste\n",
    "\n",
    "experiment_name=\"25per\"\n",
    "\n",
    "#el número de épocas determina cuántas veces el modelo va a ajustarse a los datos y aprender de ellos. Sin embargo, no siempre se necesita un número tan alto; por eso también se utilizan estrategias como el early stopping para evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(constructor, x_train, x_val, x_test, weight_decay, *argv):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    wrong_preds = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        model = constructor(*argv)\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "        train_losses.append([])\n",
    "        val_losses.append([])\n",
    "        train_accs.append([])\n",
    "        val_accs.append([])\n",
    "        \n",
    "        best_acc = 0\n",
    "\n",
    "        early_stopping_cnt = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = models.train_epoch(model, x_train, y_train, criterion, optimizer, epoch, 10, verbose=False)\n",
    "            val_loss, val_acc =models.eval_epoch(model, x_val, y_val, criterion, 'Validation', verbose=False)\n",
    "\n",
    "            \n",
    "            train_losses[-1].append(train_loss)\n",
    "            val_losses[-1].append(val_loss)\n",
    "            train_accs[-1].append(train_acc)\n",
    "            val_accs[-1].append(val_acc)\n",
    "            \n",
    "            model_name = constructor.__name__[:constructor.__name__.find('_')]\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'./{model_name}_model_TEMP_' + experiment_name)    \n",
    "                early_stopping_cnt = 0\n",
    "            else:\n",
    "                early_stopping_cnt += 1\n",
    "\n",
    "            if early_stopping_cnt >= early_stopping_limit:\n",
    "                break\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n",
    "    \n",
    "        accuracies.append(get_accuracy_by_cases(model, x_test, y_test, test_original))\n",
    "        precisions.append(get_precision_by_cases(model, x_test, y_test, test_original))\n",
    "        recalls.append(get_recall_by_cases(model, x_test, y_test, test_original))\n",
    "        f1_scores.append(get_f1_by_cases(precisions[-1], recalls[-1]))\n",
    "        \n",
    "        wrong_preds.append((f\"Experimento {i}\", get_wrong_predictions(model, x_test, y_test, test_original)))\n",
    "\n",
    "        if accuracies[-1]['Overall'] > best_accuracy:\n",
    "            torch.save(model.state_dict(), f'./best_{model_name}_model_' + experiment_name)    \n",
    "            best_accuracy = accuracies[-1]['Overall']\n",
    "\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test accuracy:\", accuracies[-1]['Overall'])\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test precision:\", precisions[-1]['Overall'])\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test recall:\", recalls[-1]['Overall'])\n",
    "        print(i + 1, \"/\", num_experiments, \"models trained | Current model test f1:\", f1_scores[-1]['Overall'])\n",
    "\n",
    "\n",
    "    \n",
    "    return accuracies, precisions, recalls, f1_scores, wrong_preds, [train_losses, val_losses, train_accs, val_accs], model\n",
    "    #return accuracies, precisions, wrong_preds, [train_losses, val_losses, train_accs, val_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_20844\\2901190800.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.8962264150943396\n",
      "1 / 6 models trained | Current model test precision: 0.7417993450767841\n",
      "1 / 6 models trained | Current model test recall: 0.7963650932400932\n",
      "1 / 6 models trained | Current model test f1: 0.7681143704686458\n",
      "2 / 6 models trained | Current model test accuracy: 0.9308176100628931\n",
      "2 / 6 models trained | Current model test precision: 0.8531725686942299\n",
      "2 / 6 models trained | Current model test recall: 0.943939393939394\n",
      "2 / 6 models trained | Current model test f1: 0.8962637989886133\n",
      "3 / 6 models trained | Current model test accuracy: 0.8962264150943396\n",
      "3 / 6 models trained | Current model test precision: 0.7756049682457311\n",
      "3 / 6 models trained | Current model test recall: 0.8463650932400932\n",
      "3 / 6 models trained | Current model test f1: 0.8094415388474357\n",
      "4 / 6 models trained | Current model test accuracy: 0.9528301886792453\n",
      "4 / 6 models trained | Current model test precision: 0.8722531680824397\n",
      "4 / 6 models trained | Current model test recall: 0.9329545454545454\n",
      "4 / 6 models trained | Current model test f1: 0.9015832935426542\n",
      "5 / 6 models trained | Current model test accuracy: 0.9433962264150944\n",
      "5 / 6 models trained | Current model test precision: 0.8788957688338493\n",
      "5 / 6 models trained | Current model test recall: 0.9496212121212121\n",
      "5 / 6 models trained | Current model test f1: 0.9128906912226445\n"
     ]
    }
   ],
   "source": [
    "cnn_accuracies, cnn_precisions, cnn_recall, cnn_f1, cnn_wrong_preds, cnn_epoch_stats, model = train_models(\n",
    "    models.CNN_Model, x_train_cnn, x_val_cnn, x_test_cnn, 0.0001, data, 64, 128, 4, -1, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Experimento 0',\n",
       "  ([(['_,_,._', '..,,uw', 'dr__,.', 'A'], 'V'),\n",
       "    (['_.,.__', '_,_,uw', '_,_dr,', 'A'], 'D'),\n",
       "    (['.,._,.', '.__,uw', ',_dr_,', 'A'], 'V'),\n",
       "    ([',.,_._', '.__,uw', ',,._dr', 'A'], 'V')],\n",
       "   [],\n",
       "   [],\n",
       "   [(['.,._,_', '_,.wu.', ',_,.dr', 'V'], 'D'),\n",
       "    (['__.._.', '__wu..', ',_dr..', 'V'], 'D'),\n",
       "    (['___._.', 'wu__,,', 'dr,_,_', 'V'], 'A'),\n",
       "    ([',.,,,,', '_,,,wu', 'dr_...', 'V'], 'A'),\n",
       "    (['__._,_', '_.wu,.', ',,_dr.', 'V'], 'A'),\n",
       "    (['__,,,_', '_wu_,,', '..dr._', 'V'], 'D'),\n",
       "    (['_,,,_.', ',,.wu_', '_,_dr_', 'V'], 'D'),\n",
       "    (['._,..,', ',_,wu_', '.,dr_,', 'V'], 'D'),\n",
       "    (['__,.._', '._wu.,', 'dr,,__', 'V'], 'D'),\n",
       "    ([',.,._.', '.wu.__', '..,dr,', 'V'], 'D'),\n",
       "    ([',,_.._', ',,..wu', ',__dr.', 'V'], 'D'),\n",
       "    ([',.,,.,', ',,,_wu', '._,_dr', 'V'], 'D'),\n",
       "    (['._._,.', '.,,.wu', '_dr__.', 'V'], 'D'),\n",
       "    (['..,,_.', 'wu.,_,', '_dr,,,', 'V'], 'D'),\n",
       "    (['_..__,', '._wu,.', '.dr,,.', 'V'], 'D'),\n",
       "    ([',_,,,,', 'wu.,,,', '.,_dr_', 'V'], 'A'),\n",
       "    (['_.,,_,', ',wu.,_', 'dr____', 'V'], 'A'),\n",
       "    (['__.___', '.._wu_', '_dr.,_', 'V'], 'D')])),\n",
       " ('Experimento 1',\n",
       "  ([(['_,_,._', '..,,uw', 'dr__,.', 'A'], 'D'),\n",
       "    (['_.,.__', '_,_,uw', '_,_dr,', 'A'], 'D'),\n",
       "    (['.,._,.', '.__,uw', ',_dr_,', 'A'], 'D'),\n",
       "    ([',.,_._', '.__,uw', ',,._dr', 'A'], 'D')],\n",
       "   [],\n",
       "   [],\n",
       "   [(['.,._,_', '_,.wu.', ',_,.dr', 'V'], 'D'),\n",
       "    (['__.._.', '__wu..', ',_dr..', 'V'], 'D'),\n",
       "    (['_,__,_', '.wu_.,', '.dr_,,', 'V'], 'D'),\n",
       "    (['___._.', 'wu__,,', 'dr,_,_', 'V'], 'A'),\n",
       "    ([',.,,,,', '_,,,wu', 'dr_...', 'V'], 'A'),\n",
       "    (['__._,_', '_.wu,.', ',,_dr.', 'V'], 'A'),\n",
       "    (['__,,,_', '_wu_,,', '..dr._', 'V'], 'A'),\n",
       "    (['_,,,_.', ',,.wu_', '_,_dr_', 'V'], 'A'),\n",
       "    (['._,..,', ',_,wu_', '.,dr_,', 'V'], 'A'),\n",
       "    (['__,.._', '._wu.,', 'dr,,__', 'V'], 'D'),\n",
       "    ([',.,._.', '.wu.__', '..,dr,', 'V'], 'A'),\n",
       "    ([',,_.._', ',,..wu', ',__dr.', 'V'], 'D'),\n",
       "    ([',.,,.,', ',,,_wu', '._,_dr', 'V'], 'D'),\n",
       "    (['._._,.', '.,,.wu', '_dr__.', 'V'], 'A'),\n",
       "    (['..,,_.', 'wu.,_,', '_dr,,,', 'V'], 'A'),\n",
       "    (['_..__,', '._wu,.', '.dr,,.', 'V'], 'A'),\n",
       "    ([',_,,,,', 'wu.,,,', '.,_dr_', 'V'], 'A'),\n",
       "    (['_.,,_,', ',wu.,_', 'dr____', 'V'], 'A'),\n",
       "    (['__.___', '.._wu_', '_dr.,_', 'V'], 'A')])),\n",
       " ('Experimento 2',\n",
       "  ([(['_,,_,_', '..,uw.', '.,dr,_', 'A'], 'V'),\n",
       "    ([',_,__,', '.,uw._', '_.._dr', 'A'], 'V'),\n",
       "    (['.,._,.', '.__,uw', ',_dr_,', 'A'], 'V'),\n",
       "    ([',.,_._', '.__,uw', ',,._dr', 'A'], 'V')],\n",
       "   [],\n",
       "   [],\n",
       "   [(['.,._,_', '_,.wu.', ',_,.dr', 'V'], 'D'),\n",
       "    (['_,__,_', '.wu_.,', '.dr_,,', 'V'], 'D'),\n",
       "    (['___._.', 'wu__,,', 'dr,_,_', 'V'], 'A'),\n",
       "    ([',.,,,,', '_,,,wu', 'dr_...', 'V'], 'D'),\n",
       "    (['__._,_', '_.wu,.', ',,_dr.', 'V'], 'A'),\n",
       "    (['_,,,_.', ',,.wu_', '_,_dr_', 'V'], 'D'),\n",
       "    (['._,..,', ',_,wu_', '.,dr_,', 'V'], 'A'),\n",
       "    (['__,.._', '._wu.,', 'dr,,__', 'V'], 'A'),\n",
       "    ([',.,._.', '.wu.__', '..,dr,', 'V'], 'A'),\n",
       "    ([',,_.._', ',,..wu', ',__dr.', 'V'], 'D'),\n",
       "    ([',.,,.,', ',,,_wu', '._,_dr', 'V'], 'D'),\n",
       "    (['._._,.', '.,,.wu', '_dr__.', 'V'], 'D'),\n",
       "    (['..,,_.', 'wu.,_,', '_dr,,,', 'V'], 'A'),\n",
       "    (['_..__,', '._wu,.', '.dr,,.', 'V'], 'D'),\n",
       "    ([',_,,,,', 'wu.,,,', '.,_dr_', 'V'], 'A'),\n",
       "    (['_.,,_,', ',wu.,_', 'dr____', 'V'], 'A'),\n",
       "    (['__.___', '.._wu_', '_dr.,_', 'V'], 'D')])),\n",
       " ('Experimento 3',\n",
       "  ([(['_,_,._', '..,,uw', 'dr__,.', 'A'], 'V'),\n",
       "    (['.,._,.', '.__,uw', ',_dr_,', 'A'], 'V'),\n",
       "    ([',.,_._', '.__,uw', ',,._dr', 'A'], 'V')],\n",
       "   [],\n",
       "   [],\n",
       "   [(['.,._,_', '_,.wu.', ',_,.dr', 'V'], 'D'),\n",
       "    (['_,__,_', '.wu_.,', '.dr_,,', 'V'], 'A'),\n",
       "    (['___._.', 'wu__,,', 'dr,_,_', 'V'], 'A'),\n",
       "    ([',.,,,,', '_,,,wu', 'dr_...', 'V'], 'A'),\n",
       "    (['__._,_', '_.wu,.', ',,_dr.', 'V'], 'A'),\n",
       "    (['_,,,_.', ',,.wu_', '_,_dr_', 'V'], 'A'),\n",
       "    (['__,.._', '._wu.,', 'dr,,__', 'V'], 'A'),\n",
       "    ([',.,._.', '.wu.__', '..,dr,', 'V'], 'A'),\n",
       "    ([',,_.._', ',,..wu', ',__dr.', 'V'], 'D'),\n",
       "    ([',.,,.,', ',,,_wu', '._,_dr', 'V'], 'D'),\n",
       "    (['._._,.', '.,,.wu', '_dr__.', 'V'], 'A'),\n",
       "    (['..,,_.', 'wu.,_,', '_dr,,,', 'V'], 'A'),\n",
       "    (['_..__,', '._wu,.', '.dr,,.', 'V'], 'A'),\n",
       "    ([',_,,,,', 'wu.,,,', '.,_dr_', 'V'], 'A'),\n",
       "    (['_.,,_,', ',wu.,_', 'dr____', 'V'], 'A'),\n",
       "    (['__.___', '.._wu_', '_dr.,_', 'V'], 'A')])),\n",
       " ('Experimento 4',\n",
       "  ([(['_,,_,_', '..,uw.', '.,dr,_', 'A'], 'V'),\n",
       "    (['__._,,', '.,uw,,', '_.dr_,', 'A'], 'D'),\n",
       "    ([',_,__,', '.,uw._', '_.._dr', 'A'], 'V'),\n",
       "    ([',.,_._', '.__,uw', ',,._dr', 'A'], 'V')],\n",
       "   [(['__.__,', ',_,wu,', '...,,r', 'C'], 'V'),\n",
       "    ([',.,.__', ',wu_,,', '__.,,r', 'C'], 'V'),\n",
       "    ([',_,_,.', 'wu___,', '_.,_r,', 'C'], 'V')],\n",
       "   [],\n",
       "   [(['.,._,_', '_,.wu.', ',_,.dr', 'V'], 'D'),\n",
       "    (['__.._.', '__wu..', ',_dr..', 'V'], 'D'),\n",
       "    (['_,__,_', '.wu_.,', '.dr_,,', 'V'], 'D'),\n",
       "    (['__._,_', '_.wu,.', ',,_dr.', 'V'], 'A'),\n",
       "    (['__,.._', '._wu.,', 'dr,,__', 'V'], 'D'),\n",
       "    ([',.,._.', '.wu.__', '..,dr,', 'V'], 'A'),\n",
       "    ([',,_.._', ',,..wu', ',__dr.', 'V'], 'D'),\n",
       "    (['._._,.', '.,,.wu', '_dr__.', 'V'], 'D')])),\n",
       " ('Experimento 5',\n",
       "  ([(['_,,_,_', '..,uw.', '.,dr,_', 'A'], 'V'),\n",
       "    (['_,_,._', '..,,uw', 'dr__,.', 'A'], 'C'),\n",
       "    ([',_,__,', '.,uw._', '_.._dr', 'A'], 'V'),\n",
       "    ([',..,,_', ',_,_uw', '.dr..,', 'A'], 'C'),\n",
       "    (['_.,.__', '_,_,uw', '_,_dr,', 'A'], 'C'),\n",
       "    (['.,._,.', '.__,uw', ',_dr_,', 'A'], 'V'),\n",
       "    ([',.,_._', '.__,uw', ',,._dr', 'A'], 'C')],\n",
       "   [(['.,....', 'wu..,.', '.,r,_.', 'C'], 'A'),\n",
       "    ([',.,.,.', '_.uw.,', ',__,r,', 'C'], 'A'),\n",
       "    ([',.._,.', 'wu.,,_', '.,.r,.', 'C'], 'A'),\n",
       "    (['._.,..', ',uw.,.', '_..r.,', 'C'], 'A'),\n",
       "    (['__.__,', '_uw.,,', '_.,,r,', 'C'], 'A'),\n",
       "    ([',.,._.', '_uw,,_', ',.r,,.', 'C'], 'A'),\n",
       "    ([',_,.,.', ',_,.uw', ',._.r,', 'C'], 'V'),\n",
       "    ([',,,,_.', 'uw._,_', '...r_.', 'C'], 'A'),\n",
       "    (['_.,,_,', 'uw,.,_', '._...r', 'C'], 'V'),\n",
       "    ([',..,,,', '__w___', 'dr.,..', 'D'], 'C'),\n",
       "    ([',..,.,', ',,.uw_', '_.._r_', 'C'], 'A'),\n",
       "    (['.,.._,', '_uw.,,', ',_,,,r', 'C'], 'A'),\n",
       "    ([',__._,', 'w_.___', 'dr._.,', 'D'], 'C'),\n",
       "    (['.,._..', '..uw_.', 'r.,.,,', 'C'], 'A'),\n",
       "    ([',.,,,_', '_uw_,.', 'r____.', 'C'], 'A'),\n",
       "    (['_,...,', '.,_uw.', 'r_._..', 'C'], 'A'),\n",
       "    (['...._,', 'wu_._.', 'r__._,', 'C'], 'A'),\n",
       "    ([',_,_,.', 'wu___,', '_.,_r,', 'C'], 'V'),\n",
       "    (['__,._,', ',_.,,.', ',._.r.', 'C'], 'D')],\n",
       "   [],\n",
       "   [(['.,._,_', '_,.wu.', ',_,.dr', 'V'], 'C'),\n",
       "    (['__._,_', '_.wu,.', ',,_dr.', 'V'], 'A'),\n",
       "    (['_,,,_.', ',,.wu_', '_,_dr_', 'V'], 'C'),\n",
       "    ([',,_.._', ',,..wu', ',__dr.', 'V'], 'D'),\n",
       "    (['._._,.', '.,,.wu', '_dr__.', 'V'], 'C'),\n",
       "    (['_.,,_,', ',wu.,_', 'dr____', 'V'], 'C'),\n",
       "    (['__.___', '.._wu_', '_dr.,_', 'V'], 'C')]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 3, 1, 3, 1, 3, 1, 3, 2, 3, 3, 1, 3, 3,\n",
      "        3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1,\n",
      "        1, 0, 0, 1, 3, 3, 3, 0, 3, 2, 3, 3, 1, 1, 3, 0, 0, 3, 3, 3, 3, 3, 3, 1,\n",
      "        1, 3, 1, 3, 2, 3, 2, 0, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 2, 3, 1,\n",
      "        1, 1, 1, 3, 1, 0, 3, 3, 2, 3, 2, 1, 0, 1, 0, 3, 3, 1, 3, 0, 1, 2, 1, 1,\n",
      "        3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 3, 1, 2, 3, 1, 1, 1, 1, 0, 3, 3, 3, 1, 1,\n",
      "        2, 3, 2, 3, 3, 3, 3, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 2, 3, 3,\n",
      "        0, 1, 3, 2, 3, 3, 3, 1, 2, 1, 3, 1, 1, 0, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3,\n",
      "        1, 3, 3, 1, 1, 2, 3, 2, 2, 2, 3, 1, 3, 1, 2, 3, 2, 3, 2, 0, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 1, 3, 0, 1, 2, 1, 3, 3, 3, 0, 3, 1, 3, 3,\n",
      "        2, 2, 1, 1, 3, 3, 1, 2, 1, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 1, 3, 2, 2, 3,\n",
      "        3, 1, 2, 3, 0, 3, 1, 1, 3, 2, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1,\n",
      "        2, 3, 3, 2, 3, 3, 0, 3, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 1,\n",
      "        3, 2, 1, 1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(x_test_cnn[0], x_test_cnn[1], x_test_cnn[2])\n",
    "y_pred = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = data.to_lstm_format(x_train)\n",
    "x_val_lstm = data.to_lstm_format(x_val)\n",
    "x_test_lstm = data.to_lstm_format(x_test)\n",
    "for i in range(len(x_train_lstm)):\n",
    "    x_train_lstm[i] = x_train_lstm[i].to(device)\n",
    "    x_val_lstm[i] = x_val_lstm[i].to(device)\n",
    "    x_test_lstm[i] = x_test_lstm[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características de entrada por paso de tiempo 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2901190800.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.9213836477987422\n",
      "1 / 6 models trained | Current model test precision: 0.8064600840336134\n",
      "1 / 6 models trained | Current model test recall: 0.8730113636363637\n",
      "1 / 6 models trained | Current model test f1: 0.8384171325535148\n",
      "Número de características de entrada por paso de tiempo 8\n",
      "2 / 6 models trained | Current model test accuracy: 0.9056603773584906\n",
      "2 / 6 models trained | Current model test precision: 0.7633612240019125\n",
      "2 / 6 models trained | Current model test recall: 0.8307036713286713\n",
      "2 / 6 models trained | Current model test f1: 0.7956099819848665\n",
      "Número de características de entrada por paso de tiempo 8\n",
      "3 / 6 models trained | Current model test accuracy: 0.89937106918239\n",
      "3 / 6 models trained | Current model test precision: 0.7166990416990418\n",
      "3 / 6 models trained | Current model test recall: 0.7566215034965035\n",
      "3 / 6 models trained | Current model test f1: 0.7361193845469112\n",
      "Número de características de entrada por paso de tiempo 8\n",
      "4 / 6 models trained | Current model test accuracy: 0.9088050314465409\n",
      "4 / 6 models trained | Current model test precision: 0.8317095588235295\n",
      "4 / 6 models trained | Current model test recall: 0.9345498251748252\n",
      "4 / 6 models trained | Current model test f1: 0.8801357601681503\n",
      "Número de características de entrada por paso de tiempo 8\n",
      "5 / 6 models trained | Current model test accuracy: 0.8836477987421384\n",
      "5 / 6 models trained | Current model test precision: 0.6883680555555556\n",
      "5 / 6 models trained | Current model test recall: 0.7242934149184149\n",
      "5 / 6 models trained | Current model test f1: 0.7058739267685992\n",
      "Número de características de entrada por paso de tiempo 8\n",
      "6 / 6 models trained | Current model test accuracy: 0.9182389937106918\n",
      "6 / 6 models trained | Current model test precision: 0.7544820615179897\n",
      "6 / 6 models trained | Current model test recall: 0.7736378976828415\n",
      "6 / 6 models trained | Current model test f1: 0.7639399150541196\n"
     ]
    }
   ],
   "source": [
    "lstm_accuracies, lstm_precision, lstm_recall, lstm_f1, lstm_wrong_preds, lstm_epoch_stats, model = train_models(models.LSTM_Model, x_train_lstm, x_val_lstm, x_test_lstm, 0.0001, data, 16, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 0, 3, 2, 1, 1, 3, 3, 2, 3, 3, 3,\n",
      "        2, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 0, 2, 1, 3, 2,\n",
      "        3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 1, 2, 1, 0, 2, 1, 3, 3, 1, 1, 3, 2, 3, 3,\n",
      "        3, 1, 1, 1, 2, 0, 3, 3, 3, 1, 1, 3, 1, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3,\n",
      "        3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 1, 3, 1, 1, 3, 3, 3, 2, 3, 1, 1,\n",
      "        1, 2, 1, 3, 0, 1, 3, 2, 1, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(x_train_lstm[0], x_train_lstm[1], x_train_lstm[2])\n",
    "y_pred = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_normal = data.to_conv_format(x_train)\n",
    "x_val_normal = data.to_conv_format(x_val)\n",
    "x_test_normal = data.to_conv_format(x_test)\n",
    "for i in range(len(x_train_normal)):\n",
    "    x_train_normal[i] = x_train_normal[i].to(device)\n",
    "    x_val_normal[i] = x_val_normal[i].to(device)\n",
    "    x_test_normal[i] = x_test_normal[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2901190800.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.8930817610062893\n",
      "1 / 6 models trained | Current model test precision: 0.7528981677237492\n",
      "1 / 6 models trained | Current model test recall: 0.788304244774833\n",
      "1 / 6 models trained | Current model test f1: 0.7701945139543722\n",
      "2 / 6 models trained | Current model test accuracy: 0.8364779874213837\n",
      "2 / 6 models trained | Current model test precision: 0.6938981734299972\n",
      "2 / 6 models trained | Current model test recall: 0.792436974789916\n",
      "2 / 6 models trained | Current model test f1: 0.7399011858444707\n",
      "3 / 6 models trained | Current model test accuracy: 0.8616352201257862\n",
      "3 / 6 models trained | Current model test precision: 0.7207528436475805\n",
      "3 / 6 models trained | Current model test recall: 0.7739873780837636\n",
      "3 / 6 models trained | Current model test f1: 0.7464221482647343\n",
      "4 / 6 models trained | Current model test accuracy: 0.8647798742138365\n",
      "4 / 6 models trained | Current model test precision: 0.7266423939121307\n",
      "4 / 6 models trained | Current model test recall: 0.7825862218662851\n",
      "4 / 6 models trained | Current model test f1: 0.7535774497706154\n",
      "5 / 6 models trained | Current model test accuracy: 0.8773584905660378\n",
      "5 / 6 models trained | Current model test precision: 0.7409060846560847\n",
      "5 / 6 models trained | Current model test recall: 0.7932050170378483\n",
      "5 / 6 models trained | Current model test f1: 0.7661640970515887\n",
      "6 / 6 models trained | Current model test accuracy: 0.8081761006289309\n",
      "6 / 6 models trained | Current model test precision: 0.6317323702043524\n",
      "6 / 6 models trained | Current model test recall: 0.7056527412099927\n",
      "6 / 6 models trained | Current model test f1: 0.6666496806957134\n"
     ]
    }
   ],
   "source": [
    "deepset_accuracies, deepset_procision, deepset_recall, deepset_f1, deepset_wrong_preds, deepset_epoch_stats, model = train_models(models.DEEPSET_Model, x_train_normal, x_val_normal, x_test_normal, 0.005, data, 128, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2901190800.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.6352201257861635\n",
      "1 / 6 models trained | Current model test precision: 0.3571575435009928\n",
      "1 / 6 models trained | Current model test recall: 0.5680215617715618\n",
      "1 / 6 models trained | Current model test f1: 0.4385598085857391\n",
      "2 / 6 models trained | Current model test accuracy: 0.5849056603773585\n",
      "2 / 6 models trained | Current model test precision: 0.28605200945626474\n",
      "2 / 6 models trained | Current model test recall: 0.3640005827505828\n",
      "2 / 6 models trained | Current model test f1: 0.3203528434078561\n",
      "3 / 6 models trained | Current model test accuracy: 0.6823899371069182\n",
      "3 / 6 models trained | Current model test precision: 0.32312911184210524\n",
      "3 / 6 models trained | Current model test recall: 0.3793859649122807\n",
      "3 / 6 models trained | Current model test f1: 0.34900503617326817\n",
      "4 / 6 models trained | Current model test accuracy: 0.7264150943396226\n",
      "4 / 6 models trained | Current model test precision: 0.5861132995485905\n",
      "4 / 6 models trained | Current model test recall: 0.6604830023428778\n",
      "4 / 6 models trained | Current model test f1: 0.62107976930714\n",
      "5 / 6 models trained | Current model test accuracy: 0.5786163522012578\n",
      "5 / 6 models trained | Current model test precision: 0.2752145381120646\n",
      "5 / 6 models trained | Current model test recall: 0.35118006993006995\n",
      "5 / 6 models trained | Current model test f1: 0.3085909728439603\n",
      "6 / 6 models trained | Current model test accuracy: 0.7232704402515723\n",
      "6 / 6 models trained | Current model test precision: 0.5552035330261137\n",
      "6 / 6 models trained | Current model test recall: 0.6803319388100068\n",
      "6 / 6 models trained | Current model test f1: 0.6114315690127302\n"
     ]
    }
   ],
   "source": [
    "deepsetv2_accuracies, deepsetv2_procision, deepsetv2_recall, deepsetv2_f1, deepsetv2_wrong_preds, deepsetv2_epoch_stats, model = train_models(models.DEEPSETV2_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 0, 3, 2, 1, 1, 3, 3, 2, 3, 3, 3,\n",
      "        2, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 2, 3, 3, 0, 0, 2, 1, 3, 2,\n",
      "        3, 3, 3, 3, 3, 3, 0, 2, 3, 3, 0, 2, 1, 0, 2, 1, 3, 3, 0, 1, 3, 2, 3, 3,\n",
      "        3, 1, 0, 1, 2, 0, 3, 3, 3, 1, 1, 3, 1, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3,\n",
      "        3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 0, 3, 3, 1, 3, 1, 0, 3, 3, 3, 2, 3, 1, 1,\n",
      "        1, 2, 1, 3, 1, 1, 3, 2, 1, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(x_train_normal[0], x_train_normal[1], x_train_normal[2])\n",
    "y_pred = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2901190800.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./{model_name}_model_TEMP_' + experiment_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6 models trained | Current model test accuracy: 0.7358490566037735\n",
      "1 / 6 models trained | Current model test precision: 0.6270269714370642\n",
      "1 / 6 models trained | Current model test recall: 0.7583333333333333\n",
      "1 / 6 models trained | Current model test f1: 0.6864574532739768\n",
      "2 / 6 models trained | Current model test accuracy: 0.7452830188679245\n",
      "2 / 6 models trained | Current model test precision: 0.5891509685196087\n",
      "2 / 6 models trained | Current model test recall: 0.6632717709640786\n",
      "2 / 6 models trained | Current model test f1: 0.6240180634476459\n",
      "3 / 6 models trained | Current model test accuracy: 0.7515723270440252\n",
      "3 / 6 models trained | Current model test precision: 0.5867193108399138\n",
      "3 / 6 models trained | Current model test recall: 0.6437275295326144\n",
      "3 / 6 models trained | Current model test f1: 0.6139027873511508\n",
      "4 / 6 models trained | Current model test accuracy: 0.7327044025157232\n",
      "4 / 6 models trained | Current model test precision: 0.49405298263773045\n",
      "4 / 6 models trained | Current model test recall: 0.6508912655971479\n",
      "4 / 6 models trained | Current model test f1: 0.5617300084905952\n",
      "5 / 6 models trained | Current model test accuracy: 0.7012578616352201\n",
      "5 / 6 models trained | Current model test precision: 0.5697655931512434\n",
      "5 / 6 models trained | Current model test recall: 0.6418494152046783\n",
      "5 / 6 models trained | Current model test f1: 0.6036632267606309\n",
      "6 / 6 models trained | Current model test accuracy: 0.6698113207547169\n",
      "6 / 6 models trained | Current model test precision: 0.49743489526971685\n",
      "6 / 6 models trained | Current model test recall: 0.6280909464099119\n",
      "6 / 6 models trained | Current model test f1: 0.5551793527566178\n"
     ]
    }
   ],
   "source": [
    "feedforward_accuracies, feedforward_precision, feedforward_recall, feedforward_f1, feedforward_wrong_preds, feedforward_epoch_stats, model = train_models(models.FEEDFORWARD_Model, x_train_normal, x_val_normal, x_test_normal, 0.0001, data, 128, 32, 8, 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 0, 3, 2, 1, 1, 3, 3, 2, 3, 3, 3,\n",
      "        2, 3, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 0, 2, 1, 3, 2,\n",
      "        3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 1, 2, 1, 0, 2, 1, 3, 3, 1, 1, 3, 2, 3, 3,\n",
      "        3, 1, 1, 1, 2, 0, 3, 3, 3, 1, 1, 3, 1, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3,\n",
      "        3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 1, 3, 1, 1, 3, 3, 3, 2, 3, 1, 1,\n",
      "        1, 2, 1, 3, 0, 1, 3, 2, 1, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(x_train_normal[0], x_train_normal[1], x_train_normal[2])\n",
    "y_pred = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy breakdown by cases for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_half = int(num_experiments / 2)\n",
    "best_cnn_accs = filter_top_k_accuracies(cnn_accuracies, top_half)\n",
    "best_lstm_accs = filter_top_k_accuracies(lstm_accuracies, top_half)\n",
    "best_deepset_accs = filter_top_k_accuracies(deepset_accuracies, top_half)\n",
    "best_deepsetv2_accs = filter_top_k_accuracies(deepsetv2_accuracies, top_half)\n",
    "best_feedforward_accs = filter_top_k_accuracies(feedforward_accuracies, top_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>cr_noop</th>\n",
       "      <th>cr_uw</th>\n",
       "      <th>cr_w</th>\n",
       "      <th>cr_wu</th>\n",
       "      <th>dr_noop</th>\n",
       "      <th>dr_uw</th>\n",
       "      <th>dr_w</th>\n",
       "      <th>dr_wu</th>\n",
       "      <th>noop_noop</th>\n",
       "      <th>noop_uw</th>\n",
       "      <th>noop_w</th>\n",
       "      <th>noop_wu</th>\n",
       "      <th>r_noop</th>\n",
       "      <th>r_uw</th>\n",
       "      <th>r_w</th>\n",
       "      <th>r_wu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>93.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>71.1%</td>\n",
       "      <td>98.2%</td>\n",
       "      <td>25.4%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>99.3%</td>\n",
       "      <td>90.9%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>94.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>90.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>99.2%</td>\n",
       "      <td>44.4%</td>\n",
       "      <td>84.2%</td>\n",
       "      <td>7.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>99.3%</td>\n",
       "      <td>99.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>98.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper)</th>\n",
       "      <td>85.7%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>83.3%</td>\n",
       "      <td>31.1%</td>\n",
       "      <td>82.5%</td>\n",
       "      <td>8.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>78.8%</td>\n",
       "      <td>90.8%</td>\n",
       "      <td>92.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start)</th>\n",
       "      <td>65.5%</td>\n",
       "      <td>98.7%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>55.0%</td>\n",
       "      <td>13.3%</td>\n",
       "      <td>52.6%</td>\n",
       "      <td>21.1%</td>\n",
       "      <td>98.6%</td>\n",
       "      <td>99.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>99.2%</td>\n",
       "      <td>34.0%</td>\n",
       "      <td>24.2%</td>\n",
       "      <td>29.2%</td>\n",
       "      <td>27.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward</th>\n",
       "      <td>72.3%</td>\n",
       "      <td>98.0%</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>99.0%</td>\n",
       "      <td>56.7%</td>\n",
       "      <td>15.6%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>17.5%</td>\n",
       "      <td>98.6%</td>\n",
       "      <td>94.2%</td>\n",
       "      <td>99.2%</td>\n",
       "      <td>96.7%</td>\n",
       "      <td>61.3%</td>\n",
       "      <td>47.7%</td>\n",
       "      <td>58.3%</td>\n",
       "      <td>43.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Overall cr_noop   cr_uw    cr_w   cr_wu dr_noop  dr_uw  \\\n",
       "CNN                      93.0%  100.0%  100.0%  100.0%  100.0%  100.0%  71.1%   \n",
       "LSTM                     90.6%  100.0%  100.0%  100.0%  100.0%   99.2%  44.4%   \n",
       "DeepSet(like in paper)   85.7%  100.0%  100.0%  100.0%  100.0%   83.3%  31.1%   \n",
       "DeepSet(sum at start)    65.5%   98.7%  100.0%   99.0%  100.0%   55.0%  13.3%   \n",
       "Feedforward              72.3%   98.0%   97.6%  100.0%   99.0%   56.7%  15.6%   \n",
       "Sample count               318      25      14      17      16      20     15   \n",
       "\n",
       "                         dr_w  dr_wu noop_noop noop_uw  noop_w noop_wu r_noop  \\\n",
       "CNN                     98.2%  25.4%    100.0%  100.0%  100.0%  100.0%  99.3%   \n",
       "LSTM                    84.2%   7.0%    100.0%  100.0%  100.0%  100.0%  99.3%   \n",
       "DeepSet(like in paper)  82.5%   8.8%    100.0%  100.0%  100.0%  100.0%  88.0%   \n",
       "DeepSet(sum at start)   52.6%  21.1%     98.6%   99.2%  100.0%   99.2%  34.0%   \n",
       "Feedforward             65.8%  17.5%     98.6%   94.2%   99.2%   96.7%  61.3%   \n",
       "Sample count               19     19        23      20      22      20     25   \n",
       "\n",
       "                         r_uw     r_w   r_wu  \n",
       "CNN                     90.9%  100.0%  94.4%  \n",
       "LSTM                    99.2%  100.0%  98.4%  \n",
       "DeepSet(like in paper)  78.8%   90.8%  92.1%  \n",
       "DeepSet(sum at start)   24.2%   29.2%  27.8%  \n",
       "Feedforward             47.7%   58.3%  43.7%  \n",
       "Sample count               22      20     21  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accuracies = [cnn_accuracies, lstm_accuracies, deepset_accuracies, deepsetv2_accuracies, feedforward_accuracies]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']\n",
    "get_stats_df(all_accuracies, model_names, test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy breakdown by cases for top 50% of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>f3_cr</th>\n",
       "      <th>f3_dr</th>\n",
       "      <th>f3_noop</th>\n",
       "      <th>f3_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>94.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>76.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>98.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>91.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>65.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>98.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper)</th>\n",
       "      <td>87.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>91.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start)</th>\n",
       "      <td>71.1%</td>\n",
       "      <td>98.6%</td>\n",
       "      <td>27.9%</td>\n",
       "      <td>98.4%</td>\n",
       "      <td>58.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward</th>\n",
       "      <td>74.4%</td>\n",
       "      <td>99.1%</td>\n",
       "      <td>43.4%</td>\n",
       "      <td>96.5%</td>\n",
       "      <td>58.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Overall   f3_cr  f3_dr f3_noop   f3_r\n",
       "CNN                      94.2%  100.0%  76.3%  100.0%  98.9%\n",
       "LSTM                     91.6%  100.0%  65.3%  100.0%  98.5%\n",
       "DeepSet(like in paper)   87.8%  100.0%  57.5%  100.0%  91.3%\n",
       "DeepSet(sum at start)    71.1%   98.6%  27.9%   98.4%  58.0%\n",
       "Feedforward              74.4%   99.1%  43.4%   96.5%  58.7%\n",
       "Sample count               318      72     73      85     88"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracies = [best_cnn_accs, best_lstm_accs, best_deepset_accs, best_deepsetv2_accs, best_feedforward_accs]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']\n",
    "collapsed_cases = ['dr', 'r', 'cr', 'noop']\n",
    "get_stats_df(best_accuracies, model_names, test_original, collapsed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>dr_noop</th>\n",
       "      <th>dr_uw</th>\n",
       "      <th>dr_w</th>\n",
       "      <th>dr_wu</th>\n",
       "      <th>f3_cr</th>\n",
       "      <th>f3_noop</th>\n",
       "      <th>f3_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>94.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>75.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>28.1%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>98.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>91.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>60.0%</td>\n",
       "      <td>87.7%</td>\n",
       "      <td>10.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>98.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper)</th>\n",
       "      <td>87.8%</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>89.5%</td>\n",
       "      <td>10.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>91.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start)</th>\n",
       "      <td>71.1%</td>\n",
       "      <td>45.0%</td>\n",
       "      <td>13.3%</td>\n",
       "      <td>40.4%</td>\n",
       "      <td>8.8%</td>\n",
       "      <td>98.6%</td>\n",
       "      <td>98.4%</td>\n",
       "      <td>58.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward</th>\n",
       "      <td>74.4%</td>\n",
       "      <td>63.3%</td>\n",
       "      <td>22.2%</td>\n",
       "      <td>70.2%</td>\n",
       "      <td>12.3%</td>\n",
       "      <td>99.1%</td>\n",
       "      <td>96.5%</td>\n",
       "      <td>58.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Overall dr_noop  dr_uw    dr_w  dr_wu   f3_cr f3_noop  \\\n",
       "CNN                      94.2%  100.0%  75.6%  100.0%  28.1%  100.0%  100.0%   \n",
       "LSTM                     91.6%  100.0%  60.0%   87.7%  10.5%  100.0%  100.0%   \n",
       "DeepSet(like in paper)   87.8%   90.0%  33.3%   89.5%  10.5%  100.0%  100.0%   \n",
       "DeepSet(sum at start)    71.1%   45.0%  13.3%   40.4%   8.8%   98.6%   98.4%   \n",
       "Feedforward              74.4%   63.3%  22.2%   70.2%  12.3%   99.1%   96.5%   \n",
       "Sample count               318      20     15      19     19      72      85   \n",
       "\n",
       "                         f3_r  \n",
       "CNN                     98.9%  \n",
       "LSTM                    98.5%  \n",
       "DeepSet(like in paper)  91.3%  \n",
       "DeepSet(sum at start)   58.0%  \n",
       "Feedforward             58.7%  \n",
       "Sample count               88  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracies = [best_cnn_accs, best_lstm_accs, best_deepset_accs, best_deepsetv2_accs, best_feedforward_accs]\n",
    "model_names = ['CNN', 'LSTM', 'DeepSet(like in paper)', 'DeepSet(sum at start)', 'Feedforward']\n",
    "collapsed_cases = ['r', 'cr', 'noop']\n",
    "get_stats_df(best_accuracies, model_names, test_original, collapsed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>f3_cr</th>\n",
       "      <th>f3_dr</th>\n",
       "      <th>f3_noop</th>\n",
       "      <th>f3_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN #0</th>\n",
       "      <td>93.1%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>69.9%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN #1</th>\n",
       "      <td>92.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>68.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN #2</th>\n",
       "      <td>93.4%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>71.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN #3</th>\n",
       "      <td>94.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>74.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN #4</th>\n",
       "      <td>95.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>96.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN #5</th>\n",
       "      <td>89.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>78.1%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>80.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Overall   f3_cr  f3_dr f3_noop    f3_r\n",
       "CNN #0         93.1%  100.0%  69.9%  100.0%  100.0%\n",
       "CNN #1         92.8%  100.0%  68.5%  100.0%  100.0%\n",
       "CNN #2         93.4%  100.0%  71.2%  100.0%  100.0%\n",
       "CNN #3         94.0%  100.0%  74.0%  100.0%  100.0%\n",
       "CNN #4         95.3%  100.0%  83.6%  100.0%   96.6%\n",
       "CNN #5         89.6%  100.0%  78.1%  100.0%   80.7%\n",
       "Sample count     318      72     73      85      88"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats_per_model(cnn_accuracies, ['CNN #' + str(i) for i in range(len(cnn_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>f3_cr</th>\n",
       "      <th>f3_dr</th>\n",
       "      <th>f3_noop</th>\n",
       "      <th>f3_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM #0</th>\n",
       "      <td>92.1%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM #1</th>\n",
       "      <td>90.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>58.9%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM #2</th>\n",
       "      <td>89.9%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>56.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM #3</th>\n",
       "      <td>90.9%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>65.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>95.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM #4</th>\n",
       "      <td>88.4%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>49.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM #5</th>\n",
       "      <td>91.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>64.4%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Overall   f3_cr  f3_dr f3_noop    f3_r\n",
       "LSTM #0        92.1%  100.0%  65.8%  100.0%  100.0%\n",
       "LSTM #1        90.6%  100.0%  58.9%  100.0%  100.0%\n",
       "LSTM #2        89.9%  100.0%  56.2%  100.0%  100.0%\n",
       "LSTM #3        90.9%  100.0%  65.8%  100.0%   95.5%\n",
       "LSTM #4        88.4%  100.0%  49.3%  100.0%  100.0%\n",
       "LSTM #5        91.8%  100.0%  64.4%  100.0%  100.0%\n",
       "Sample count     318      72     73      85      88"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats_per_model(lstm_accuracies, ['LSTM #' + str(i) for i in range(len(lstm_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>f3_cr</th>\n",
       "      <th>f3_dr</th>\n",
       "      <th>f3_noop</th>\n",
       "      <th>f3_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper) #0</th>\n",
       "      <td>89.3%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>58.9%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>95.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper) #1</th>\n",
       "      <td>83.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>54.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>78.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper) #2</th>\n",
       "      <td>86.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>53.4%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>88.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper) #3</th>\n",
       "      <td>86.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>56.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>87.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper) #4</th>\n",
       "      <td>87.7%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>90.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(like in paper) #5</th>\n",
       "      <td>80.8%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>37.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>83.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Overall   f3_cr  f3_dr f3_noop   f3_r\n",
       "DeepSet(like in paper) #0   89.3%  100.0%  58.9%  100.0%  95.5%\n",
       "DeepSet(like in paper) #1   83.6%  100.0%  54.8%  100.0%  78.4%\n",
       "DeepSet(like in paper) #2   86.2%  100.0%  53.4%  100.0%  88.6%\n",
       "DeepSet(like in paper) #3   86.5%  100.0%  56.2%  100.0%  87.5%\n",
       "DeepSet(like in paper) #4   87.7%  100.0%  57.5%  100.0%  90.9%\n",
       "DeepSet(like in paper) #5   80.8%  100.0%  37.0%  100.0%  83.0%\n",
       "Sample count                  318      72     73      85     88"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats_per_model(deepset_accuracies, ['DeepSet(like in paper) #' + str(i) for i in range(len(deepset_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>f3_cr</th>\n",
       "      <th>f3_dr</th>\n",
       "      <th>f3_noop</th>\n",
       "      <th>f3_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start) #0</th>\n",
       "      <td>63.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>61.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start) #1</th>\n",
       "      <td>58.5%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>39.7%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start) #2</th>\n",
       "      <td>68.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>1.4%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>67.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start) #3</th>\n",
       "      <td>72.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>38.4%</td>\n",
       "      <td>96.5%</td>\n",
       "      <td>55.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start) #4</th>\n",
       "      <td>57.9%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>37.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSet(sum at start) #5</th>\n",
       "      <td>72.3%</td>\n",
       "      <td>95.8%</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>98.8%</td>\n",
       "      <td>51.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Overall   f3_cr  f3_dr f3_noop   f3_r\n",
       "DeepSet(sum at start) #0   63.5%  100.0%  61.6%  100.0%   0.0%\n",
       "DeepSet(sum at start) #1   58.5%  100.0%  39.7%  100.0%   0.0%\n",
       "DeepSet(sum at start) #2   68.2%  100.0%   1.4%  100.0%  67.0%\n",
       "DeepSet(sum at start) #3   72.6%  100.0%  38.4%   96.5%  55.7%\n",
       "DeepSet(sum at start) #4   57.9%  100.0%  37.0%  100.0%   0.0%\n",
       "DeepSet(sum at start) #5   72.3%   95.8%  43.8%   98.8%  51.1%\n",
       "Sample count                 318      72     73      85     88"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats_per_model(deepsetv2_accuracies, ['DeepSet(sum at start) #' + str(i) for i in range(len(deepsetv2_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>f3_cr</th>\n",
       "      <th>f3_dr</th>\n",
       "      <th>f3_noop</th>\n",
       "      <th>f3_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feedforward #0</th>\n",
       "      <td>73.6%</td>\n",
       "      <td>98.6%</td>\n",
       "      <td>50.7%</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>48.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward #1</th>\n",
       "      <td>74.5%</td>\n",
       "      <td>98.6%</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>91.8%</td>\n",
       "      <td>63.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward #2</th>\n",
       "      <td>75.2%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>35.6%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>63.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward #3</th>\n",
       "      <td>73.3%</td>\n",
       "      <td>95.8%</td>\n",
       "      <td>31.5%</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>65.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward #4</th>\n",
       "      <td>70.1%</td>\n",
       "      <td>98.6%</td>\n",
       "      <td>46.6%</td>\n",
       "      <td>98.8%</td>\n",
       "      <td>38.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedforward #5</th>\n",
       "      <td>67.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>34.2%</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>37.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample count</th>\n",
       "      <td>318</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Overall   f3_cr  f3_dr f3_noop   f3_r\n",
       "Feedforward #0   73.6%   98.6%  50.7%   97.6%  48.9%\n",
       "Feedforward #1   74.5%   98.6%  43.8%   91.8%  63.6%\n",
       "Feedforward #2   75.2%  100.0%  35.6%  100.0%  63.6%\n",
       "Feedforward #3   73.3%   95.8%  31.5%   97.6%  65.9%\n",
       "Feedforward #4   70.1%   98.6%  46.6%   98.8%  38.6%\n",
       "Feedforward #5   67.0%  100.0%  34.2%   97.6%  37.5%\n",
       "Sample count       318      72     73      85     88"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats_per_model(feedforward_accuracies, ['Feedforward #' + str(i) for i in range(len(feedforward_accuracies))], test_original, ['cr', 'dr', 'noop', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características de entrada por paso de tiempo 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2902303673.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_lstm_model.load_state_dict(torch.load('best_LSTM_model_' + experiment_name))\n",
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2902303673.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_cnn_model.load_state_dict(torch.load('best_CNN_model_' + experiment_name))\n",
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2902303673.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_deepset_model.load_state_dict(torch.load('best_DEEPSET_model_' + experiment_name))\n",
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2902303673.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_deepsetv2_model.load_state_dict(torch.load('best_DEEPSETV2_model_' + experiment_name))\n",
      "C:\\Users\\juand\\AppData\\Local\\Temp\\ipykernel_26492\\2902303673.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_feedforward_model.load_state_dict(torch.load('best_FEEDFORWARD_model_' + experiment_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lstm_model = models.LSTM_Model(data, 16, 32, 8).to(device)\n",
    "best_lstm_model.load_state_dict(torch.load('best_LSTM_model_' + experiment_name))\n",
    "best_cnn_model = models.CNN_Model(data, 64, 128, 4, -1,).to(device)\n",
    "best_cnn_model.load_state_dict(torch.load('best_CNN_model_' + experiment_name))\n",
    "best_deepset_model = models.DEEPSET_Model(data).to(device)\n",
    "best_deepset_model.load_state_dict(torch.load('best_DEEPSET_model_' + experiment_name))\n",
    "best_deepsetv2_model = models.DEEPSETV2_Model(data).to(device)\n",
    "best_deepsetv2_model.load_state_dict(torch.load('best_DEEPSETV2_model_' + experiment_name))\n",
    "best_feedforward_model = models.FEEDFORWARD_Model(data).to(device)\n",
    "best_feedforward_model.load_state_dict(torch.load('best_FEEDFORWARD_model_' + experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong predictions for best performing CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds_bycases(get_wrong_predictions_bycases(best_cnn_model, x_test_cnn, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 false positives: \n",
      "\n",
      "Muestra ['_,,_,_', '..,uw.', '.,dr,_', 'A'] | Prediccion V\n",
      "Muestra ['__._,,', '.,uw,,', '_.dr_,', 'A'] | Prediccion D\n",
      "Muestra [',_,__,', '.,uw._', '_.._dr', 'A'] | Prediccion V\n",
      "Muestra [',.,_._', '.__,uw', ',,._dr', 'A'] | Prediccion V\n",
      "Top 3 false positives: \n",
      "\n",
      "Muestra ['__.__,', ',_,wu,', '...,,r', 'C'] | Prediccion V\n",
      "Muestra [',.,.__', ',wu_,,', '__.,,r', 'C'] | Prediccion V\n",
      "Muestra [',_,_,.', 'wu___,', '_.,_r,', 'C'] | Prediccion V\n",
      "Top 0 false positives: \n",
      "\n",
      "Top 8 false positives: \n",
      "\n",
      "Muestra ['.,._,_', '_,.wu.', ',_,.dr', 'V'] | Prediccion D\n",
      "Muestra ['__.._.', '__wu..', ',_dr..', 'V'] | Prediccion D\n",
      "Muestra ['_,__,_', '.wu_.,', '.dr_,,', 'V'] | Prediccion D\n",
      "Muestra ['__._,_', '_.wu,.', ',,_dr.', 'V'] | Prediccion A\n",
      "Muestra ['__,.._', '._wu.,', 'dr,,__', 'V'] | Prediccion D\n",
      "Muestra [',.,._.', '.wu.__', '..,dr,', 'V'] | Prediccion A\n",
      "Muestra [',,_.._', ',,..wu', ',__dr.', 'V'] | Prediccion D\n",
      "Muestra ['._._,.', '.,,.wu', '_dr__.', 'V'] | Prediccion D\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_wrong_preds(get_wrong_predictions(best_cnn_model, x_test_cnn, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong predictions for best performing LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds_bycases(get_wrong_predictions_bycases(best_lstm_model, x_test_lstm, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 false positives: \n",
      "\n",
      "Muestra ['_,_,._', '..,,uw', 'dr__,.', 'A'] | Prediccion D\n",
      "Muestra [',_..,.', '.,_uw,', '_dr__,', 'A'] | Prediccion D\n",
      "Muestra [',..,,_', ',_,_uw', '.dr..,', 'A'] | Prediccion D\n",
      "Muestra ['_.,.__', '_,_,uw', '_,_dr,', 'A'] | Prediccion D\n",
      "Muestra ['.,._,.', '.__,uw', ',_dr_,', 'A'] | Prediccion D\n",
      "Muestra [',.,_._', '.__,uw', ',,._dr', 'A'] | Prediccion D\n",
      "Top 0 false positives: \n",
      "\n",
      "Top 0 false positives: \n",
      "\n",
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['.,._,_', '_,.wu.', ',_,.dr', 'V'] | Prediccion D\n",
      "Muestra ['__.._.', '__wu..', ',_dr..', 'V'] | Prediccion A\n",
      "Muestra ['_,__,_', '.wu_.,', '.dr_,,', 'V'] | Prediccion A\n",
      "Muestra ['___._.', 'wu__,,', 'dr,_,_', 'V'] | Prediccion D\n",
      "Muestra [',.,,,,', '_,,,wu', 'dr_...', 'V'] | Prediccion D\n",
      "Muestra ['__._,_', '_.wu,.', ',,_dr.', 'V'] | Prediccion A\n",
      "Muestra ['__,,,_', '_wu_,,', '..dr._', 'V'] | Prediccion D\n",
      "Muestra ['_,,,_.', ',,.wu_', '_,_dr_', 'V'] | Prediccion D\n",
      "Muestra ['._,..,', ',_,wu_', '.,dr_,', 'V'] | Prediccion D\n",
      "Muestra ['__,.._', '._wu.,', 'dr,,__', 'V'] | Prediccion D\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_wrong_preds(get_wrong_predictions(best_lstm_model, x_test_lstm, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong predictions for best performing DeepSets V1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds_bycases(get_wrong_predictions_bycases(best_deepset_model, x_test_normal, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['_,_,._', '..,,uw', 'dr__,.', 'A'] | Prediccion V\n",
      "Muestra [',,__..', '.,uw._', '._.dr,', 'A'] | Prediccion D\n",
      "Muestra [',_.,,_', 'uw,..,', ',dr_,.', 'A'] | Prediccion C\n",
      "Muestra [',_..,.', '.,_uw,', '_dr__,', 'A'] | Prediccion D\n",
      "Muestra ['__._,,', '.,uw,,', '_.dr_,', 'A'] | Prediccion D\n",
      "Muestra [',_,__,', '.,uw._', '_.._dr', 'A'] | Prediccion D\n",
      "Muestra [',..,,_', ',_,_uw', '.dr..,', 'A'] | Prediccion D\n",
      "Muestra ['_.,.__', '_,_,uw', '_,_dr,', 'A'] | Prediccion D\n",
      "Muestra ['.,._,.', '.__,uw', ',_dr_,', 'A'] | Prediccion D\n",
      "Muestra [',.,_._', '.__,uw', ',,._dr', 'A'] | Prediccion D\n",
      "Top 7 false positives: \n",
      "\n",
      "Muestra ['._____', ',._.w,', 'dr,,_.', 'D'] | Prediccion V\n",
      "Muestra ['.__.__', ',.,,._', '...,r.', 'C'] | Prediccion V\n",
      "Muestra ['__,..,', ',.._,.', '__r.__', 'C'] | Prediccion V\n",
      "Muestra ['__.__,', '_uw.,,', '_.,,r,', 'C'] | Prediccion A\n",
      "Muestra [',,.,_,', '___,,.', '___,r,', 'C'] | Prediccion V\n",
      "Muestra ['.,__.,', ',.,,._', ',_dr,.', 'D'] | Prediccion V\n",
      "Muestra ['.,....', '__w,__', '_,dr,_', 'D'] | Prediccion A\n",
      "Top 0 false positives: \n",
      "\n",
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['.,._,_', '_,.wu.', ',_,.dr', 'V'] | Prediccion D\n",
      "Muestra ['_,__,_', '.wu_.,', '.dr_,,', 'V'] | Prediccion D\n",
      "Muestra [',.,,,,', '_,,,wu', 'dr_...', 'V'] | Prediccion C\n",
      "Muestra ['__._,_', '_.wu,.', ',,_dr.', 'V'] | Prediccion A\n",
      "Muestra ['__,,,_', '_wu_,,', '..dr._', 'V'] | Prediccion D\n",
      "Muestra ['_,,,_.', ',,.wu_', '_,_dr_', 'V'] | Prediccion D\n",
      "Muestra ['._,..,', ',_,wu_', '.,dr_,', 'V'] | Prediccion D\n",
      "Muestra ['__,.._', '._wu.,', 'dr,,__', 'V'] | Prediccion A\n",
      "Muestra [',.,._.', '.wu.__', '..,dr,', 'V'] | Prediccion D\n",
      "Muestra [',,_.._', ',,..wu', ',__dr.', 'V'] | Prediccion D\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_wrong_preds(get_wrong_predictions(best_deepset_model, x_test_normal, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong predictions for best performing DeepSets V2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds_bycases(get_wrong_predictions_bycases(best_deepsetv2_model, x_test_normal, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['_,,_,_', '..,uw.', '.,dr,_', 'A'] | Prediccion D\n",
      "Muestra [',_.,,_', 'uw,..,', ',dr_,.', 'A'] | Prediccion V\n",
      "Muestra ['.,,,_.', '_uw._.', ',.,_dr', 'A'] | Prediccion D\n",
      "Muestra [',_..,.', '.,_uw,', '_dr__,', 'A'] | Prediccion D\n",
      "Muestra ['__._,,', '.,uw,,', '_.dr_,', 'A'] | Prediccion D\n",
      "Muestra ['____,,', '_uw._.', ',_.dr,', 'A'] | Prediccion D\n",
      "Muestra [',_,__,', '.,uw._', '_.._dr', 'A'] | Prediccion V\n",
      "Muestra ['_.._,_', 'uw_,__', 'dr..,,', 'A'] | Prediccion D\n",
      "Muestra [',..,,_', ',_,_uw', '.dr..,', 'A'] | Prediccion D\n",
      "Muestra ['_.,.__', '_,_,uw', '_,_dr,', 'A'] | Prediccion D\n",
      "Top 10 false positives: \n",
      "\n",
      "Muestra [',,__,,', '_._.,w', ',,,r_.', 'C'] | Prediccion V\n",
      "Muestra ['_.._,,', '__,,uw', ',,.._r', 'C'] | Prediccion V\n",
      "Muestra ['_,._..', '.._w.,', ',_,_dr', 'D'] | Prediccion A\n",
      "Muestra [',_..,,', ',_w._.', '.,_dr.', 'D'] | Prediccion V\n",
      "Muestra [',_,,__', '.__uw.', ',r,,._', 'C'] | Prediccion V\n",
      "Muestra ['.___,_', ',,.,wu', ',r..__', 'C'] | Prediccion V\n",
      "Muestra ['_.,_,_', ',_w._,', ',dr,..', 'D'] | Prediccion A\n",
      "Muestra [',____.', '.__.wu', ',_r,__', 'C'] | Prediccion V\n",
      "Muestra [',_,_,,', '_w..,,', ',,,,r.', 'C'] | Prediccion V\n",
      "Muestra ['_,.__.', ',_.,__', ',_,r__', 'C'] | Prediccion V\n",
      "Top 0 false positives: \n",
      "\n",
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['.,._,_', '_,.wu.', ',_,.dr', 'V'] | Prediccion A\n",
      "Muestra ['__.._.', '__wu..', ',_dr..', 'V'] | Prediccion C\n",
      "Muestra ['_,__,_', '.wu_.,', '.dr_,,', 'V'] | Prediccion A\n",
      "Muestra ['___._.', 'wu__,,', 'dr,_,_', 'V'] | Prediccion D\n",
      "Muestra ['__._,_', '_.wu,.', ',,_dr.', 'V'] | Prediccion D\n",
      "Muestra ['_,,.,_', '...wu.', '_,.___', 'V'] | Prediccion C\n",
      "Muestra ['_,,,_.', ',,.wu_', '_,_dr_', 'V'] | Prediccion D\n",
      "Muestra ['._,..,', ',_,wu_', '.,dr_,', 'V'] | Prediccion D\n",
      "Muestra ['__,.._', '._wu.,', 'dr,,__', 'V'] | Prediccion A\n",
      "Muestra [',.,._.', '.wu.__', '..,dr,', 'V'] | Prediccion D\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_wrong_preds(get_wrong_predictions(best_deepsetv2_model, x_test_normal, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong predictions for best performing Feedforward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_preds_bycases(get_wrong_predictions_bycases(best_feedforward_model, x_test_normal, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['_,,_,_', '..,uw.', '.,dr,_', 'A'] | Prediccion D\n",
      "Muestra ['_,_,._', '..,,uw', 'dr__,.', 'A'] | Prediccion V\n",
      "Muestra [',,__..', '.,uw._', '._.dr,', 'A'] | Prediccion D\n",
      "Muestra [',_.,,_', 'uw,..,', ',dr_,.', 'A'] | Prediccion D\n",
      "Muestra ['.,,,_.', '_uw._.', ',.,_dr', 'A'] | Prediccion C\n",
      "Muestra [',_..,.', '.,_uw,', '_dr__,', 'A'] | Prediccion D\n",
      "Muestra ['__._,,', '.,uw,,', '_.dr_,', 'A'] | Prediccion D\n",
      "Muestra ['____,,', '_uw._.', ',_.dr,', 'A'] | Prediccion D\n",
      "Muestra [',_,__,', '.,uw._', '_.._dr', 'A'] | Prediccion D\n",
      "Muestra [',..,,_', ',_,_uw', '.dr..,', 'A'] | Prediccion D\n",
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['.__.__', '.,w.__', '_._.r.', 'C'] | Prediccion V\n",
      "Muestra [',._,._', ',.....', '_.r,_,', 'C'] | Prediccion V\n",
      "Muestra [',_,_,,', '_w..,,', ',,,,r.', 'C'] | Prediccion D\n",
      "Muestra ['.,....', 'wu..,.', '.,r,_.', 'C'] | Prediccion V\n",
      "Muestra ['.__.__', ',.,,._', '...,r.', 'C'] | Prediccion V\n",
      "Muestra [',.,.,.', '_.uw.,', ',__,r,', 'C'] | Prediccion V\n",
      "Muestra ['._,_,,', '.__.,_', '_,_,.r', 'C'] | Prediccion D\n",
      "Muestra ['__..,.', '._,_.,', ',__.dr', 'D'] | Prediccion V\n",
      "Muestra ['_,.,,_', '..,_w_', '_,_dr.', 'D'] | Prediccion A\n",
      "Muestra ['.,,.__', '._uw__', ',_r,_.', 'C'] | Prediccion V\n",
      "Top 0 false positives: \n",
      "\n",
      "Top 10 false positives: \n",
      "\n",
      "Muestra ['.,._,_', '_,.wu.', ',_,.dr', 'V'] | Prediccion D\n",
      "Muestra ['_,__,_', '.wu_.,', '.dr_,,', 'V'] | Prediccion D\n",
      "Muestra ['__._,_', '_.wu,.', ',,_dr.', 'V'] | Prediccion D\n",
      "Muestra ['__,,,_', '_wu_,,', '..dr._', 'V'] | Prediccion D\n",
      "Muestra ['_,,,_.', ',,.wu_', '_,_dr_', 'V'] | Prediccion A\n",
      "Muestra ['._,..,', ',_,wu_', '.,dr_,', 'V'] | Prediccion D\n",
      "Muestra ['__,.._', '._wu.,', 'dr,,__', 'V'] | Prediccion A\n",
      "Muestra [',.,._.', '.wu.__', '..,dr,', 'V'] | Prediccion A\n",
      "Muestra [',,_.._', ',,..wu', ',__dr.', 'V'] | Prediccion D\n",
      "Muestra [',.,,.,', ',,,_wu', '._,_dr', 'V'] | Prediccion D\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_wrong_preds(get_wrong_predictions(best_feedforward_model, x_test_normal, y_test, test_original), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(cnn_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(lstm_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(deepset_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepset V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(deepsetv2_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeedFordward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_epochs_stats(feedforward_epoch_stats, num_experiments, display_train_loss=False, display_val_loss=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
